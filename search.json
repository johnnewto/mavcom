[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MAVCOM",
    "section": "",
    "text": "documentation is available at Mavcom docs"
  },
  {
    "objectID": "index.html#guide-to-developing-with-mavcom",
    "href": "index.html#guide-to-developing-with-mavcom",
    "title": "MAVCOM",
    "section": "Guide to developing with Mavcom",
    "text": "Guide to developing with Mavcom"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "MAVCOM",
    "section": "Install",
    "text": "Install\n\nPython 3.10 venv for Ubuntu 21.04, Ubuntu 20.04 LTS https://www.python.org/downloads/\n\nsudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt update\nsudo apt install python3.10\nNote For Ubuntu 18.04 Deadsnakes/ppa is not hold distribution for Ubuntu 18.04 LTS, so you need to install it manually. Download Python 3.10.0 from https://github.com/conda-forge/miniforge\nThere are 2 or 3 options for Linux architectures:\n\nLinux x86_64 (amd64)\nPython 3.8 Linux aarch64 (arm64) Note: on Jetson 3.10 might fail with a segment fault on arm64 with gstreamer\nLatest Miniconda installer links by Python version\n\nGive the script execution permission and run it to install into ~/miniforge3\nchmod +x Miniforge3-Linux-x86_64.sh\n./Miniforge3-Linux-x86_64.sh\nor\n./Miniconda3-py38_23.10.0-1-Linux-aarch64.sh\nFollow the prompts to install\n\nDownload Mavcom from github and create a virtual environment\n\nmkdir repos\ncd repos\ngit clone https://github.com/johnnewto/mavcom.git\ncd UAV\n~/miniforge3/bin/python -m venv 'venv'\nsource ./venv/bin/activate\npip install --upgrade pip\npip install -e ."
  },
  {
    "objectID": "index.html#documenting-with-nbdev---initial-setup",
    "href": "index.html#documenting-with-nbdev---initial-setup",
    "title": "MAVCOM",
    "section": "Documenting with nbdev - Initial setup",
    "text": "Documenting with nbdev - Initial setup\nif you want to develop with nbdev, you’ll need to install it first. For a step-by-step guide to using nbdev guide to using nbdev You’ll need the following software to develope using nbdev:\n\nPython venv\nA Python package manager: ie pip\nJupyter Notebook\n\npip install jupyter\n\nnbdev\n\npip install nbdev\n\nQuarto\n\nnbdev_install_quarto\n\nInstall Quarto JupyterLab extension\n\npip install jupyterlab-quarto\n\nInstall nbdev pre-commit hooks to catch and fix uncleaned and unexported notebooks\n\npip install pre-commit\nsee nbdev Pre-Commit Hooks for more details\n\nPreview Docs\nStart the preview by entering this into your terminal:\nnbdev_preview\n\n\nPrepare your changes\nBefore commiting your changes to GitHub we recommend running nbdev_prepare in the terminal,\nwhich bundles the following commands:\n\nnbdev_export: Builds the .py modules from Jupyter notebooks\nnbdev_test: Tests your notebooks\nnbdev_clean: Cleans your notebooks to get rid of extreanous output for git\nnbdev_readme: Updates your repo’s README.md file from your index notebook.\n\n\n\nUpdate Static site docs\nGenerate the static docs by entering nbdev_docs into your terminal:\n\n\nPush to GitHub\nYou can now commit and push your changes to GitHub. As we mentioned before, always remember to run nbdev_prepare before you commit to ensure your modules are exported and your tests pass. You can use git status to check which files have been generated or changed. Then:\ngit add .\ngit commit -m 'Add `say_hello`; update index' # Update this text with your own message\ngit push\nThis will kick-off your GitHub Actions. Wait a minute or two for those to complete, then check your updated repo and documentation."
  },
  {
    "objectID": "index.html#other",
    "href": "index.html#other",
    "title": "MAVCOM",
    "section": "Other",
    "text": "Other\n\nSet up autoreload\nSince you’ll be often updating your modules from one notebook, and using them in another, it’s helpful if your notebook automatically reads in the new modules as soon as the Python file changes. To make this happen, just add these lines to the top of your notebook:\n%load_ext autoreload\n%autoreload 2"
  },
  {
    "objectID": "contributing/directives.html",
    "href": "contributing/directives.html",
    "title": "Directives",
    "section": "",
    "text": "Directives are special comments that are preceded by #| that control:\nnbdev augments Quarto by providing additional directives than what are available in Quarto. All Quarto directives can be used in nbdev notebooks.\nThis cheat sheet lists all nbdev directives in addition to some Quarto directives we believe are important. We recommend consulting the quarto docs to see all of the directives available to you.\nTo clarify the origin of directives we use the following emojis:",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Directives"
    ]
  },
  {
    "objectID": "contributing/directives.html#cell-visibility",
    "href": "contributing/directives.html#cell-visibility",
    "title": "Directives",
    "section": "Cell Visibility",
    "text": "Cell Visibility\nThe following directives control cell visibility in rendered documentation:\n\n📓 #|hide\nHide cell input and output.\n\n\n\n\n\n\nExample\n\n\n\n\n\nThe following will result in the contents of the cell and it’s output from being hidden:\n#|hide\nprint('you will not see this')\nNote that using #|hide is equivalent to using the Quarto directive #|include: false:\n#|include: false\nprint('you will not see this')\nSee the quarto docs for more information about #|include.\n\n\n\n\n\n🔵 #|echo: &lt;true|false&gt;\nToggle the visibility of code-cell inputs.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|echo: false\nprint('you can see the output but not the code!')\nwhich results in:\nyou can see the output but not the code!\n\n\n\n\n\n🔵 #|output: &lt;true|false|asis&gt;\nSetting this to false hides the output of a cell. Setting this to asis renders the output as raw markdown.\n\n\n\n\n\n\nExample\n\n\n\n\n\nThe following cell will not display any output:\n#|output: false\n1 + 1\nThe following cell with #|output: asis will produce the output hello fastai rendered as markdown instead of a string:\n#|output: asis\nprint(\"`hello fastai`\")\n\n\n\n\n\n📓 #|hide_line\nHide a specific line of code in an input cell.\n\n\n\n\n\n\nExample\n\n\n\n\n\ndef _secret(): ...\n\nfor i in range(3):\n    _secret() #|hide_line\n    print(i)\nbecomes this:\n\ndef _secret(): ...\n\nfor i in range(3):\n    print(i)\n\n0\n1\n2\n\n\n\n\n\n\n\n📓 #|filter_stream &lt;keyword&gt; ...\nFilter lines containing specific keywords in cell outputs.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|filter_stream FutureWarning MultiIndex\nprint('\\n'.join(['A line', 'Foobar baz FutureWarning blah', \n                 'zig zagMultiIndex zoom', 'Another line.']))\nwill output this:\n\n\nA line\nAnother line.\n\n\n\n\n\n\n\n🔵 #|code-fold: &lt;show|true&gt;\nThe #|code-fold directive allows you to collapse code cells. When set to true, the element is collapsed by default, when set to show show the element is shown by default.\n\n\n\n\n\n\nExample\n\n\n\n\n\nWhen you set #|code-fold: true, the input cell is collapsed:\n\n\nCode\nprint('this is')\nprint('output')\nprint('that takes')\nprint('lots of vertical space')\n\n\nthis is\noutput\nthat takes\nlots of vertical space\n\n\nWhen you set #|code-fold: show the input cell is shown but still in a collapsible element:\n\n\nCode\nprint('this is')\nprint('output')\nprint('that takes')\nprint('lots of vertical space')\n\n\nthis is\noutput\nthat takes\nlots of vertical space",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Directives"
    ]
  },
  {
    "objectID": "contributing/directives.html#generating-source-code",
    "href": "contributing/directives.html#generating-source-code",
    "title": "Directives",
    "section": "Generating Source Code",
    "text": "Generating Source Code\nThe following directives control how source code is exported from code cells.\n\n📓 #|default_exp &lt;name&gt;\nNames the module where cells with the #|export directive will be exported to by default.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#| default_exp baz\n\n# In a new notebook cell:\n\n#| export\ndef my_function(): pass\nIf our package is named: bitsnbytes then we can do:\nfrom bitsnbytes.baz import my_function\nYou can define the package name by using lib_name in settings.ini.\n\n\n\n\n\n📓 #|export\nExports the items in the cell into the generated module and documentation.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|export\ndef say_hello(to:str # name of person to say hello to\n             ):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\nThe above cell will get exported to the module specified by #|default_exp. These exports are automatically included in __all__ for the module. To learn how export without inclusion in __all__, see the #|exporti directive.\nFurthermore, the documentation for this function will automatically be rendered like this:\n\n\nsay_hello\n\n say_hello (to:str)\n\nSay hello to somebody\n\n\n\n\nType\nDetails\n\n\n\n\nto\nstr\nname of person to say hello to\n\n\n\nThe docs are generated from this export using show_doc. See these docs for a detailed discussion of show_doc.\n\n\n\n\n\n\n📓 #|exporti\nAn internal export. Not included in __all__ or the docs. Useful for a function that is called by other functions in this module but is not part of the public API.\nEquivalently, you can prefix your function or method with _ e.g. def _private(): pass.\n\n\n📓 #|exports\nA source export. Like #|export but in addition to showing docs via showdoc.show_doc, it also shows the source code.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|exports\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\nthis will produce the following output:\n\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\n\n\n\nsay_hello\n\n say_hello (to)\n\nSay hello to somebody",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Directives"
    ]
  },
  {
    "objectID": "contributing/directives.html#cell-execution",
    "href": "contributing/directives.html#cell-execution",
    "title": "Directives",
    "section": "Cell Execution",
    "text": "Cell Execution\nThe following directives allow you to control how cells are executed during docs rendering and testing.\n\n📓 #|exec_doc\nEnsures that a cell is executed each time before generating docs. When a cell does not have this annotation, it is run according to the default rules described here.\n\n\n\n\n\n\nExample\n\n\n\n\n\n\ndatetime.datetime.now()\n\ndatetime.datetime(2022, 8, 18, 9, 1, 43, 907609)\n\n\nHowever with the annotation:\n#|exec_doc\ndatetime.datetime.now()\nwe can see that the time has been updated:\n\ndatetime.datetime.now()\n\ndatetime.datetime(2024, 5, 16, 5, 53, 27, 148423)\n\n\n\n\n\n\n\n🔵 #|eval: &lt;true|false&gt;\nWhen set to false, the cell is ignored during testing.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|eval: false\nraise Exception(\"I'm not raised because I'm not run\")\n\n\n\n\n\nCell execution when there is no directive\nWhen a cell has no directives, cells are run by nbdev according to the behavior described here.",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Directives"
    ]
  },
  {
    "objectID": "contributing/why_nbdev.html",
    "href": "contributing/why_nbdev.html",
    "title": "Why nbdev",
    "section": "",
    "text": "Popular Python documentation standards such as numpy docstrings and sphinx facilitate documentation of source code with docstrings, which are limited in their expressiveness and functionality. Notebooks, on the other hand, offer a richer medium for authoring documentation (with markdown and code cells) compared to docstrings, and unlock new ways of documenting your code that are otherwhise infeasible.\nFurthermore, traditional testing frameworks such as pytest and unittest encourage writing tests in a separate context that is disjointed from the associated source code and documentation. With nbdev, you write tests in the same context as your source code and documentation, such that tests can optionally become part of the narrative within your documentation.\nSince nbdev allows your colleagues and users to view the tests, code and documentation in a single context with a REPL that invites experimentation, the way you author code, documentation and tests in nbdev are very different than traditional software development workflows.\nIn Notebook Best Practices we compare a function coded, tested, and documented in nbdev versus ordinary .py files. Here are a few of the challenges we faced with other approaches that led us to using nbdev. In .py files:\n\nDocstrings repeat information that is already contained in the function signature, such as names of parameters, default values, and types\nExamples are manually entered. This requires the author to copy and paste both the code and outputs. Furthermore, the author must manually re-enter or change these examples anytime the code changes, which is an error-prone process\nExamples are limited to short code snippets and cannot contain rich output like plots or graphics\nExamples cannot have prose interleaved with code except for code comments\nReaders of your code must copy and paste contents of the docstring if they wish to reproduce the examples.",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Why nbdev"
    ]
  },
  {
    "objectID": "contributing/config.html",
    "href": "contributing/config.html",
    "title": "Configuration",
    "section": "",
    "text": "All of nbdev’s configuration is done through a file called settings.ini which lives in the root of your repo. It’s in ConfigParser format. For example, here’s the first few lines of nbdev’s settings.ini file\n\n\n[DEFAULT]\nlib_name = nbdev\ndescription = Create delightful software with Jupyter Notebooks\ncopyright = 2020 onwards, Jeremy Howard\nkeywords = nbdev fastai jupyter notebook export\nuser = fastai\nauthor = Jeremy Howard and Hamel Husain\nauthor_email = j@fast.ai\nbranch = master\nmin_python = 3.7\n\n\nYou can create this file with nbdev_create_config (in which case you pass the settings manually), or with nbdev_new (which sets it up automatically for you from your repo settings). Here are all of nbdev’s settings (excluding the path and cfg_name parameters which decide where the config file is saved):\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrepo\nstr\nNone\nRepo name\n\n\nbranch\nstr\nNone\nRepo default branch\n\n\nuser\nstr\nNone\nRepo username\n\n\nauthor\nstr\nNone\nPackage author’s name\n\n\nauthor_email\nstr\nNone\nPackage author’s email address\n\n\ndescription\nstr\nNone\nShort summary of the package\n\n\npath\nstr\n.\nPath to create config file\n\n\ncfg_name\nstr\nsettings.ini\nName of config file to create\n\n\nlib_name\nstr\n%(repo)s\nPackage name\n\n\ngit_url\nstr\nhttps://github.com/%(user)s/%(repo)s\nRepo URL\n\n\ncustom_sidebar\nbool_arg\nFalse\nUse a custom sidebar.yml?\n\n\nnbs_path\nPath\nnbs\nPath to notebooks\n\n\nlib_path\nPath\nNone\nPath to package root (default: repo with - replaced by _)\n\n\ndoc_path\nPath\n_docs\nPath to rendered docs\n\n\ntst_flags\nstr\nnotest\nTest flags\n\n\nversion\nstr\n0.0.1\nVersion of this release\n\n\ndoc_host\nstr\nhttps://%(user)s.github.io\nHostname for docs\n\n\ndoc_baseurl\nstr\n/%(repo)s\nBase URL for docs\n\n\nkeywords\nstr\nnbdev jupyter notebook python\nPackage keywords\n\n\nlicense\nstr\napache2\nLicense for the package\n\n\ncopyright\nstr\nNone\nCopyright for the package, defaults to ‘current_year onwards, author’\n\n\nstatus\nstr\n3\nDevelopment status PyPI classifier\n\n\nmin_python\nstr\n3.7\nMinimum Python version PyPI classifier\n\n\naudience\nstr\nDevelopers\nIntended audience PyPI classifier\n\n\nlanguage\nstr\nEnglish\nLanguage PyPI classifier\n\n\nrecursive\nbool_arg\nTrue\nInclude subfolders in notebook globs?\n\n\nblack_formatting\nbool_arg\nFalse\nFormat libraries with black?\n\n\nreadme_nb\nstr\nindex.ipynb\nNotebook to export as repo readme\n\n\ntitle\nstr\n%(lib_name)s\nQuarto website title\n\n\nallowed_metadata_keys\nstr\n\nPreserve the list of keys in the main notebook metadata\n\n\nallowed_cell_metadata_keys\nstr\n\nPreserve the list of keys in cell level metadata\n\n\njupyter_hooks\nbool_arg\nTrue\nRun Jupyter hooks?\n\n\nclean_ids\nbool_arg\nTrue\nRemove ids from plaintext reprs?\n\n\nclear_all\nbool_arg\nFalse\nRemove all cell metadata and cell outputs?\n\n\nput_version_in_init\nbool_arg\nTrue\nAdd the version to the main init.py in nbdev_export\n\n\n\n\n\nYou can customise nbdev for all repositories for your user with a ~/.config/nbdev/settings.ini file.\nIn order for Git actions to run smoothly, add requirements and dev_requirements with required packages in settings.ini.\nsee here as a reference.",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Configuration"
    ]
  },
  {
    "objectID": "api/mavlink.viewsheen_gimbal.html",
    "href": "api/mavlink.viewsheen_gimbal.html",
    "title": "Mavlink ViewSheen Gimbal Component",
    "section": "",
    "text": "Gimbal Component\nhttps://mavlink.io/en/services/gimbal.html\nhttps://mavlink.io/en/services/gimbal_v2.html &gt; Concepts - Gimbal Manager and Gimbal Device - To accommodate gimbals with varying capabilities, and various hardware setups, “a gimbal” is conceptually split into two parts:\nGimbal Device: the actual gimbal device, hardware and software. Gimbal Manager: software to deconflict gimbal messages and commands from different sources, and to abstract the capabilities of the Gimbal Device from gimbal users. The Gimbal Manager and Gimbal Device expose respective message sets that can be used for: gimbal manager/device discovery, querying capabilities, publishing status, and various types of orientation/attitude control.\nThe key concept to understand is that a Gimbal Manager has a 1:1 relationship with a particular Gimbal Device, and is the only party on the M\n\nsource\n\n\nGimbalClient\n\n GimbalClient (source_component, mav_type, debug)\n\nCreate a Viewsheen mavlink gimbal client component for send commands to a gimbal on a companion computer or GCS\n\n\n\n\nDetails\n\n\n\n\nsource_component\nused for component indication\n\n\nmav_type\nused for heartbeat MAV_TYPE indication\n\n\ndebug\nlogging level\n\n\n\n\nsource\n\n\nGimbalServer\n\n GimbalServer (source_component, mav_type, debug)\n\nCreate a Viewsheen mavlink Camera Server Component for receiving commands from a gimbal on a companion computer or GCS\n\n\n\n\nDetails\n\n\n\n\nsource_component\nused for component indication\n\n\nmav_type\nused for heartbeat MAV_TYPE indication\n\n\ndebug\nlogging level\n\n\n\n\nMAV_TYPE_GCS = mavutil.mavlink.MAV_TYPE_GCS\nMAV_TYPE_CAMERA = mavutil.mavlink.MAV_TYPE_CAMERA\n# cli = GimbalClient(mav_connection=None, source_component=11, mav_type=MAV_TYPE_GCS, debug=False)\n# gim1 = GimbalServer(mav_connection=None, source_component=22, mav_type=MAV_TYPE_CAMERA, debug=False)\n\ncon1, con2 = \"udpin:localhost:14445\", \"udpout:localhost:14445\"\n# con1, con2 = \"/dev/ttyACM0\", \"/dev/ttyUSB0\"\nwith MAVCom(con1, source_system=111, debug=False) as client:\n    with MAVCom(con2, source_system=222, debug=False) as server:\n        gimbal:GimbalClient = client.add_component(GimbalClient( mav_type=MAV_TYPE_GCS, source_component = 11, debug=False))\n        server.add_component(GimbalServer( mav_type=MAV_TYPE_CAMERA, source_component = 22, debug=False))\n        \n        gimbal.wait_heartbeat(target_system=222, target_component=22, timeout=0.99)\n        time.sleep(0.1)\n        gimbal.set_target(222, 22)\n        \n        NAN = float(\"nan\")\n        # client.component[11]._test_command(222, 22, 1)\n        # for i in range (1)  :\n        #     time.sleep(0.01)\n        gimbal.set_attitude( NAN, NAN, 0.0, 0.2)\n        time.sleep(0.5)\n        gimbal.set_attitude( NAN, NAN, 0.0, -0.2)\n        time.sleep(0.5)\n        gimbal.start_capture()\n        # gimbal.set_zoom(1)\n        \n        \n        # client.component[11].set_attitude(0, 0, 0, 0, 0, 0)\n\nINFO   | mavcom.MAVCom      | 44.813 |  mavcom.py:393 | Thread-7 (listen)  | MAVLink Mav2: True, source_system: 111\nINFO   | mavcom.MAVCom      | 44.915 |  mavcom.py:393 | Thread-8 (listen)  | MAVLink Mav2: True, source_system: 222\nINFO   | mavcom.GimbalClien | 44.917 | component.py:111 | MainThread         | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\nINFO   | mavcom.MAVCom      | 52.945 |  mavcom.py:441 | MainThread         | MAVCom  closed\nINFO   | mavcom.GimbalClien | 53.953 | component.py:366 | MainThread         | GimbalClient closed\nINFO   | mavcom.MAVCom      | 53.955 |  mavcom.py:441 | MainThread         | MAVCom  closed\n\n\nset_mav_connection GimbalClient mavcom.py:107 self.mav_connection = &lt;MAVCom&gt;\n\n\nKeyboardInterrupt: \n\n\n\n# assert False, \"Stop here\"",
    "crumbs": [
      "Get Started",
      "API",
      "Mavlink ViewSheen Gimbal Component"
    ]
  },
  {
    "objectID": "api/mavlink.component.html",
    "href": "api/mavlink.component.html",
    "title": "Mavlink Component",
    "section": "",
    "text": "import time, os, sys\n\nfrom mavcom.logging import logging\nfrom mavcom.utils.general import LeakyQueue\n\n# os.environ['MAVLINK20'] == '1' should be placed in mavcom.__init__.py\nassert os.environ[\n           'MAVLINK20'] == '1', \"Set the environment variable before from pymavlink import mavutil  library is imported\"\nExported source\nfrom mavcom.mavlink.component import *\nsource",
    "crumbs": [
      "Get Started",
      "API",
      "Mavlink Component"
    ]
  },
  {
    "objectID": "api/mavlink.component.html#test-locally-using-udp-ports",
    "href": "api/mavlink.component.html#test-locally-using-udp-ports",
    "title": "Mavlink Component",
    "section": "Test locally using UDP ports",
    "text": "Test locally using UDP ports\n\nStarting a client and server\n\non the same machine using UDP ports 14445 with server_system_ID=111, client_system_ID=222\n\n\n\nExported source\nfrom mavcom.mavlink.component import Component, mavutil\nfrom mavcom.mavlink.mavcom import MAVCom\n\nMAV_TYPE_GCS = mavutil.mavlink.MAV_TYPE_GCS\nMAV_TYPE_CAMERA = mavutil.mavlink.MAV_TYPE_CAMERA\n\nclass Cam1(Component):\n    def __init__(self, source_component, mav_type, debug=False):\n        super().__init__(source_component=source_component, mav_type=mav_type,\n                         debug=debug)\n\nclass Cam2(Component):\n    def __init__(self, source_component, mav_type, debug=False):\n        super().__init__(source_component=source_component, mav_type=mav_type,\n                         debug=debug)\nclass Cli(Component):\n    def __init__(self, source_component, mav_type, debug=False):\n        super().__init__(source_component=source_component, mav_type=mav_type,\n                         debug=debug)\n\ndef test_ack():\n    \"\"\"Test sending a command and receiving an ack from client to server\"\"\"\n    with MAVCom(\"udpin:localhost:14445\", source_system=111, debug=False) as client:\n        with MAVCom(\"udpout:localhost:14445\", source_system=222, debug=False) as server:\n            client.add_component(Cli(mav_type=MAV_TYPE_GCS, source_component = 11, debug=False))\n            server.add_component(Cam1(mav_type=MAV_TYPE_CAMERA, source_component = 22, debug=False))\n            server.add_component(Cam1(mav_type=MAV_TYPE_CAMERA, source_component = 23, debug=False))\n            \n            for key, comp in client.component.items():\n                if comp.wait_heartbeat(target_system=222, target_component=22, timeout=0.1):\n                    print (\"*** Received heartbeat **** \" )\n            NUM_TO_SEND = 2\n            for i in range(NUM_TO_SEND):\n                client.component[11]._test_command(222, 22, 1)\n                client.component[11]._test_command(222, 23, 1)\n                \n            client.component[11]._test_command(222, 24, 1)\n    \n        print(f\"{server.source_system = };  {server.message_cnts = }\")\n        print(f\"{client.source_system = };  {client.message_cnts = }\")\n        print()\n        print(f\"{client.source_system = } \\n{client.summary()} \\n\")\n        print(f\"{server.source_system = } \\n{server.summary()} \\n\")\n    \n        assert client.component[11].num_cmds_sent == NUM_TO_SEND * 2 + 1\n        assert client.component[11].num_acks_rcvd == NUM_TO_SEND * 2\n        assert client.component[11].num_acks_drop == 1\n        assert server.component[22].num_cmds_rcvd == NUM_TO_SEND\n        assert server.component[23].num_cmds_rcvd == NUM_TO_SEND\n        \ntest_ack()\n\n\nINFO   | mavcom.MAVCom      | 12.366 |  mavcom.py:396 | Thread-37 (listen) | MAVLink Mav2: True, source_system: 111\nINFO   | mavcom.MAVCom      | 12.468 |  mavcom.py:396 | Thread-38 (listen) | MAVLink Mav2: True, source_system: 222\nINFO   | mavcom.Cli         | 12.471 | component.py:127 | MainThread         | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\nINFO   | mavcom.Cam1        | 12.472 | component.py:127 | MainThread         | Component Started self.source_component = 22, self.mav_type = 30, self.source_system = 222\nINFO   | mavcom.Cam1        | 12.474 | component.py:127 | MainThread         | Component Started self.source_component = 23, self.mav_type = 30, self.source_system = 222\nWARNIN | mavcom.Cli         | 12.976 | component.py:352 | MainThread         | **No ACK: 222/22 MAV_CMD_DO_DIGICAM_CONTROL:203\nWARNIN | mavcom.Cli         | 13.477 | component.py:352 | MainThread         | **No ACK: 222/23 MAV_CMD_DO_DIGICAM_CONTROL:203\nWARNIN | mavcom.Cli         | 13.979 | component.py:352 | MainThread         | **No ACK: 222/22 MAV_CMD_DO_DIGICAM_CONTROL:203\nWARNIN | mavcom.Cli         | 14.481 | component.py:352 | MainThread         | **No ACK: 222/23 MAV_CMD_DO_DIGICAM_CONTROL:203\nERROR  | mavcom.MAVCom      | 14.482 |  mavcom.py:419 | Thread-38 (listen) |  Component 24 does not exist? ; Exception: 24\nWARNIN | mavcom.Cli         | 14.982 | component.py:352 | MainThread         | **No ACK: 222/24 MAV_CMD_DO_DIGICAM_CONTROL:203\nINFO   | mavcom.Cam1        | 15.476 | component.py:382 | MainThread         | Cam1 closed\nINFO   | mavcom.Cam1        | 15.477 | component.py:382 | MainThread         | Cam1 closed\nINFO   | mavcom.MAVCom      | 15.479 |  mavcom.py:447 | MainThread         | MAVCom  closed\nINFO   | mavcom.Cli         | 17.475 | component.py:382 | MainThread         | Cli closed\nINFO   | mavcom.MAVCom      | 17.477 |  mavcom.py:447 | MainThread         | MAVCom  closed\n\n\nset_mav_connection Cli component.py:123 self.mav_connection = &lt;MAVCom&gt;\nset_mav_connection Cam1 component.py:123 self.mav_connection = &lt;MAVCom&gt;\nset_mav_connection Cam1 component.py:123 self.mav_connection = &lt;MAVCom&gt;\n*** Received heartbeat **** \nserver.source_system = 222;  server.message_cnts = {111: {'COMMAND_LONG': 5, 'HEARTBEAT': 3}}\nclient.source_system = 111;  client.message_cnts = {222: {'HEARTBEAT': 6}}\n\nclient.source_system = 111 \n - comp.source_component = 11\n - comp.num_msgs_rcvd = 6\n - comp.num_cmds_sent = 5\n - comp.num_cmds_rcvd = 0\n - comp.num_acks_rcvd = 0\n - comp.num_acks_sent = 0\n - comp.num_acks_drop = 5\n - comp.message_cnts = {222: {'HEARTBEAT': 6}} \n\nserver.source_system = 222 \n - comp.source_component = 22\n - comp.num_msgs_rcvd = 4\n - comp.num_cmds_sent = 0\n - comp.num_cmds_rcvd = 2\n - comp.num_acks_rcvd = 0\n - comp.num_acks_sent = 0\n - comp.num_acks_drop = 0\n - comp.message_cnts = {111: {'COMMAND_LONG': 2, 'HEARTBEAT': 2}}\n - comp.source_component = 23\n - comp.num_msgs_rcvd = 4\n - comp.num_cmds_sent = 0\n - comp.num_cmds_rcvd = 2\n - comp.num_acks_rcvd = 0\n - comp.num_acks_sent = 0\n - comp.num_acks_drop = 0\n - comp.message_cnts = {111: {'COMMAND_LONG': 2, 'HEARTBEAT': 2}} \n\n\nAssertionError: \n\n\n\n\nTest with Serial ports\nTest using a Pixhawk connected via telemetry 2 and USB serial ports. CamClient is set to udpin:localhost:14445 and CamServer is set to udpout:localhost:14435 udpin is so that the client can receive UDP from the mavproxy server at localhost:14445 mavproxy.py –master=/dev/ttyACM1 –baudrate 57600 –out udpout:localhost:14445 mavproxy.py –master=/dev/ttyACM3 –baudrate 57600 –out udpout:localhost:14435\n\nFor debugging help see http://localhost:3000/tutorials/mavlink_doc&debug.html and http://localhost:3000/tutorials/mavlink_doc&debug.html#debugging",
    "crumbs": [
      "Get Started",
      "API",
      "Mavlink Component"
    ]
  },
  {
    "objectID": "api/mavlink.mavcom.html",
    "href": "api/mavlink.mavcom.html",
    "title": "Mavlink MavCom",
    "section": "",
    "text": "# logging.getLogger(\"uav\").setLevel(logging.INFO)\n\n\nMAV_SYSTEM_GCS_CLIENT = 200  # GCS type client (TODO its not clear if this is correct,  255 = GCS)\nMAV_TYPE_GCS = mavutil.mavlink.MAV_TYPE_GCS\nMAV_SYSTEM_VEHICLE = 111  # 1 = vehicle\nMAV_TYPE_CAMERA = mavutil.mavlink.MAV_TYPE_CAMERA\nMAV_COMP_ID_CAMERA = mavutil.mavlink.MAV_COMP_ID_CAMERA\nMAV_COMP_ID_USER1 = mavutil.mavlink.MAV_COMP_ID_USER1\n\n\n\n\nComponent\n\n Component (source_component:int, mav_type:int, loglevel:LogLevels|int=20)\n\nCreate a client component to send commands to a companion computer or GCS that will control a cameras via a CameraServer instance\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsource_component\nint\n\nused for component indication\n\n\nmav_type\nint\n\nused for heartbeat MAV_TYPE indication\n\n\nloglevel\nLogLevels | int\n20\nlogging level\n\n\n\n\n\n\n\n\nMAVCom\n\n MAVCom (connection_string:str, baudrate:int=57600, source_system:int=111,\n         loglevel:LogLevels|int=20)\n\nMavlink Base to set up a mavlink_connection for send and receive messages to and from a remote system.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nconnection_string\nstr\n\n“udpin:localhost:14550”\n\n\nbaudrate\nint\n57600\nbaud rate of the serial port\n\n\nsource_system\nint\n111\nremote or air system 1 = vehicle\n\n\nloglevel\nLogLevels | int\n20\nlogging level\n\n\n\n\n\n\n# show_doc(MavLinkBase)\n\n\nTest locally using UDP ports\n\n\nStarting a client and server\n\non the same machine using UDP ports 14445 with server_system_ID=111, client_system_ID=222\n\n\n\nExported source\ndef test_MAVCom():\n    \"\"\"Test MAVCom with a client and server on the same machine using UDP ports `14445`  with `server_system_ID=111, client_system_ID=222`\"\"\"\n    with MAVCom(\"udpin:localhost:14445\", source_system=111, loglevel=LogLevels.DEBUG) as client:\n        with MAVCom(\"udpout:localhost:14445\", source_system=222, loglevel=LogLevels.DEBUG) as server:\n            server.add_component(Component(server, mav_type=mavlink.MAV_TYPE_CAMERA, loglevel=LogLevels.DEBUG))\n            client.add_component(Component(client, mav_type=mavlink.MAV_TYPE_GCS, loglevel=LogLevels.DEBUG))\n    \n            MAX_PINGS = 4\n            client.component[11].send_ping(222, 22, max_pings=MAX_PINGS)\n            time.sleep(0.5)\n    \n    print(f\"{server.source_system = };  {server.message_cnts = }\")\n    print(f\"{client.source_system = };  {client.message_cnts = }\")\n    \n    test_eq(server.message_cnts[111]['PING'], MAX_PINGS)\n    test_eq(server.message_cnts[111]['HEARTBEAT']&gt;0, True) \n    test_eq(client.message_cnts[222]['PING'], MAX_PINGS)\n    test_eq(client.message_cnts[222]['HEARTBEAT']&gt;0, True)\n    \ntest_MAVCom()\n\n\nINFO |07.381| mavcom.MAVCom   | mavcom.py :386 |  Thread-17 | MainProces | MAVLink Mav2: True, source_system: 111\nINFO |07.484| mavcom.MAVCom   | mavcom.py :386 |  Thread-18 | MainProces | MAVLink Mav2: True, source_system: 222\nDEBUG|07.487| mavcom.Componen | basecompon:119 | MainThread | MainProces | set_mav_connection Component general.py:119 self.mav_com = &lt;MAVCom&gt;\nDEBUG|07.489| mavcom.Componen | basecompon:165 |  Thread-19 | MainProces | Starting heartbeat type: 30 to all Systems and Components\nDEBUG|07.490| mavcom.Componen | basecompon:168 |  Thread-19 | MainProces | Sent heartbeat 30 self.source_system = 222 self.source_component = &lt;MAVCom&gt;\nException in thread Thread-19:\nTraceback (most recent call last):\n  File \"/usr/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\nDEBUG|07.491| mavcom.Componen | basecompon:127 | MainThread | MainProces | Called from Component.start_mav_connection(), override to add startup behaviour\nINFO |07.492| mavcom.Componen | basecompon:123 | MainThread | MainProces | Component Started self.source_component = &lt;MAVCom&gt;, self.mav_type = 30, self.source_system = 222\n    self.run()\n  File \"/usr/lib/python3.9/threading.py\", line 917, in run\nDEBUG|07.494| mavcom.Componen | basecompon:119 | MainThread | MainProces | set_mav_connection Component general.py:119 self.mav_com = &lt;MAVCom&gt;\n    self._target(*self._args, **self._kwargs)\n  File \"/home/john/PycharmProjects/mavcom/mavcom/mavlink/basecomponent.py\", line 170, in _thread_send_heartbeat\nDEBUG|07.496| mavcom.Componen | basecompon:165 |  Thread-21 | MainProces | Starting heartbeat type: 6 to all Systems and Components\n    self.master.mav.heartbeat_send(\n  File \"/home/john/PycharmProjects/mavcom/venv/lib/python3.9/site-packages/pymavlink/dialects/v20/ardupilotmega.py\", line 30550, in heartbeat_send\nDEBUG|07.501| mavcom.Componen | basecompon:127 | MainThread | MainProces | Called from Component.start_mav_connection(), override to add startup behaviour\n    self.send(self.heartbeat_encode(type, autopilot, base_mode, custom_mode, system_status, mavlink_version), force_mavlink1=force_mavlink1)\n  File \"/home/john/PycharmProjects/mavcom/venv/lib/python3.9/site-packages/pymavlink/dialects/v20/ardupilotmega.py\", line 20228, in send\nDEBUG|07.501| mavcom.Componen | basecompon:168 |  Thread-21 | MainProces | Sent heartbeat 6 self.source_system = 111 self.source_component = &lt;MAVCom&gt;\n    buf = mavmsg.pack(self, force_mavlink1=force_mavlink1)\n  File \"/home/john/PycharmProjects/mavcom/venv/lib/python3.9/site-packages/pymavlink/dialects/v20/ardupilotmega.py\", line 19808, in pack\n    return self._pack(mav, self.crc_extra, self.unpacker.pack(self.custom_mode, self.type, self.autopilot, self.base_mode, self.system_status, self.mavlink_version), force_mavlink1=force_mavlink1)\n  File \"/home/john/PycharmProjects/mavcom/venv/lib/python3.9/site-packages/pymavlink/dialects/v20/ardupilotmega.py\", line 272, in _pack\n    self._msgbuf = bytearray(self._header.pack(force_mavlink1=force_mavlink1))\n  File \"/home/john/PycharmProjects/mavcom/venv/lib/python3.9/site-packages/pymavlink/dialects/v20/ardupilotmega.py\", line 88, in pack\n    return struct.pack(\nstruct.error: required argument is not an integer\nException in thread Thread-21:\nTraceback (most recent call last):\n  File \"/usr/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\nINFO |07.508| mavcom.Componen | basecompon:123 | MainThread | MainProces | Component Started self.source_component = &lt;MAVCom&gt;, self.mav_type = 6, self.source_system = 111\n    self.run()\n  File \"/usr/lib/python3.9/threading.py\", line 917, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/john/PycharmProjects/mavcom/mavcom/mavlink/basecomponent.py\", line 170, in _thread_send_heartbeat\n    self.master.mav.heartbeat_send(\n  File \"/home/john/PycharmProjects/mavcom/venv/lib/python3.9/site-packages/pymavlink/dialects/v20/ardupilotmega.py\", line 30550, in heartbeat_send\n    self.send(self.heartbeat_encode(type, autopilot, base_mode, custom_mode, system_status, mavlink_version), force_mavlink1=force_mavlink1)\n  File \"/home/john/PycharmProjects/mavcom/venv/lib/python3.9/site-packages/pymavlink/dialects/v20/ardupilotmega.py\", line 20228, in send\n    buf = mavmsg.pack(self, force_mavlink1=force_mavlink1)\n  File \"/home/john/PycharmProjects/mavcom/venv/lib/python3.9/site-packages/pymavlink/dialects/v20/ardupilotmega.py\", line 19808, in pack\n    return self._pack(mav, self.crc_extra, self.unpacker.pack(self.custom_mode, self.type, self.autopilot, self.base_mode, self.system_status, self.mavlink_version), force_mavlink1=force_mavlink1)\n  File \"/home/john/PycharmProjects/mavcom/venv/lib/python3.9/site-packages/pymavlink/dialects/v20/ardupilotmega.py\", line 272, in _pack\n    self._msgbuf = bytearray(self._header.pack(force_mavlink1=force_mavlink1))\n  File \"/home/john/PycharmProjects/mavcom/venv/lib/python3.9/site-packages/pymavlink/dialects/v20/ardupilotmega.py\", line 88, in pack\n    return struct.pack(\nstruct.error: required argument is not an integer\nINFO |08.489| mavcom.Componen | basecompon:417 | MainThread | MainProces | Component closed (not waiting for _t_heartbeat daemon thread)\nINFO |08.490| mavcom.MAVCom   | mavcom.py :442 | MainThread | MainProces | MAVCom  closed\nINFO |09.387| mavcom.Componen | basecompon:417 | MainThread | MainProces | Component closed (not waiting for _t_heartbeat daemon thread)\nINFO |09.389| mavcom.MAVCom   | mavcom.py :442 | MainThread | MainProces | MAVCom  closed\n\n\nKeyError: 11\n\n\n\n# assert False, \"Stop here\"\n\nThis will show on wireshark as follows: &gt; Using the display filte string not icmp  && udp.port eq 14445 && mavlink_proto\n\nFor debugging help see http://localhost:3000/tutorials/mavlink_doc&debug.html and http://localhost:3000/tutorials/mavlink_doc&debug.html#debugging",
    "crumbs": [
      "Get Started",
      "API",
      "Mavlink  MavCom"
    ]
  },
  {
    "objectID": "tutorials/mav_camera_walkthrough.html",
    "href": "tutorials/mav_camera_walkthrough.html",
    "title": "Mavlink Camera Walkthrough",
    "section": "",
    "text": "Here we create an entire mavlink connection with client at the GCS and server at the camera. The client and server are connected via a UDP connection or a radio modem serial connection The camera can be controlled via the client, and the video stream is sent from the server to the client. The client can also request camera information, storage information, etc from the server.\n\n\nfrom mavcom.mavlink import CameraClient, CameraServer,  MAVCom, GimbalClient, GimbalServer, mavutil, mavlink\n# from mavcom.mavlink.camera_client import CameraClient\n# from mavcom.mavlink.camera_server import  CameraServer\n# from mavcom.mavlink import Component, mavutil, mavlink, MAVCom\nfrom mavcom.utils import boot_time_str, read_camera_dict_from_toml, find_config_dir\nfrom mavcom.camera.gst_cam import GSTCamera    # fake camera for testing\nfrom gstreamer import  GstPipeline\nimport gstreamer.utils as gst_utils\nfrom mavcom.logging import LogLevels\nfrom pathlib import Path\nimport cv2\n\nCreate a CameraClient and CameraServer\n\nMAV_TYPE_GCS = mavutil.mavlink.MAV_TYPE_GCS\nMAV_TYPE_CAMERA = mavutil.mavlink.MAV_TYPE_CAMERA\n\nCreate a gstreamer pipelene to display the received video\nCreate Pysical camera object, here either CV2Camera or GSTCamera The toml file contains the camera parameters, such as resolution, framerate, etc and also the gstreamer pipeline command to create the video streams.\n\ncam_gst_1 = GSTCamera(camera_dict=read_camera_dict_from_toml(find_config_dir() / \"test_camera_info.toml\"))\n# cam_cv2_1 = CV2Camera(camera_dict=read_camera_dict_from_toml(find_config_dir() / \"test_camera_info.toml\"))\n\nINFO   | mavcom.GSTCamera   | 38.075 | gst_cam.py:317 | MainThread         | GSTCamera Started\nINFO   | pygst.GstPipeli | 38.086 | gst_tools.py:223 | MainThread         | Starting GstPipeline: videotestsrc  ! video/x-raw,width=1920,height=1080,framerate=30/1 ! tee name=t t. ! queue ! autovideosink t. ! queue leaky=2 ! intervideosink channel=channel_0 t. ! queue leaky=2 ! intervideosink channel=channel_1 t. ! queue leaky=2 ! videoconvert ! videorate drop-only=true ! intervideosink channel=channel_2 \n\n\nJohn Doe                        \n\n\n\nSINK_PIPELINE = gst_utils.to_gst_string([\n            'udpsrc port=5000 ! application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96',\n            'rtph264depay ! avdec_h264',\n            'fpsdisplaysink',\n            # 'autovideosink',\n        ])\n\nrcv_pipeline = GstPipeline(SINK_PIPELINE)     # Create a Gstreamer pipeline to display the received video on fpsdisplaysink\n\nCreate the client mavlink connection, this is mounted on the GCS\n\n# assert False\n\n\n# for the client, we use the udpin connection, you can use serial as an option i.e \"/dev/ttyACM0\", \"/dev/ttyUSB0\"\nclient = MAVCom(\"udpin:localhost:14445\", source_system=111, loglevel=LogLevels.INFO)\n\nINFO   | mavcom.MAVCom      | 38.254 |  mavcom.py:393 | Thread-5 (listen)  | MAVLink Mav2: True, source_system: 111\n\n\nCreate the server mavlink connection, this is mounted on the UAV companion computer\n\n# for the server, we use the udpout connection, you can use serial as an option  \"/dev/ttyUSB0\"\nserver = MAVCom(\"udpout:localhost:14445\", source_system=222)\n\nINFO   | mavcom.MAVCom      | 38.365 |  mavcom.py:393 | Thread-6 (listen)  | MAVLink Mav2: True, source_system: 222\n\n\nAdd the camera client to the client mavlink connection\n\ncam = client.add_component(CameraClient(mav_type=mavlink.MAV_TYPE_GCS, source_component=11))\n\nINFO   | mavcom.CameraClien | 38.404 | component.py:135 | MainThread         | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\n\n\nAdd the camera server to the server mavlink connection\n\nserver.add_component(CameraServer(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=mavlink.MAV_COMP_ID_CAMERA, camera=cam_gst_1))\n\nINFO   | mavcom.CameraServe | 38.418 | component.py:135 | MainThread         | Component Started self.source_component = 100, self.mav_type = 30, self.source_system = 222\n\n\n&lt;CameraServer&gt;\n\n\nWait for the heartbeat from the camera server\n\nasync def doit():\n    ret = await cam.wait_heartbeat(remote_mav_type=mavlink.MAV_TYPE_CAMERA)\n    print(f\"Heartbeat received {ret = }\")\nawait doit()\n\nHeartbeat received ret = (222, 100)\n\n\nSet the target system and component for the camera client and request camera information, storage information, camera capture status, and camera settings\n\nasync def doit():\n    msg = await cam.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_INFORMATION, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n    print (f\"1 MAVLINK_MSG_ID_CAMERA_INFORMATION {msg }\")\n    msg = await cam.request_message(mavlink.MAVLINK_MSG_ID_STORAGE_INFORMATION, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n    print (f\"2 MAVLINK_MSG_ID_STORAGE_INFORMATION {msg }\")\n    msg = await cam.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n    print (f\"3 MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS {msg }\")\n    msg = await cam.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_SETTINGS, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n    print (f\"4 MAVLINK_MSG_ID_CAMERA_SETTINGS {msg }\")\nawait doit()\n\n1 MAVLINK_MSG_ID_CAMERA_INFORMATION CAMERA_INFORMATION {time_boot_ms : 520, vendor_name : John Doe, model_name : Fake Camera, firmware_version : 1, focal_length : 8.0, sensor_size_h : 6.0, sensor_size_v : 4.0, resolution_h : 1920, resolution_v : 1080, lens_id : 0, flags : 0, cam_definition_version : 1, cam_definition_uri : http://example.com/camera_definition.xml, gimbal_device_id : 0}\n2 MAVLINK_MSG_ID_STORAGE_INFORMATION STORAGE_INFORMATION {time_boot_ms : 621, storage_id : 0, storage_count : 1, status : 0, total_capacity : 100000000.0, used_capacity : 0.0, available_capacity : 100000000.0, read_speed : 0.0, write_speed : 0.0, type : 0, name : }\n3 MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS CAMERA_CAPTURE_STATUS {time_boot_ms : 722, image_status : 0, video_status : 0, image_interval : 0.0, recording_time_ms : 0, available_capacity : 0.0, image_count : 0}\n4 MAVLINK_MSG_ID_CAMERA_SETTINGS CAMERA_SETTINGS {time_boot_ms : 824, mode_id : 0, zoomLevel : 0.0, focusLevel : 0.0}\n\n\nStart an image capture seqeunce, and display the images as they arrive\n\n# cam.image_start_capture(interval=0.1, count=10)\n# while cam_gst_1.capture_thread.is_alive():\n#     if cam_gst_1.last_image is not None:\n#         cv2.imshow('gst_src', cam_gst_1.last_image)\n#         cam_gst_1.last_image = None\n#     cv2.waitKey(10)\n\nAssertionError: call set_target(target_system, target_component) first\n\n\nShutdown the receive pipeline and close the mavlink connections\n\nrcv_pipeline.shutdown()\nclient.close()\nserver.close()\ncv2.destroyAllWindows()\n\nPerform the same test, but with the CV2Camera all in one cell\n\nfrom mavcom.utils.display import show_image\nfrom mavcom.logging import LogLevels\n\nfrom mavcom.mavlink import CameraClient, CameraServer,  MAVCom, GimbalClient, GimbalServer, mavutil, mavlink\nfrom mavcom.utils.general import boot_time_str, With, read_camera_dict_from_toml, find_config_dir\n\nfrom mavcom.camera.gst_cam import GSTCamera\nfrom gstreamer import GstPipeline, Gst, GstContext, GstPipes\nimport gstreamer.utils as gst_utils\nimport cv2\nimport time\nfrom pathlib import Path\nimport asyncio\n\nSINK_PIPELINE = gst_utils.to_gst_string([\n            'udpsrc port=5000 ! application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96',\n            'rtph264depay ! avdec_h264',\n            'fpsdisplaysink',\n            # 'autovideosink',\n        ])\ncon1, con2 = \"udpin:localhost:14445\", \"udpout:localhost:14445\"\n# con1, con2 = \"/dev/ttyACM0\", \"/dev/ttyUSB0\"\n\nprint (f\"{boot_time_str =}\")\n\ncam_uav = GSTCamera(camera_dict=read_camera_dict_from_toml(find_config_dir() / \"test_camera_info.toml\"))\n# cam_uav = CV2Camera(camera_dict=read_camera_dict_from_toml(find_config_dir() / \"test_camera_info.toml\"))\n\nasync def doit ():\n    # with GstContext():  # GST main loop in thread\n    with GstContext(), GstPipeline(SINK_PIPELINE):     # Create a Gstreamer pipeline to display the received video on fpsdisplaysink\n        with MAVCom(con1, source_system=111) as client:\n            with MAVCom(con2, source_system=222) as server:\n                gcs = client.add_component(CameraClient(mav_type=mavlink.MAV_TYPE_GCS, source_component=11))\n                server.add_component(CameraServer(camera=cam_uav, source_component=mavlink.MAV_COMP_ID_CAMERA))\n                # server.add_component(CameraServer(mav_type=MAV_TYPE_CAMERA, source_component=22, camera=None, debug=False))\n    \n                ret = await gcs.wait_heartbeat(remote_mav_type=mavlink.MAV_TYPE_CAMERA)\n                print(f\"Heartbeat received {ret = }\")\n                time.sleep(0.1)\n                msg = await gcs.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_INFORMATION, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n                print (f\"1 MAVLINK_MSG_ID_CAMERA_INFORMATION {msg }\")\n                msg = await gcs.request_message(mavlink.MAVLINK_MSG_ID_STORAGE_INFORMATION, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n                print (f\"2 MAVLINK_MSG_ID_STORAGE_INFORMATION {msg }\")\n                msg = await gcs.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n                print (f\"3 MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS {msg }\")\n                msg = await gcs.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_SETTINGS, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n                print (f\"4 MAVLINK_MSG_ID_CAMERA_SETTINGS {msg }\")\n    \n                ret = await gcs.image_start_capture(222, mavlink.MAV_COMP_ID_CAMERA, interval=0.2, count=5)\n                print(f\"{ret = }\")\n                \n                time.sleep(1)\n                for file in cam_mavcom.list_files():\n                    if file.endswith(\".jpg\"):\n                        img = cam_mavcom.load_image_from_memoryfs(file)\n                        print (f\"{file = }, {img.shape = }\")\n\n                lastimg = img\n                show_image(lastimg, rgb2bgr=True)\n                # start = time.time()\n                msg = await gcs.request_message(mavlink.MAVLINK_MSG_ID_STORAGE_INFORMATION, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n                print(f\"5 MAVLINK_MSG_ID_STORAGE_INFORMATION {msg}\")\n                # time.sleep(5)\n\n    \nawait doit()\n\nINFO   | mavcom.GSTCamera   | 16.334 | gst_cam.py:317 | MainThread         | GSTCamera Started\nINFO   | pygst.GstPipeli | 16.405 | gst_tools.py:223 | MainThread         | Starting GstPipeline: videotestsrc  ! video/x-raw,width=1920,height=1080,framerate=30/1 ! tee name=t t. ! queue ! autovideosink t. ! queue leaky=2 ! intervideosink channel=channel_0 t. ! queue leaky=2 ! intervideosink channel=channel_1 t. ! queue leaky=2 ! videoconvert ! videorate drop-only=true ! intervideosink channel=channel_2 \nINFO   | pygst.GstPipeli | 16.416 | gst_tools.py:223 | MainThread         | Starting GstPipeline: udpsrc port=5000 ! application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96 ! rtph264depay ! avdec_h264 ! fpsdisplaysink\nINFO   | mavcom.MAVCom      | 16.518 |  mavcom.py:393 | Thread-47 (listen) | MAVLink Mav2: True, source_system: 111\nINFO   | mavcom.MAVCom      | 16.620 |  mavcom.py:393 | Thread-48 (listen) | MAVLink Mav2: True, source_system: 222\nINFO   | mavcom.CameraClien | 16.622 | component.py:135 | MainThread         | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\nINFO   | mavcom.CameraServe | 16.624 | component.py:135 | MainThread         | Component Started self.source_component = 100, self.mav_type = 30, self.source_system = 222\nWARNIN | mavcom.CameraClien | 19.835 | component.py:261 | MainThread         | **** ACK not handled MAV_CMD_REQUEST_MESSAGE:512 from : 222/100 COMMAND_ACK {command : 512, result : 0, progress : 0, result_param2 : 0, target_system : 111, target_component : 11}\nWARNIN | mavcom.CameraClien | 19.837 | component.py:263 | MainThread         |       command_id = MAV_CMD_REQUEST_MESSAGE msg.get_srcSystem() = 222, target_system = 222,  msg.get_srcComponent() = 100, target_component = 100\nWARNIN | mavcom.CameraClien | 19.838 | component.py:261 | MainThread         | **** ACK not handled MAV_CMD_REQUEST_MESSAGE:512 from : 222/100 COMMAND_ACK {command : 512, result : 0, progress : 0, result_param2 : 0, target_system : 111, target_component : 11}\nWARNIN | mavcom.CameraClien | 19.839 | component.py:263 | MainThread         |       command_id = MAV_CMD_REQUEST_MESSAGE msg.get_srcSystem() = 222, target_system = 222,  msg.get_srcComponent() = 100, target_component = 100\nWARNIN | mavcom.CameraClien | 19.841 | component.py:261 | MainThread         | **** ACK not handled MAV_CMD_REQUEST_MESSAGE:512 from : 222/100 COMMAND_ACK {command : 512, result : 0, progress : 0, result_param2 : 0, target_system : 111, target_component : 11}\nWARNIN | mavcom.CameraClien | 19.842 | component.py:263 | MainThread         |       command_id = MAV_CMD_REQUEST_MESSAGE msg.get_srcSystem() = 222, target_system = 222,  msg.get_srcComponent() = 100, target_component = 100\nWARNIN | mavcom.CameraClien | 19.843 | component.py:261 | MainThread         | **** ACK not handled MAV_CMD_REQUEST_MESSAGE:512 from : 222/100 COMMAND_ACK {command : 512, result : 0, progress : 0, result_param2 : 0, target_system : 111, target_component : 11}\nWARNIN | mavcom.CameraClien | 19.845 | component.py:263 | MainThread         |       command_id = MAV_CMD_REQUEST_MESSAGE msg.get_srcSystem() = 222, target_system = 222,  msg.get_srcComponent() = 100, target_component = 100\nINFO   | pygst.GstJpegEn | 19.847 | gst_tools.py:223 | Thread-10 (_t_list | Starting GstJpegEnc: intervideosrc channel=channel_1   ! videoconvert ! videoscale ! video/x-raw,width=640,height=480,framerate=4/1 ! queue ! jpegenc quality=85 ! appsink name=mysink emit-signals=True max-buffers=1 drop=True\nINFO   | pygst.GstJpegEn | 19.847 | gst_tools.py:223 | Thread-52 (_t_list | Starting GstJpegEnc: intervideosrc channel=channel_1   ! videoconvert ! videoscale ! video/x-raw,width=640,height=480,framerate=4/1 ! queue ! jpegenc quality=85 ! appsink name=mysink emit-signals=True max-buffers=1 drop=True\nINFO   | mavcom.GSTCamera   | 19.877 | gst_cam.py:541 | Thread-53 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:19_0010.jpg\nINFO   | mavcom.GSTCamera   | 19.878 | gst_cam.py:541 | Thread-54 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:19_0000.jpg\nWARNIN | mavcom.CameraClien | 19.946 | component.py:374 | MainThread         | **No ACK: 222/100 MAV_CMD_IMAGE_START_CAPTURE:2000\nINFO   | mavcom.GSTCamera   | 20.127 | gst_cam.py:541 | Thread-53 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:20_0011.jpg\nINFO   | mavcom.GSTCamera   | 20.129 | gst_cam.py:541 | Thread-54 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:20_0001.jpg\nINFO   | mavcom.GSTCamera   | 20.377 | gst_cam.py:541 | Thread-53 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:20_0012.jpg\nINFO   | mavcom.GSTCamera   | 20.379 | gst_cam.py:541 | Thread-54 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:20_0002.jpg\nINFO   | mavcom.GSTCamera   | 20.627 | gst_cam.py:541 | Thread-53 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:20_0013.jpg\nINFO   | mavcom.GSTCamera   | 20.629 | gst_cam.py:541 | Thread-54 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:20_0003.jpg\nINFO   | mavcom.GSTCamera   | 20.877 | gst_cam.py:541 | Thread-53 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:20_0014.jpg\nINFO   | mavcom.GSTCamera   | 20.879 | gst_cam.py:541 | Thread-54 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:20_0004.jpg\nINFO   | pygst.GstJpegEn | 20.881 | gst_tools.py:884 | Thread-53 (_launch | Sending EOS event, to trigger shutdown of pipeline\nINFO   | pygst.GstJpegEn | 20.882 | gst_tools.py:884 | Thread-54 (_launch | Sending EOS event, to trigger shutdown of pipeline\nWARNIN | mavcom.CameraClien | 20.967 | component.py:261 | MainThread         | **** ACK not handled MAV_CMD_IMAGE_START_CAPTURE:2000 from : 222/100 COMMAND_ACK {command : 2000, result : 0, progress : 0, result_param2 : 0, target_system : 111, target_component : 11}\nWARNIN | mavcom.CameraClien | 20.972 | component.py:263 | MainThread         |       command_id = MAV_CMD_IMAGE_START_CAPTURE msg.get_srcSystem() = 222, target_system = 222,  msg.get_srcComponent() = 100, target_component = 100\nWARNIN | mavcom.CameraClien | 20.972 | component.py:261 | MainThread         | **** ACK not handled MAV_CMD_IMAGE_START_CAPTURE:2000 from : 222/100 COMMAND_ACK {command : 2000, result : 0, progress : 0, result_param2 : 0, target_system : 111, target_component : 11}\nWARNIN | mavcom.CameraClien | 20.972 | component.py:263 | MainThread         |       command_id = MAV_CMD_IMAGE_START_CAPTURE msg.get_srcSystem() = 222, target_system = 222,  msg.get_srcComponent() = 100, target_component = 100\nINFO   | pygst.GstPipeli | 21.806 | gst_tools.py:306 | MainThread         | GstPipeline Shutdown\nINFO   | mavcom.GSTCamera   | 21.807 | gst_cam.py:485 | MainThread         | GSTCamera closed\nINFO   | mavcom.CameraServe | 22.631 | component.py:404 | MainThread         | CameraServer closed\nINFO   | mavcom.MAVCom      | 22.632 |  mavcom.py:442 | MainThread         | MAVCom  closed\nINFO   | mavcom.CameraClien | 23.629 | component.py:404 | MainThread         | CameraClient closed\nINFO   | mavcom.MAVCom      | 23.631 |  mavcom.py:442 | MainThread         | MAVCom  closed\nINFO   | pygst.GstPipeli | 23.691 | gst_tools.py:306 | MainThread         | GstPipeline Shutdown\n\n\nboot_time_str ='2023-10-15|12:07:37'\nJohn Doe                        \nHeartbeat received ret = (222, 100)\n1 MAVLINK_MSG_ID_CAMERA_INFORMATION CAMERA_INFORMATION {time_boot_ms : 158802, vendor_name : John Doe, model_name : Fake Camera, firmware_version : 1, focal_length : 8.0, sensor_size_h : 6.0, sensor_size_v : 4.0, resolution_h : 1920, resolution_v : 1080, lens_id : 0, flags : 0, cam_definition_version : 1, cam_definition_uri : http://example.com/camera_definition.xml, gimbal_device_id : 0}\n2 MAVLINK_MSG_ID_STORAGE_INFORMATION STORAGE_INFORMATION {time_boot_ms : 158904, storage_id : 0, storage_count : 1, status : 0, total_capacity : 100000000.0, used_capacity : 662987.0, available_capacity : 99337016.0, read_speed : 0.0, write_speed : 0.0, type : 0, name : }\n3 MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS CAMERA_CAPTURE_STATUS {time_boot_ms : 159906, image_status : 1, video_status : 0, image_interval : 0.20000000298023224, recording_time_ms : 0, available_capacity : 0.0, image_count : 10}\n4 MAVLINK_MSG_ID_CAMERA_SETTINGS CAMERA_SETTINGS {time_boot_ms : 160908, mode_id : 0, zoomLevel : 0.0, focusLevel : 0.0}\nret = False\nfile = '/2023-10-15|12:10:19_0000.jpg', img.shape = (480, 640, 3)\nfile = '/2023-10-15|12:10:20_0001.jpg', img.shape = (480, 640, 3)\nfile = '/2023-10-15|12:10:20_0002.jpg', img.shape = (480, 640, 3)\nfile = '/2023-10-15|12:10:20_0003.jpg', img.shape = (480, 640, 3)\nfile = '/2023-10-15|12:10:20_0004.jpg', img.shape = (480, 640, 3)\n5 MAVLINK_MSG_ID_STORAGE_INFORMATION STORAGE_INFORMATION {time_boot_ms : 163046, storage_id : 0, storage_count : 1, status : 0, total_capacity : 100000000.0, used_capacity : 116104.0, available_capacity : 99883896.0, read_speed : 0.0, write_speed : 0.0, type : 0, name : }",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Mavlink Camera Walkthrough"
    ]
  },
  {
    "objectID": "tutorials/mav_camera_walkthrough.html#introduction",
    "href": "tutorials/mav_camera_walkthrough.html#introduction",
    "title": "Mavlink Camera Walkthrough",
    "section": "",
    "text": "Here we create an entire mavlink connection with client at the GCS and server at the camera. The client and server are connected via a UDP connection or a radio modem serial connection The camera can be controlled via the client, and the video stream is sent from the server to the client. The client can also request camera information, storage information, etc from the server.\n\n\nfrom mavcom.mavlink import CameraClient, CameraServer,  MAVCom, GimbalClient, GimbalServer, mavutil, mavlink\n# from mavcom.mavlink.camera_client import CameraClient\n# from mavcom.mavlink.camera_server import  CameraServer\n# from mavcom.mavlink import Component, mavutil, mavlink, MAVCom\nfrom mavcom.utils import boot_time_str, read_camera_dict_from_toml, find_config_dir\nfrom mavcom.camera.gst_cam import GSTCamera    # fake camera for testing\nfrom gstreamer import  GstPipeline\nimport gstreamer.utils as gst_utils\nfrom mavcom.logging import LogLevels\nfrom pathlib import Path\nimport cv2\n\nCreate a CameraClient and CameraServer\n\nMAV_TYPE_GCS = mavutil.mavlink.MAV_TYPE_GCS\nMAV_TYPE_CAMERA = mavutil.mavlink.MAV_TYPE_CAMERA\n\nCreate a gstreamer pipelene to display the received video\nCreate Pysical camera object, here either CV2Camera or GSTCamera The toml file contains the camera parameters, such as resolution, framerate, etc and also the gstreamer pipeline command to create the video streams.\n\ncam_gst_1 = GSTCamera(camera_dict=read_camera_dict_from_toml(find_config_dir() / \"test_camera_info.toml\"))\n# cam_cv2_1 = CV2Camera(camera_dict=read_camera_dict_from_toml(find_config_dir() / \"test_camera_info.toml\"))\n\nINFO   | mavcom.GSTCamera   | 38.075 | gst_cam.py:317 | MainThread         | GSTCamera Started\nINFO   | pygst.GstPipeli | 38.086 | gst_tools.py:223 | MainThread         | Starting GstPipeline: videotestsrc  ! video/x-raw,width=1920,height=1080,framerate=30/1 ! tee name=t t. ! queue ! autovideosink t. ! queue leaky=2 ! intervideosink channel=channel_0 t. ! queue leaky=2 ! intervideosink channel=channel_1 t. ! queue leaky=2 ! videoconvert ! videorate drop-only=true ! intervideosink channel=channel_2 \n\n\nJohn Doe                        \n\n\n\nSINK_PIPELINE = gst_utils.to_gst_string([\n            'udpsrc port=5000 ! application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96',\n            'rtph264depay ! avdec_h264',\n            'fpsdisplaysink',\n            # 'autovideosink',\n        ])\n\nrcv_pipeline = GstPipeline(SINK_PIPELINE)     # Create a Gstreamer pipeline to display the received video on fpsdisplaysink\n\nCreate the client mavlink connection, this is mounted on the GCS\n\n# assert False\n\n\n# for the client, we use the udpin connection, you can use serial as an option i.e \"/dev/ttyACM0\", \"/dev/ttyUSB0\"\nclient = MAVCom(\"udpin:localhost:14445\", source_system=111, loglevel=LogLevels.INFO)\n\nINFO   | mavcom.MAVCom      | 38.254 |  mavcom.py:393 | Thread-5 (listen)  | MAVLink Mav2: True, source_system: 111\n\n\nCreate the server mavlink connection, this is mounted on the UAV companion computer\n\n# for the server, we use the udpout connection, you can use serial as an option  \"/dev/ttyUSB0\"\nserver = MAVCom(\"udpout:localhost:14445\", source_system=222)\n\nINFO   | mavcom.MAVCom      | 38.365 |  mavcom.py:393 | Thread-6 (listen)  | MAVLink Mav2: True, source_system: 222\n\n\nAdd the camera client to the client mavlink connection\n\ncam = client.add_component(CameraClient(mav_type=mavlink.MAV_TYPE_GCS, source_component=11))\n\nINFO   | mavcom.CameraClien | 38.404 | component.py:135 | MainThread         | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\n\n\nAdd the camera server to the server mavlink connection\n\nserver.add_component(CameraServer(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=mavlink.MAV_COMP_ID_CAMERA, camera=cam_gst_1))\n\nINFO   | mavcom.CameraServe | 38.418 | component.py:135 | MainThread         | Component Started self.source_component = 100, self.mav_type = 30, self.source_system = 222\n\n\n&lt;CameraServer&gt;\n\n\nWait for the heartbeat from the camera server\n\nasync def doit():\n    ret = await cam.wait_heartbeat(remote_mav_type=mavlink.MAV_TYPE_CAMERA)\n    print(f\"Heartbeat received {ret = }\")\nawait doit()\n\nHeartbeat received ret = (222, 100)\n\n\nSet the target system and component for the camera client and request camera information, storage information, camera capture status, and camera settings\n\nasync def doit():\n    msg = await cam.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_INFORMATION, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n    print (f\"1 MAVLINK_MSG_ID_CAMERA_INFORMATION {msg }\")\n    msg = await cam.request_message(mavlink.MAVLINK_MSG_ID_STORAGE_INFORMATION, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n    print (f\"2 MAVLINK_MSG_ID_STORAGE_INFORMATION {msg }\")\n    msg = await cam.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n    print (f\"3 MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS {msg }\")\n    msg = await cam.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_SETTINGS, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n    print (f\"4 MAVLINK_MSG_ID_CAMERA_SETTINGS {msg }\")\nawait doit()\n\n1 MAVLINK_MSG_ID_CAMERA_INFORMATION CAMERA_INFORMATION {time_boot_ms : 520, vendor_name : John Doe, model_name : Fake Camera, firmware_version : 1, focal_length : 8.0, sensor_size_h : 6.0, sensor_size_v : 4.0, resolution_h : 1920, resolution_v : 1080, lens_id : 0, flags : 0, cam_definition_version : 1, cam_definition_uri : http://example.com/camera_definition.xml, gimbal_device_id : 0}\n2 MAVLINK_MSG_ID_STORAGE_INFORMATION STORAGE_INFORMATION {time_boot_ms : 621, storage_id : 0, storage_count : 1, status : 0, total_capacity : 100000000.0, used_capacity : 0.0, available_capacity : 100000000.0, read_speed : 0.0, write_speed : 0.0, type : 0, name : }\n3 MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS CAMERA_CAPTURE_STATUS {time_boot_ms : 722, image_status : 0, video_status : 0, image_interval : 0.0, recording_time_ms : 0, available_capacity : 0.0, image_count : 0}\n4 MAVLINK_MSG_ID_CAMERA_SETTINGS CAMERA_SETTINGS {time_boot_ms : 824, mode_id : 0, zoomLevel : 0.0, focusLevel : 0.0}\n\n\nStart an image capture seqeunce, and display the images as they arrive\n\n# cam.image_start_capture(interval=0.1, count=10)\n# while cam_gst_1.capture_thread.is_alive():\n#     if cam_gst_1.last_image is not None:\n#         cv2.imshow('gst_src', cam_gst_1.last_image)\n#         cam_gst_1.last_image = None\n#     cv2.waitKey(10)\n\nAssertionError: call set_target(target_system, target_component) first\n\n\nShutdown the receive pipeline and close the mavlink connections\n\nrcv_pipeline.shutdown()\nclient.close()\nserver.close()\ncv2.destroyAllWindows()\n\nPerform the same test, but with the CV2Camera all in one cell\n\nfrom mavcom.utils.display import show_image\nfrom mavcom.logging import LogLevels\n\nfrom mavcom.mavlink import CameraClient, CameraServer,  MAVCom, GimbalClient, GimbalServer, mavutil, mavlink\nfrom mavcom.utils.general import boot_time_str, With, read_camera_dict_from_toml, find_config_dir\n\nfrom mavcom.camera.gst_cam import GSTCamera\nfrom gstreamer import GstPipeline, Gst, GstContext, GstPipes\nimport gstreamer.utils as gst_utils\nimport cv2\nimport time\nfrom pathlib import Path\nimport asyncio\n\nSINK_PIPELINE = gst_utils.to_gst_string([\n            'udpsrc port=5000 ! application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96',\n            'rtph264depay ! avdec_h264',\n            'fpsdisplaysink',\n            # 'autovideosink',\n        ])\ncon1, con2 = \"udpin:localhost:14445\", \"udpout:localhost:14445\"\n# con1, con2 = \"/dev/ttyACM0\", \"/dev/ttyUSB0\"\n\nprint (f\"{boot_time_str =}\")\n\ncam_uav = GSTCamera(camera_dict=read_camera_dict_from_toml(find_config_dir() / \"test_camera_info.toml\"))\n# cam_uav = CV2Camera(camera_dict=read_camera_dict_from_toml(find_config_dir() / \"test_camera_info.toml\"))\n\nasync def doit ():\n    # with GstContext():  # GST main loop in thread\n    with GstContext(), GstPipeline(SINK_PIPELINE):     # Create a Gstreamer pipeline to display the received video on fpsdisplaysink\n        with MAVCom(con1, source_system=111) as client:\n            with MAVCom(con2, source_system=222) as server:\n                gcs = client.add_component(CameraClient(mav_type=mavlink.MAV_TYPE_GCS, source_component=11))\n                server.add_component(CameraServer(camera=cam_uav, source_component=mavlink.MAV_COMP_ID_CAMERA))\n                # server.add_component(CameraServer(mav_type=MAV_TYPE_CAMERA, source_component=22, camera=None, debug=False))\n    \n                ret = await gcs.wait_heartbeat(remote_mav_type=mavlink.MAV_TYPE_CAMERA)\n                print(f\"Heartbeat received {ret = }\")\n                time.sleep(0.1)\n                msg = await gcs.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_INFORMATION, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n                print (f\"1 MAVLINK_MSG_ID_CAMERA_INFORMATION {msg }\")\n                msg = await gcs.request_message(mavlink.MAVLINK_MSG_ID_STORAGE_INFORMATION, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n                print (f\"2 MAVLINK_MSG_ID_STORAGE_INFORMATION {msg }\")\n                msg = await gcs.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n                print (f\"3 MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS {msg }\")\n                msg = await gcs.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_SETTINGS, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n                print (f\"4 MAVLINK_MSG_ID_CAMERA_SETTINGS {msg }\")\n    \n                ret = await gcs.image_start_capture(222, mavlink.MAV_COMP_ID_CAMERA, interval=0.2, count=5)\n                print(f\"{ret = }\")\n                \n                time.sleep(1)\n                for file in cam_mavcom.list_files():\n                    if file.endswith(\".jpg\"):\n                        img = cam_mavcom.load_image_from_memoryfs(file)\n                        print (f\"{file = }, {img.shape = }\")\n\n                lastimg = img\n                show_image(lastimg, rgb2bgr=True)\n                # start = time.time()\n                msg = await gcs.request_message(mavlink.MAVLINK_MSG_ID_STORAGE_INFORMATION, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n                print(f\"5 MAVLINK_MSG_ID_STORAGE_INFORMATION {msg}\")\n                # time.sleep(5)\n\n    \nawait doit()\n\nINFO   | mavcom.GSTCamera   | 16.334 | gst_cam.py:317 | MainThread         | GSTCamera Started\nINFO   | pygst.GstPipeli | 16.405 | gst_tools.py:223 | MainThread         | Starting GstPipeline: videotestsrc  ! video/x-raw,width=1920,height=1080,framerate=30/1 ! tee name=t t. ! queue ! autovideosink t. ! queue leaky=2 ! intervideosink channel=channel_0 t. ! queue leaky=2 ! intervideosink channel=channel_1 t. ! queue leaky=2 ! videoconvert ! videorate drop-only=true ! intervideosink channel=channel_2 \nINFO   | pygst.GstPipeli | 16.416 | gst_tools.py:223 | MainThread         | Starting GstPipeline: udpsrc port=5000 ! application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96 ! rtph264depay ! avdec_h264 ! fpsdisplaysink\nINFO   | mavcom.MAVCom      | 16.518 |  mavcom.py:393 | Thread-47 (listen) | MAVLink Mav2: True, source_system: 111\nINFO   | mavcom.MAVCom      | 16.620 |  mavcom.py:393 | Thread-48 (listen) | MAVLink Mav2: True, source_system: 222\nINFO   | mavcom.CameraClien | 16.622 | component.py:135 | MainThread         | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\nINFO   | mavcom.CameraServe | 16.624 | component.py:135 | MainThread         | Component Started self.source_component = 100, self.mav_type = 30, self.source_system = 222\nWARNIN | mavcom.CameraClien | 19.835 | component.py:261 | MainThread         | **** ACK not handled MAV_CMD_REQUEST_MESSAGE:512 from : 222/100 COMMAND_ACK {command : 512, result : 0, progress : 0, result_param2 : 0, target_system : 111, target_component : 11}\nWARNIN | mavcom.CameraClien | 19.837 | component.py:263 | MainThread         |       command_id = MAV_CMD_REQUEST_MESSAGE msg.get_srcSystem() = 222, target_system = 222,  msg.get_srcComponent() = 100, target_component = 100\nWARNIN | mavcom.CameraClien | 19.838 | component.py:261 | MainThread         | **** ACK not handled MAV_CMD_REQUEST_MESSAGE:512 from : 222/100 COMMAND_ACK {command : 512, result : 0, progress : 0, result_param2 : 0, target_system : 111, target_component : 11}\nWARNIN | mavcom.CameraClien | 19.839 | component.py:263 | MainThread         |       command_id = MAV_CMD_REQUEST_MESSAGE msg.get_srcSystem() = 222, target_system = 222,  msg.get_srcComponent() = 100, target_component = 100\nWARNIN | mavcom.CameraClien | 19.841 | component.py:261 | MainThread         | **** ACK not handled MAV_CMD_REQUEST_MESSAGE:512 from : 222/100 COMMAND_ACK {command : 512, result : 0, progress : 0, result_param2 : 0, target_system : 111, target_component : 11}\nWARNIN | mavcom.CameraClien | 19.842 | component.py:263 | MainThread         |       command_id = MAV_CMD_REQUEST_MESSAGE msg.get_srcSystem() = 222, target_system = 222,  msg.get_srcComponent() = 100, target_component = 100\nWARNIN | mavcom.CameraClien | 19.843 | component.py:261 | MainThread         | **** ACK not handled MAV_CMD_REQUEST_MESSAGE:512 from : 222/100 COMMAND_ACK {command : 512, result : 0, progress : 0, result_param2 : 0, target_system : 111, target_component : 11}\nWARNIN | mavcom.CameraClien | 19.845 | component.py:263 | MainThread         |       command_id = MAV_CMD_REQUEST_MESSAGE msg.get_srcSystem() = 222, target_system = 222,  msg.get_srcComponent() = 100, target_component = 100\nINFO   | pygst.GstJpegEn | 19.847 | gst_tools.py:223 | Thread-10 (_t_list | Starting GstJpegEnc: intervideosrc channel=channel_1   ! videoconvert ! videoscale ! video/x-raw,width=640,height=480,framerate=4/1 ! queue ! jpegenc quality=85 ! appsink name=mysink emit-signals=True max-buffers=1 drop=True\nINFO   | pygst.GstJpegEn | 19.847 | gst_tools.py:223 | Thread-52 (_t_list | Starting GstJpegEnc: intervideosrc channel=channel_1   ! videoconvert ! videoscale ! video/x-raw,width=640,height=480,framerate=4/1 ! queue ! jpegenc quality=85 ! appsink name=mysink emit-signals=True max-buffers=1 drop=True\nINFO   | mavcom.GSTCamera   | 19.877 | gst_cam.py:541 | Thread-53 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:19_0010.jpg\nINFO   | mavcom.GSTCamera   | 19.878 | gst_cam.py:541 | Thread-54 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:19_0000.jpg\nWARNIN | mavcom.CameraClien | 19.946 | component.py:374 | MainThread         | **No ACK: 222/100 MAV_CMD_IMAGE_START_CAPTURE:2000\nINFO   | mavcom.GSTCamera   | 20.127 | gst_cam.py:541 | Thread-53 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:20_0011.jpg\nINFO   | mavcom.GSTCamera   | 20.129 | gst_cam.py:541 | Thread-54 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:20_0001.jpg\nINFO   | mavcom.GSTCamera   | 20.377 | gst_cam.py:541 | Thread-53 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:20_0012.jpg\nINFO   | mavcom.GSTCamera   | 20.379 | gst_cam.py:541 | Thread-54 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:20_0002.jpg\nINFO   | mavcom.GSTCamera   | 20.627 | gst_cam.py:541 | Thread-53 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:20_0013.jpg\nINFO   | mavcom.GSTCamera   | 20.629 | gst_cam.py:541 | Thread-54 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:20_0003.jpg\nINFO   | mavcom.GSTCamera   | 20.877 | gst_cam.py:541 | Thread-53 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:20_0014.jpg\nINFO   | mavcom.GSTCamera   | 20.879 | gst_cam.py:541 | Thread-54 (_launch | Image saved to memory filesystem with name: 2023-10-15|12:10:20_0004.jpg\nINFO   | pygst.GstJpegEn | 20.881 | gst_tools.py:884 | Thread-53 (_launch | Sending EOS event, to trigger shutdown of pipeline\nINFO   | pygst.GstJpegEn | 20.882 | gst_tools.py:884 | Thread-54 (_launch | Sending EOS event, to trigger shutdown of pipeline\nWARNIN | mavcom.CameraClien | 20.967 | component.py:261 | MainThread         | **** ACK not handled MAV_CMD_IMAGE_START_CAPTURE:2000 from : 222/100 COMMAND_ACK {command : 2000, result : 0, progress : 0, result_param2 : 0, target_system : 111, target_component : 11}\nWARNIN | mavcom.CameraClien | 20.972 | component.py:263 | MainThread         |       command_id = MAV_CMD_IMAGE_START_CAPTURE msg.get_srcSystem() = 222, target_system = 222,  msg.get_srcComponent() = 100, target_component = 100\nWARNIN | mavcom.CameraClien | 20.972 | component.py:261 | MainThread         | **** ACK not handled MAV_CMD_IMAGE_START_CAPTURE:2000 from : 222/100 COMMAND_ACK {command : 2000, result : 0, progress : 0, result_param2 : 0, target_system : 111, target_component : 11}\nWARNIN | mavcom.CameraClien | 20.972 | component.py:263 | MainThread         |       command_id = MAV_CMD_IMAGE_START_CAPTURE msg.get_srcSystem() = 222, target_system = 222,  msg.get_srcComponent() = 100, target_component = 100\nINFO   | pygst.GstPipeli | 21.806 | gst_tools.py:306 | MainThread         | GstPipeline Shutdown\nINFO   | mavcom.GSTCamera   | 21.807 | gst_cam.py:485 | MainThread         | GSTCamera closed\nINFO   | mavcom.CameraServe | 22.631 | component.py:404 | MainThread         | CameraServer closed\nINFO   | mavcom.MAVCom      | 22.632 |  mavcom.py:442 | MainThread         | MAVCom  closed\nINFO   | mavcom.CameraClien | 23.629 | component.py:404 | MainThread         | CameraClient closed\nINFO   | mavcom.MAVCom      | 23.631 |  mavcom.py:442 | MainThread         | MAVCom  closed\nINFO   | pygst.GstPipeli | 23.691 | gst_tools.py:306 | MainThread         | GstPipeline Shutdown\n\n\nboot_time_str ='2023-10-15|12:07:37'\nJohn Doe                        \nHeartbeat received ret = (222, 100)\n1 MAVLINK_MSG_ID_CAMERA_INFORMATION CAMERA_INFORMATION {time_boot_ms : 158802, vendor_name : John Doe, model_name : Fake Camera, firmware_version : 1, focal_length : 8.0, sensor_size_h : 6.0, sensor_size_v : 4.0, resolution_h : 1920, resolution_v : 1080, lens_id : 0, flags : 0, cam_definition_version : 1, cam_definition_uri : http://example.com/camera_definition.xml, gimbal_device_id : 0}\n2 MAVLINK_MSG_ID_STORAGE_INFORMATION STORAGE_INFORMATION {time_boot_ms : 158904, storage_id : 0, storage_count : 1, status : 0, total_capacity : 100000000.0, used_capacity : 662987.0, available_capacity : 99337016.0, read_speed : 0.0, write_speed : 0.0, type : 0, name : }\n3 MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS CAMERA_CAPTURE_STATUS {time_boot_ms : 159906, image_status : 1, video_status : 0, image_interval : 0.20000000298023224, recording_time_ms : 0, available_capacity : 0.0, image_count : 10}\n4 MAVLINK_MSG_ID_CAMERA_SETTINGS CAMERA_SETTINGS {time_boot_ms : 160908, mode_id : 0, zoomLevel : 0.0, focusLevel : 0.0}\nret = False\nfile = '/2023-10-15|12:10:19_0000.jpg', img.shape = (480, 640, 3)\nfile = '/2023-10-15|12:10:20_0001.jpg', img.shape = (480, 640, 3)\nfile = '/2023-10-15|12:10:20_0002.jpg', img.shape = (480, 640, 3)\nfile = '/2023-10-15|12:10:20_0003.jpg', img.shape = (480, 640, 3)\nfile = '/2023-10-15|12:10:20_0004.jpg', img.shape = (480, 640, 3)\n5 MAVLINK_MSG_ID_STORAGE_INFORMATION STORAGE_INFORMATION {time_boot_ms : 163046, storage_id : 0, storage_count : 1, status : 0, total_capacity : 100000000.0, used_capacity : 116104.0, available_capacity : 99883896.0, read_speed : 0.0, write_speed : 0.0, type : 0, name : }",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Mavlink Camera Walkthrough"
    ]
  },
  {
    "objectID": "tutorials/mavlink_doc&debug.html",
    "href": "tutorials/mavlink_doc&debug.html",
    "title": "Mavlink Documentation and debugging",
    "section": "",
    "text": "#   # | default_exp mavlink.cam_base\n\n\nimport mavcom.logging\n#| hide\n\nMavlink Routing https://ardupilot.org/dev/docs/mavlink-routing-in-ardupilot.html Each message contains a System ID and Component ID field to specify where the message came from. In addition some messages (including SET_POSITION_TARGET_GLOBAL_INT) include target_system and target_component fields to allow specifying which system/component should execute the command. \nhttps://mavlink.io/en/guide/routing.html A MAVLINK network is made up of systems (vehicles, ground stations, antenna trackers, etc.), which may be composed from one or more components (autopilot, camera, servos, etc.).\nEach system has a network-unique system id, and each component has a system-unique component id that can be used for addressing/routing:\nThe system id has a value between 1 and 255. The default autopilot system id is usually 1. Users should allocate unique increasing id values when adding new autopilots to a network. GCS systems and developer APIs typically use an ID at the top of the numeric range to reduce ID clashes (e.g. 255). Often their system ID is configurable to allow multi-GCS systems. The component id is allocated by type and number from MAV_COMPONENT. Messages can be intended for all systems, specific systems, all components in a system, or specific components within a system. The protocol defines two 8-bit fields that can (optionally) be specified in the message payload to indicate where the message should be sent/routed. If the ids are omitted or set to zero then the message is considered a broadcast (intended for all systems/components).\ntarget_system: System that should execute the command target_component: Component that should execute the command (requires target_system). MAVLink components are expected to process messages that have a matching system/component id and broadcast messages. They are expected to route/resend messages that are intended for other (or all) recipients to other active channels (i.e. MAVLink systems may be connected across different transports, connected by a MAVLink system that routes the messages). Broadcast messages are forwarded to all channels that haven’t seen the message. Addressed messages are resent on a new channel iff the system has previously seen a message from the target on that channel (messages are not resent if the addressee is not known or is on the original/incoming channel).\n\nMavlink Camera Control via mavproxy serial port and UDP\n*** First Run Mavproxy***\nmavproxy.py --master udpin:localhost:14445 --out udpout:localhost:14550\nmavproxy.py --master=/dev/ttyACM1 --baudrate 57600 --out udpout:localhost:14445\n\n\nMavlink Camera Control via mavproxy serial port and UDP\nThe camera control messages are sent to the camera server via mavproxy. The camera server is running on the companion computer and the manager on the GCS PC. We connect via UDP and wait for the camera heartbeat. Then start and stop the cam_1 (component 22) streaming\n\nimport time\n\nfrom fastcore.test import *\nfrom mavcom.mavlink import CameraClient, CameraServer, MAVCom, mavlink\nfrom mavcom.cameras.gst_cam import GSTCamera\nfrom mavcom.utils import helpers\nfrom mavcom.utils.general import boot_time_str, toml_load, config_dir\n\n\nasync def main():\n    with MAVCom(\"udpin:localhost:14445\", source_system=111, ) as gcs_mavlink:   # ground control station mavlink\n        with MAVCom(\"udpout:localhost:14445\", source_system=222, ) as drone_mavlink: # drone mavlink\n            # connect to the cameras manager\n            gcs_cam: CameraClient = gcs_mavlink.add_component(CameraClient(mav_type=mavlink.MAV_TYPE_GCS, source_component=11))\n            \n            # add UAV cameras\n            cam_1 = GSTCamera(camera_dict=toml_load(config_dir() / \"test_cam_0.toml\"), loglevel=10)\n            cam_2 = GSTCamera(camera_dict=toml_load(config_dir() / \"test_cam_1.toml\"))\n\n            # connect cameras to mavlink\n            drone_mavlink.add_component(CameraServer(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=22, camera=cam_1,))\n            drone_mavlink.add_component(CameraServer(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=23, camera=cam_2))\n            \n            # wait for heartbeat signal from the drone\n            ret = await gcs_cam.wait_heartbeat(target_system=222, target_component=22, timeout=1)\n            print(f\"Heartbeat {ret = }\")\n            time.sleep(0.1)\n            \n            await gcs_cam.video_start_streaming(222, 22, )\n            time.sleep(2)\n            await gcs_cam.video_stop_streaming(222, 22, )\n            \nawait main()  \n            # client.master.wait_heartbeat()\n            \n        #     client.trigger_camera(2)\n        #     client.trigger_camera(2)\n        # \n        # \n        # print(f\"client.num_commands_sent: {client.num_commands_sent}\")\n        # print(f\"server.num_commands_received: {server.num_commands_received}\")\n        # print(f\"client.num_acks_received: {client.num_acks_received}\")\n        # \n        # print(f\"server msgs: {server.message_cnts}\")\n        # print(f\"client msgs: {client.message_cnts}\")\n        # \n        # test_eq(client.num_commands_sent, server.num_commands_received)\n        # test_eq(client.num_acks_received, server.num_commands_received)\n\nINFO |30.150| mavcom.MAVCom      | mavcom.py :378 | Thread-77  | MainProces | MAVLink Mav2: True, source_system: 111\nINFO |30.251| mavcom.MAVCom      | mavcom.py :378 | Thread-78  | MainProces | MAVLink Mav2: True, source_system: 222\nINFO |30.253| mavcom.CameraClien | component.:117 | MainThread | MainProces | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\nINFO |30.257| mavcom.GSTCamera   | gst_cam.py:351 | MainThread | MainProces | GSTCamera Started\nINFO |30.269| pygst.GstPipeli | gst_tools.:225 | MainThread | MainProces | Starting GstPipeline: videotestsrc pattern=ball is-live=true ! timeoverlay ! textoverlay text=\"Front\" valignment=top halignment=right font-desc=\"Sans, 18\" shaded-background=true ! capsfilter caps=video/x-raw,format=RGB,width=800,height=600,framerate=30/1 ! tee name=t t. ! queue ! videoscale  ! capsfilter caps=video/x-raw,format=RGB,width=400,height=300 ! videoconvert ! autovideosink t. ! queue leaky=2 ! intervideosink channel=channel_0  sync=false t. ! queue leaky=2 ! intervideosink channel=channel_1  sync=false t. ! interpipesink name=cam_0 \nDEBUG|30.269| pygst.GstPipeli | gst_tools.:229 | MainThread | MainProces | GstPipeline Setting pipeline state to PLAYING ... \nDEBUG|30.270| pygst.GstPipeli | gst_tools.:231 | MainThread | MainProces | GstPipeline Pipeline state set to PLAYING \nINFO |30.272| pygst.GstStream | gst_tools.:225 | MainThread | MainProces | Starting GstStreamUDP: interpipesrc listen-to=cam_0 is-live=true allow-renegotiation=true format=time ! valve name=myvalve drop=False  ! queue ! videoconvert ! x264enc tune=zerolatency noise-reduction=10000 bitrate=2048 speed-preset=superfast ! rtph264pay ! udpsink host=127.0.0.1 port=5000 sync=true\nDEBUG|30.273| pygst.GstStream | gst_tools.:229 | MainThread | MainProces | GstStreamUDP Setting pipeline state to PLAYING ... \nDEBUG|30.273| pygst.GstStream | gst_tools.:231 | MainThread | MainProces | GstStreamUDP Pipeline state set to PLAYING \nINFO |30.274| mavcom.GSTCamera   | gst_cam.py:654 | MainThread | MainProces | Video streaming pipeline \"gstreamer_udpsink\" created on port 5000\nDEBUG|30.374| pygst.GstStream | gst_tools.:265 | MainThread | MainProces | Valve \"myvalve\" state set to True\nINFO |30.375| mavcom.GSTCamera   | gst_cam.py:668 | MainThread | MainProces | Video streaming \"gstreamer_udpsink\" stopped (paused) on port 5000\nINFO |30.378| mavcom.GSTCamera   | gst_cam.py:351 | MainThread | MainProces | GSTCamera Started\nINFO |30.390| pygst.GstPipeli | gst_tools.:225 | MainThread | MainProces | Starting GstPipeline: videotestsrc pattern=ball is-live=true ! timeoverlay ! textoverlay text=\"Left\" valignment=top halignment=right font-desc=\"Sans, 18\" shaded-background=true ! capsfilter caps=video/x-raw,format=RGB,width=800,height=600,framerate=30/1 ! tee name=t t. ! queue ! videoscale  ! capsfilter caps=video/x-raw,format=RGB,width=400,height=300 ! videoconvert ! autovideosink t. ! queue leaky=2 ! intervideosink channel=channel_0  sync=false t. ! queue leaky=2 ! intervideosink channel=channel_1  sync=false t. ! interpipesink name=cam_1 \nINFO |30.393| pygst.GstStream | gst_tools.:225 | MainThread | MainProces | Starting GstStreamUDP: interpipesrc listen-to=cam_1 is-live=true allow-renegotiation=true format=time ! valve name=myvalve drop=False  ! queue ! videoconvert ! x264enc tune=zerolatency noise-reduction=10000 bitrate=2048 speed-preset=superfast ! rtph264pay ! udpsink host=127.0.0.1 port=5001 sync=true\nINFO |30.394| mavcom.GSTCamera   | gst_cam.py:654 | MainThread | MainProces | Video streaming pipeline \"gstreamer_udpsink\" created on port 5001\nINFO |30.495| mavcom.GSTCamera   | gst_cam.py:668 | MainThread | MainProces | Video streaming \"gstreamer_udpsink\" stopped (paused) on port 5001\nINFO |30.496| mavcom.CameraServe | component.:117 | MainThread | MainProces | Component Started self.source_component = 22, self.mav_type = 30, self.source_system = 222\nINFO |30.498| mavcom.CameraServe | component.:117 | MainThread | MainProces | Component Started self.source_component = 23, self.mav_type = 30, self.source_system = 222\nINFO |30.600| mavcom.GSTCamera   | gst_cam.py:662 | Thread-84  | MainProces | Video streaming \"gstreamer_udpsink\" resumed on port 5000\nINFO |30.601| mavcom.CameraServe | camera_ser:338 | Thread-84  | MainProces | Started video streaming: streamId = 0.0\nINFO |32.703| mavcom.GSTCamera   | gst_cam.py:668 | Thread-84  | MainProces | Video streaming \"gstreamer_udpsink\" stopped (paused) on port 5000\nINFO |33.407| pygst.GstPipeli | gst_tools.:335 | MainThread | MainProces | GstPipeline Shutdown\nINFO |33.409| mavcom.GSTCamera   | gst_cam.py:513 | MainThread | MainProces | GSTCamera closed\nINFO |33.580| pygst.GstStream | gst_tools.:335 | MainThread | MainProces | GstStreamUDP Shutdown\nINFO |33.582| mavcom.GSTCamera   | gst_cam.py:707 | MainThread | MainProces | !!!!!! Closed \"gstreamer_udpsink\" \nINFO |33.583| mavcom.CameraServe | component.:388 | MainThread | MainProces | CameraServer closed (not waiting for _t_heartbeat daemon thread)\nINFO |33.690| pygst.GstPipeli | gst_tools.:335 | MainThread | MainProces | GstPipeline Shutdown\nINFO |33.691| mavcom.GSTCamera   | gst_cam.py:513 | MainThread | MainProces | GSTCamera closed\nINFO |33.801| pygst.GstStream | gst_tools.:335 | MainThread | MainProces | GstStreamUDP Shutdown\nINFO |33.803| mavcom.GSTCamera   | gst_cam.py:707 | MainThread | MainProces | !!!!!! Closed \"gstreamer_udpsink\" \nINFO |33.804| mavcom.CameraServe | component.:388 | MainThread | MainProces | CameraServer closed (not waiting for _t_heartbeat daemon thread)\nINFO |33.805| mavcom.MAVCom      | mavcom.py :427 | MainThread | MainProces | MAVCom  closed\nINFO |34.503| mavcom.CameraClien | component.:388 | MainThread | MainProces | CameraClient closed (not waiting for _t_heartbeat daemon thread)\nINFO |34.505| mavcom.MAVCom      | mavcom.py :427 | MainThread | MainProces | MAVCom  closed\n\n\nJohn Doe                        \nJohn Doe                        \nHeartbeat ret = (222, 22)\n\n\n\n\nDebugging with wireshark\nsee Parsing MAVLink in Wireshark Instasll wireshark\nsee How to install and use wireshark- on ubuntu\nsudo apt-get install wireshark\nsudo apt update\nsudo apt install wireshark\nwireshark\nIf you face any error during installation or running Wireshark like Wireshark xdg_runtime_dir not set then open the terminal and run this command and click YES to the message box\nsudo dpkg-reconfigure wireshark-common\nThe above can be debugged with wireshark using the filter\nmavlink_proto.sysid!=255 && not icmp\nmavlink_proto.sysid!=255 && mavlink_proto.sysid!=1 && not icmp\n\nWireshark on Ubuntu see Parsing MAVLink in Wireshark\nWireshark has implemented Privilege Separation which means that the Wireshark GUI (or the tshark CLI) can run as a normal user while the dumpcap capture utility runs as root. This can be achieved by installing dumpcap setuid root. The advantage of this solution is that while dumpcap is run as root the vast majority of Wireshark’s code is run as a normal user (where it can do much less damage). https://wikileaks.org/ciav7p1/cms/page_16384719.html - Install Wireshark sudo apt-get install wireshark - Create a wireshark group sudo groupadd wireshark - Add your username to the wireshark group sudo usermod -a -G wireshark YOUR_USERNAME - Change the group ownership of the file dumpcap to wireshark sudo chgrp wireshark /usr/bin/dumpcap - Chage the mode of the file dumpcap to allow execution by the group wireshark sudo chmod 750 /usr/bin/dumpcap - Grant capabilities with setcap sudo setcap cap_net_raw,cap_net_admin=eip /usr/bin/dumpcap - Verify the change sudo getcap /usr/bin/dumpcap - Reboot - sudo reboot now\nAlso see * https://wiki.wireshark.org/CaptureSetup/CapturePrivileges\nNote The last few lines of the plugin file specify the ports to be monitored. &gt; -- bind protocol dissector to port 14550 and 14580 &gt;&gt;local udp_dissector_table = DissectorTable.get(\"udp.port\") udp_dissector_table:add(14415, mavlink_proto) udp_dissector_table:add(14425, mavlink_proto) udp_dissector_table:add(14435, mavlink_proto) udp_dissector_table:add(14445, mavlink_proto) udp_dissector_table:add(14550, mavlink_proto) udp_dissector_table:add(14580, mavlink_proto) udp_dissector_table:add(18570, mavlink_proto)\nQGC can also be used to debug the communication\n\nEnable mavlink fowarding in QGC to localhost:14445\n\n\n\nSerial Port Connection\n\nConnection using a serial crossover cable or via pixhawk telemetry ports \nTelemetry 2 port on pixhawk is connected to the USB port on the companion computer using a serial crossover cable. 1. (red) VCC +5V 2. (?) TX (OUT) +3.3V 3. (?) RX (IN) +3.3V 4. (?) CTS +3.3V 5. (?) RTS +3.3V 6. (?) GND GND`\n\n\nFinding the correct serial ports\nCheck that if you are a member of that group: “dialout” group.\ngroups ${USER}\nIf not, add yourself to it and reboot or logout and login again.\nsudo usermod -a -G dialout $USER\nsudo reboot now\nCutecom is a GUI serial terminal program that can be used to test the serial ports.\nsudo apt-get install cutecom lrzsz\nRun Cutecom and select the correct serial port and baud rate. Note that the status bar showing Ardupilot Pihawk4, also check that it might be using 57600 baud rate.\ncutecom\n\n\n\n\nRunning PX4 SITL\nsee PX4 SITL Gazebo Simulation\nin the PX4 directory run make px4_sitl gz_x500\n*** Run Mavproxy*** mavproxy.py --master udpin:localhost:14445 --out udpout:localhost:14550 mavproxy.py --master=/dev/ttyACM1 --baudrate 57600 --out udpout:localhost:14445\nhttps://github.com/mavlink/MAVSDK/issues/1803\nSo I managed to change OpenHD in this regard. No idea why I had such a hard time wrapping my head around, but now it works the following: OpenHD binds port 127.0.0.1:14551 and listens on 127.0.0.1:14550 AND instead of using sendto() with a unbound port (which then in turn means the sender port can be anything) messages are sent with sendto() from the bound port (the same that is used for listening).\nSo messages from OpenHD to mavsdk go the following: OpenHD (out) via 127:0:0:1:14551 sent to 127:0:0:0:1:14550\nSo when mavsdk receives the first message, the sender address::port is 127:0:0:1:14551 and mavsdk can send the messages back to 127:0:0:1:14551.\nhttps://julianoes.com/ The ports are not symmetrical! QGC listens on local port 14550 and sends UDP packets back to wherever messages came from.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Mavlink Documentation and debugging"
    ]
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Click through to any of these tutorials to get started with UAV’s features.\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nAPI Walkthrough\n\n\nA step-by-step guide to using nbdev\n\n\n\n\nAirsim Walkthrough\n\n\nDocumentation for using Microsoft Airsim in a Jupyter notebook\n\n\n\n\nMavlink Camera Walkthrough\n\n\nDocumentation\n\n\n\n\nMavlink Documentation and debugging\n\n\nMavlink Documentaion and debugging with wireshark and QGC\n\n\n\n\ntemplate01\n\n\nbla bla bla\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Get Started",
      "Tutorials"
    ]
  },
  {
    "objectID": "tutorials/airsim_walkthrough.html",
    "href": "tutorials/airsim_walkthrough.html",
    "title": "Airsim Walkthrough",
    "section": "",
    "text": "# no export #| default_exp airsim\n\n\n# logging.basicConfig(format='%(asctime)-8s,%(msecs)-3d %(levelname)5s [%(filename)10s:%(lineno)3d] %(message)s',\n#                     datefmt='%H:%M:%S',\n#                     level=logging.INFO)  # Todo add this to params\n# logger = logging.getLogger(__name__)\n\n\nfrom mavcom.utils.display import *\nfrom mavcom.utils.sim_linux import *\nfrom mavcom.airsim.client import *\n# import mavcom.utils.sim_linux as sim\n\n\nAirsim Connection\n\n\n\nRunSim\n\n RunSim (name:str='Coastline', resx:int=800, resy:int=600,\n         windowed:str|None='windowed',\n         settings:str|pathlib.Path|None=None)\n\nRun the Airsim simulator\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nname\nstr\nCoastline\nname of the simulator environment\n\n\nresx\nint\n800\nwindow size x\n\n\nresy\nint\n600\nwindow size y\n\n\nwindowed\nstr | None\nwindowed\nwindowed or fullscreen\n\n\nsettings\nstr | Path | None\nNone\nsettings file\n\n\n\n\nrs = RunSim(\"AirSimNH\", settings=\"config/airsim_settings_high_res.json\")\n\nERROR|10.762| mavcom.RunSim      | sim_linux.: 73 | MainThread | MainProces | Settings file config/settings_high_res.json not found.\nINFO |10.763| mavcom.RunSim      | sim_linux.: 75 | MainThread | MainProces | Settings file None found.\n\n\nAirsim AirSimNH already running.\n\n\n\n\n\nAirSimClient\n\n AirSimClient (ip='', port:int=41451, timeout_value=3600)\n\nMultirotor Client for the Airsim simulator with higher level procedures\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nip\nstr\n\nrpc connection address\n\n\nport\nint\n41451\nrpc connection port\n\n\ntimeout_value\nint\n3600\ntimeout for client ping in seconds\n\n\n\n\nasc = AirSimClient()\n\nConnected!\nClient Ver:1 (Min Req: 1), Server Ver:1 (Min Req: 1)\n\n\n\n\nSimulator assets\nassets can be listed with rs.client.simListAssets() and placed within the environment with rs.place_asset(x,y,z,asset_name)\n\n\n\nVehicleClient.simListAssets\n\n VehicleClient.simListAssets ()\n\nLists all the assets present in the Asset Registry\nReturns: list[str]: Names of all the assets\n\nassets = asc.simListAssets()\nprint(f\"Assets: {assets}\")\n\nAssets: ['Sphere', 'Cone', 'Cylinder', 'SM_SkySphere', 'Garage_Door_01offset', 'Garage_Mech_01', 'Garage_Door_02offset', 'Garage_Half_Mech_01', 'Inner_Door_01', 'Hinge_01', 'Outer_Door_01', 'Fan_Blades_01', 'Fan_Base_01', 'Outer_Wall_Quart_Win_06', 'Veranda_01', 'Street_Sign_02', 'Street_Sign_01', 'Stop_Sign_02', 'Stop_Sign_01', 'Rock_01', 'Power_Line_Connector_01', 'Power_Line_Complete_01', 'Power_Line_Cable_Single_01', 'Power_Line_Cable_01_Spline', 'Power_Line_01', 'Path_01', 'Monument_01', 'Garden_Tressel_02', 'Garden_Tressel_01', 'Garden_Rocks_01', 'Garden_Chair_01', 'Fence_01', 'Drain_Pipe_02', 'Drain_Pipe_01', 'Car_01', 'bin_02', 'bin_01', 'Bench_01', 'Basketball_Hoop_01', 'Skateboard_01', 'Plug_Socket_01', 'Picture_Frame_01', 'Paint_Can_01', 'Mug_01', 'Light_Switch_01', 'Fridge_Alphabet_01', 'extractor_01', 'Dufflebag_01', 'Drinks_Can_07', 'Drinks_Can_06', 'Drinks_Can_05', 'Drinks_Can_04', 'Drinks_Can_03', 'Drinks_Can_01', 'Curtain_03', 'Curtain_02', 'Curtain_01', 'Book_01', 'Toilet_01', 'table_01', 'Sofa_02', 'Sofa_01', 'small_table_03', 'small_table_02', 'small_table_01', 'Sink_01', 'Shutters_01', 'Shelf_01', 'Pool_Table_01', 'Office_Desk_01', 'Kitchen_Unit_Sink_01', 'Kitchen_Unit_Corner_01', 'Kitchen_Unit_02', 'Kitchen_Unit_01', 'Kitchen_Splash_Tile_01', 'Kitchen_Cupboard_Fan_01', 'Kitchen_Cupboard_02', 'Fireplace_01', 'coffee_table_02', 'coffee_table_01', 'Chair_01', 'Bookcase_02', 'Bookcase_01', 'Bed_Double_02', 'Bed_Double_01', 'Tree_01', 'Oak_03', 'Leaves_01', 'Hedge_03', 'Hedge_02', 'Hedge_01', 'Grass_Large_01', 'Grass_01', 'Fir_01', 'Daisys_01', 'Birch_01', 'Tft_01', 'Tablet_01', 'Oven_01', 'Mouse_01', 'Lcd_01', 'Laptop_01', 'Lamp_01', 'Keyboard_01', 'Headphones_01', 'Gamepad_01', 'Fridge_01', 'fan_01', 'Desktop_01', 'BRPlayer_01', 'Wall_Low_Quart_01', 'Wall_Low_Half_01', 'Wall_Low_End_01', 'Wall_Low_8th_01', 'Wall_Low_01', 'Swimming_Pool_Steps_02', 'Swimming_Pool_Steps_01', 'Swimming_Pool_Floor_01', 'Swimming_Pool_Edge_01', 'Swimming_Pool_Curve_01', 'Stairs_Beam_Quart_01', 'Staircase_Extra_Banister_01', 'Staircase_03', 'Staircase_02', 'Staircase_01', 'Banister_Roof_Angle_01', 'Banister_End_01', 'Banister_01', 'Roof_Flat_Open_Apex_01', 'Roof_Flat_Open_01', 'Roof_Flat_01', 'Roof_Quart_Open_03', 'Roof_Quart_Open_01', 'Roof_Quart_Corner_01', 'Roof_Open_01', 'Roof_Middle_Half_Half_01', 'Roof_Middle_Half_01', 'Roof_Middle_Apex_02', 'Roof_Middle_Apex_01', 'Roof_Middle_01', 'Roof_Half_01', 'Roof_End_Thin_01', 'Roof_Edge_Half_Middle_01', 'Roof_Edge_End_02', 'Roof_Edge_End_01', 'Roof_Corner_02', 'Roof_Corner_01', 'Roof_Apex_Fill_01', 'Roof_01', 'Outer_Wall_Quart_Roof_02', 'Outer_Wall_Quart_Roof_01', 'Road_Drive_Opening_03New', 'Road_Drive_Opening_02New', 'Road_Corner_01', 'Road_4Way_01NEW', 'Road_3Way_01New', 'Road_01New', 'Porch_Pillar_01', 'Porch_Middle_01', 'Porch_Corner_01', 'Porch_Banister_Quart_01', 'Porch_Banister_8th_01', 'Outdoor_Steps_01', 'Structural_Support_01', 'Outer_Wall_Quart_Win_05', 'Outer_Wall_Quart_Win_04', 'Outer_Wall_Quart_Win_03', 'Outer_Wall_Quart_Win_02', 'Outer_Wall_quart_Win_01', 'Outer_Wall_Quart_Garage_01', 'Outer_Wall_Quart_Door_03', 'Outer_Wall_quart_door_02', 'Outer_Wall_Quart_Door_01', 'Outer_Wall_Quart_01', 'Outer_Wall_Half_Win_02', 'Outer_Wall_Half_Win_01', 'Outer_Wall_Half_Garage_02', 'Outer_Wall_Half_Garage_01', 'Outer_Wall_Half_Door_01', 'Outer_Wall_Half_Apex_01', 'Outer_Wall_Half_01', 'Outer_Wall_8th_Win_01', 'Outer_Wall_8th_Door_01', 'Outer_Wall_8th_01', 'Outer_Wall_16th_01', 'Outer_Wall_01', 'House_Base_Quart_01', 'Cladding_Edge_01', '9', '7', '6', '5', '3', '2', '1', 'Inner_Wall_Roof_01', 'Inner_Wall_Quart_plus_8th_01', 'Inner_Wall_Quart_Door_01', 'Inner_Wall_Quart_Arch_01', 'Inner_Wall_Quart_01', 'Inner_Wall_Half_Door_01', 'Inner_Wall_Half_Arch_01', 'Inner_Wall_Half_01', 'Inner_Wall_Close_Gap_01', 'Inner_Wall_8th_Door_01', 'Inner_Wall_8th_Arch_01', 'Inner_Wall_8th_01', 'Inner_Wall_16th_01', 'Outer_Wall_Quart_Floor_01', 'Outer_Wall_Quart_Base_01', 'Floor_Quart_01', 'Floor_Half_Stairs_01', 'Floor_Half_Half_01', 'Floor_Half_Basic_01', 'Floor_Half_01', 'Floor_Basic_01', 'Floor_8th__01', 'Floor_01', 'Driveway_Quart_01', 'Driveway_Half_01', 'Driveway_Edge_01', 'Driveway_8th_01', 'driveway_16th_Curve_02', 'driveway_16th_Curve_01', 'Driveway_16th_01', 'Driveway_01', 'Chimney_Top_01', 'Chimney_Roof_01', 'Chimney_Mid_01', 'Chimney_Base_02', 'Chimney_Base_01', 'Cube', 'Schoolbus_Small_FixedTransforms', 'boxtruck_WithHeadlights_boxtruck_fixedtransforms_LOD0', 'Vehicle_Police_ISM', 'Ambulance_Truck_FixedTransforms', 'BicycleMan', '009_SUV_ISM_NewMat', 'Saloon_ISM_NewMat', '006_Hatchback_ISM_NewMat', 'Plane', 'S_1_Unit_Plane', 'right_OculusTouch_v3Controller', 'left_OculusTouch_v3Controller', 'right_ValveIndexController', 'left_ValveIndexController', 'GoogleDaydreamController', 'HTCViveController', 'right_OculusTouchController', 'left_OculusTouchController', 'right_MicrosoftMixedRealityController', 'left_MicrosoftMixedRealityController', 'right_OculusTouch_v2Controller', 'left_OculusTouch_v2Controller', 'OculusGoController', 'MapleLeaf01', 'Quadrotor1', 'Propeller', 'BaseAnimalBP', 'Medium_House_Prefab_01', 'Car_Porch_Prefab_01', 'Small_House_Prefab_01', 'Garage_Door_BP2', 'Inner_Door_Swing_01', 'Outer_Door_Swing_01', 'Garage_Door_Half_BP', 'Outer_Door_BP', 'Stairs_Prefab_01', 'BP_Fan_01', 'DeerBothBP', 'RaccoonBP', 'AnimalAIController', 'DmgTypeBP_Environmental', 'BP_Sky_Sphere', 'MenuActor', 'BP_CameraDirector', 'BP_PIPCamera', 'BP_ComputerVisionPawn', 'BP_FlyingPawn', 'WeatherActor', 'SuvFrontWheel', 'SuvBackWheel', 'SuvCarPawn']\n\n\n\n\n\nAirSimClient.place_object\n\n AirSimClient.place_object (name:str, x:float, y:float, z:float,\n                            scale:float=1.0, physics_enabled:bool=False)\n\nPlace an object in the simulator First check to see if the asset it is based on exists\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nname\nstr\n\nasset name\n\n\nx\nfloat\n\nposition x\n\n\ny\nfloat\n\nposition y\n\n\nz\nfloat\n\nposition z\n\n\nscale\nfloat\n1.0\nscale\n\n\nphysics_enabled\nbool\nFalse\nphysics enabled\n\n\n\n\nasc.place_object(\"Sofa_02\", 5.0, 0.0, -1.0, scale=0.5 )\n\nThe sofa can be seen at the location with rs.client.simGetObjectPose(\"Sofa_02\") The sofa can be moved with rs.move_asset(x,y,z,asset_name)\n\n\n\nVehicleClient.simGetObjectPose\n\n VehicleClient.simGetObjectPose (object_name)\n\nThe position inside the returned Pose is in the world frame\nArgs: object_name (str): Object to get the Pose of\nReturns: Pose:\n\nasc.simGetObjectPose(\"Sofa_02\")\n\n&lt;Pose&gt; {   'orientation': &lt;Quaternionr&gt; {   'w_val': nan,\n    'x_val': nan,\n    'y_val': nan,\n    'z_val': nan},\n    'position': &lt;Vector3r&gt; {   'x_val': nan,\n    'y_val': nan,\n    'z_val': nan}}\n\n\n\n\n\nAirSimClient.get_image\n\n AirSimClient.get_image (camera_name:str='0', rgb2bgr:bool=False)\n\nGet an image from camera camera_name\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncamera_name\nstr\n0\ncamera name\n\n\nrgb2bgr\nbool\nFalse\nconvert to bgr\n\n\nReturns\nndarray\n\nimage\n\n\n\nShow the image with show_image(img) here we can see the camera placed at the takeoff point looking at the sofa\nTodo not sure why we have to rgd2bgr it\n\nimg = asc.get_image(rgb2bgr=True)\nax = show_image(img)\n\n\n\n\n\n\n\n\n\nimg = asc.get_image(\"center\", rgb2bgr=True)\nax = show_image(img)\n\n\n\n\n\n\n\n\n\ncams = [\"high_res\", \"front_center\", \"front_right\", \"front_left\", \"bottom_center\", \"back_center\"]\nimgs = asc.get_images(cams, rgb2bgr=True)\n\n\nfrom matplotlib import pyplot as plt\n\n\n_,axs = plt.subplots(3,2,figsize=(12,10))\nfor i,ax in enumerate(axs.flatten()): show_image(imgs[i], ax=ax, title=f' {cams[i]}')\n\n\nrs.exit()\n\n\n\nRun a loop grabbing the camera\n\nrs = RunSim(\"AirSimNH\", settings=\"config/settings_high_res.json\")\n\nasc = AirSimClient()\n\nframecounter = 1\ncam_num = 0\ncams = [\"high_res\", \"front_center\", \"front_right\", \"front_left\", \"bottom_center\", \"back_center\"]\nwith VideoWriter(\"images/airsim_test.mp4\", 5.0) as video:\n    while(True):\n        framecounter += 1\n        \n        img = asc.get_image(cams[cam_num], rgb2bgr=False)\n        puttext(img, f\"Frame: {framecounter}\")\n        img_bgr = resize(img, width=500)\n        cv2.imshow(\"Camera\", img)\n        \n        video.add(img_bgr)\n        k = cv2.waitKey(10)\n        if k == ord('q') or k == ord('Q') or k == 27:\n            break\n        \n        if k == ord('c') or k == ord('C'):\n            cam_num += 1\n            if cam_num &gt;= len(cams):\n                cam_num = 0\n            print(f\"Camera: {cams[cam_num]}\")\n        if framecounter &gt; 50:\n            break\n    cv2.destroyAllWindows()\n    rs.exit()\nvideo.show(width=500)",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Airsim Walkthrough"
    ]
  },
  {
    "objectID": "tutorials/template.html",
    "href": "tutorials/template.html",
    "title": "template01",
    "section": "",
    "text": "All of nbdev’s configuration is done through a file called settings.ini which lives in the root of your repo. It’s in ConfigParser format. For example, here’s the first few lines of nbdev’s settings.ini file",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "template01"
    ]
  },
  {
    "objectID": "tutorials/api_walkthrough.html",
    "href": "tutorials/api_walkthrough.html",
    "title": "API Walkthrough",
    "section": "",
    "text": "The written tutorial below shows you how to create a Python package from scratch using nbdev.\nAlternatively, you can watch this video tutorial where Jeremy Howard and Hamel Husain guide you through a similar process step by step:",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "API Walkthrough"
    ]
  },
  {
    "objectID": "tutorials/api_walkthrough.html#installation",
    "href": "tutorials/api_walkthrough.html#installation",
    "title": "API Walkthrough",
    "section": "Installation",
    "text": "Installation\nYou’ll need the following software to complete the tutorial, read on for specific installation instructions:\n\nPython\nA Python package manager: we recommend conda or pip\nJupyter Notebook\nnbdev\nQuarto\n\nIf you haven’t worked with Python before, we recommend getting started with the Anaconda Individual Edition and using the conda package manager.\nNote that you will only need to follow the steps in the installation section once per environment. If you create a new repo, you won’t need to redo these.\n\nInstall JupyterLab\nLaunch a terminal and install JupyterLab by entering:\nconda install -c conda-forge -y jupyterlab\n…or\npip install jupyterlab\n…if you’re using the pip package manager.\nYou can now launch Jupyter by entering:\njupyter lab\nThis should open JupyterLab in a new browser tab:\n\n\n\n\n\n\n\nInstall nbdev\nThe next step is to install nbdev itself. JupyterLab comes with its own terminal, so we’ll use that moving forward.\nIn the Launcher, scroll down to the “Other” section, then click “Terminal”. If the Launcher isn’t opened, you can open it by clicking “File” → “New Launcher”.\nA new tab should open with a blank terminal – it might not look exactly the same, depending on how your shell is configured:\n\n\n\n\n\nFor Mac and Linux, enter:\nconda install -c fastai -y nbdev\n…or for Mac, Linux and Windows:\npip install nbdev\n…if you’re using pip.\n\n\nInstall Quarto\nnbdev provides a command to install the latest version of Quarto. In the terminal, enter:\nnbdev_install_quarto\nYour password may be requested at this point. Since nbdev is open source, you can read the source code of this command to verify that it isn’t doing anything malicious. Or, if you prefer, you may instead follow Quarto’s official installation instructions.\n\n\nInstall Quarto JupyterLab extension\nQuarto provides its own JupyterLab extension that allows it to render Quarto markdown content.\nFor example, here is their notebook demonstrating some of its features:\n\nInstall the extension by entering:\npip install jupyterlab-quarto\nNote that the jupyterlab-quarto package is not currently available via conda.\n\nYou’re all setup and ready to go! Installing these tools may take some time, but you’ll only need to do it once. Next, we’ll setup an nbdev repo for your specific project.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "API Walkthrough"
    ]
  },
  {
    "objectID": "tutorials/api_walkthrough.html#first-steps",
    "href": "tutorials/api_walkthrough.html#first-steps",
    "title": "API Walkthrough",
    "section": "First steps",
    "text": "First steps\nBy the end of this section you’ll have your own nbdev repo with tests, continuous integration, streamlined PyPI & conda packaging, and a documentation website.\n\nCreate an empty GitHub repo\nCreate an empty GitHub repo using the convenient link github.com/new. If you get stuck, you might find GitHub’s Create a repo page helpful.\nRemember to add a description, since nbdev will use that later. Don’t add a README file, .gitignore, or license just yet.\nIf you’re using the web interface, it should look something like this (with your own repository name and descrpition) before you click “Create Repository”:\n\n\n\n\n\nYou should then be redirected to your new repo:\n\n\n\n\n\n\n\n\n\n\n\nTry GitHub’s powerful CLI\n\n\n\n\n\nGitHub’s web interface is a great way to get started. As you grow more experienced, you might want to explore the GitHub CLI (command line interface). We often prefer to use command line tools for repetitive tasks where we’re likely to make mistakes. Having those tasks written as small scripts in your terminal means that you can repeat them with little effort.\n\n\n\n\n\nInitialise your repo with nbdev\nNow clone your repo from the Jupyter terminal you started earlier (or create a new terminal following those instructions if needed). If you get stuck here, you might find GitHub’s Cloning a repository page helpful.\nSince we created a repo named nbev-hello-world with the fastai user, we can clone it as follows:\ngit clone https://github.com/fastai/nbdev-hello-world.git\nThen cd (change directory) to our repo:\ncd nbdev-hello-world\nYou may have seen this message while cloning:\nYou appear to have cloned an empty repository.\n…since the repo is completely empty. Let’s add some files!\nnbdev provides the nbdev_new command to initialise an empty git repository. It’ll infer information about your project from git and GitHub, and ask you to input anything remaining. It will create files in your repo that:\n\nStreamline publishing Python packages to PyPI and conda.\nConfigure Quarto for publication-grade technical documentation.\nSetup GitHub actions to test notebooks and build and deploy Quarto docs to GitHub pages.\n\nInitialise your nbdev repo by entering:\nnbdev_new\nIt may ask you to enter information that it couldn’t infer from git or GitHub.\n\n\n\n\n\n\nNote\n\n\n\nnbdev_new assumes that your package name is the same as your repo name (with - replaced by _). Use the --lib_name option if that isn’t the case.\n\n\nDouble-check your settings.ini file to ensure that it has all of the correct information. Then commit and push your additions to GitHub:\ngit add .\ngit commit -m'Initial commit'\ngit push\n\n\nEnable GitHub Pages\nnbdev hosts your docs on GitHub Pages—an excellent (and free!) way to host websites.\n\n\n\n\n\n\nNote\n\n\n\nnbdev uses GitHub Pages by default because its easily accessible. However, you can use any host you like. See these docs for more information.\n\n\nYou need to enable GitHub Pages for your repo by clicking on the “Settings” tab near the top-right of your repo page, then “Pages” on the left, then setting the “Branch” to “gh-pages”, and finally clicking “Save”.\nIt should look similar to this after you click “Save”:\n\n\n\n\n\nNow it’s time to see all of the goodies nbdev gives you!\n\n\nCheck out your workflows\nOpen GitHub Actions by clicking the “Actions” tab near the top of your repo page. You should see two workflow runs:\n\n\n\n\n\nIf you opened this page shortly after pushing your initial commit, the runs may not have a green check (✅) because they’re still “In progress” or “Queued”. That’s no problem, they shouldn’t take much more than a minute to complete.\nIf you see a red cross (❌), that means something failed. Click on the cross, then click “Details”, and you’ll be able to see what failed. If you can’t figure out what’s wrong, search the forum in case someone else resolved the same issue, otherwise create a new post describing your issue in as much detail as you can, and we’ll try our best to help you. Remember that including a link to an actual repo and/or GitHub Action is the best way for us to quickly identify what’s wrong.\nWhat do these workflows do?\n\nCI – The CI (continuous integration) workflow streamlines your developer workflow, particularly with multiple collaborators. Every time you push to GitHub, it ensures that:\n\nYour notebooks and libraries are in sync\nYour notebooks are cleaned of unwanted metadata (which pollute pull requests and git histories and lead to merge conflicts)\nYour notebook tests all pass\n\nDeploy to GitHub Pages – Builds your docs with Quarto and deploys it to GitHub Pages.\n\nWe provide these basic workflows out-of-the-box, however, you can edit their corresponding YAML files in the .github/workflows/ folder to your liking.\n\n\nCheck out your docs\nWhen you enable GitHub Pages you should see a new workflow run: “pages build and deployment”. As the name suggests, this workflow deploys your website contents to GitHub Pages.\n\n\n\n\n\nWait for the workflow run to complete, then open your website. By default it should be available at: https://{user}.github.io/{repo}. For example, you can view fastai’s nbdev-hello-world docs at https://fastai.github.io/nbdev-hello-world.\n\n\n\n\n\n\n\nRecap\nYou now have a base nbdev repo with continuous integration and hosted documentation! Here’s a recap of the steps you took:\n\nCreated a GitHub repo (with GitHub Pages enabled)\nInitialised your repo with nbdev_new\nPushed to GitHub.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "API Walkthrough"
    ]
  },
  {
    "objectID": "tutorials/api_walkthrough.html#make-your-first-edit",
    "href": "tutorials/api_walkthrough.html#make-your-first-edit",
    "title": "API Walkthrough",
    "section": "Make your first edit",
    "text": "Make your first edit\nIn this section, you’ll make your first edit to the repo you created in First steps.\n\nInstall hooks for git-friendly notebooks\nStep one when working with Jupyter notebooks in a new repo is to install nbdev’s hooks (you can think of “hooks” as plugins or extensions to an application).\nInstall them by entering this command in your terminal:\nnbdev_install_hooks\n\n\n\n\n\n\nNote\n\n\n\nThe clean hook currently only supports Jupyter Notebook and JupyterLab. If you’re using VSCode, you can try the experimental nbdev VSCode extension. Otherwise, you might also want to try nbdev’s pre-commit hooks.\n\n\nSee Git-friendly Jupyter for more about how nbdev hooks work and how to customise them. Here’s a short summary:\n\nFix broken notebooks due to git merge conflicts so that they can be opened and resolved directly in Jupyter.\nEach time you save a Jupyter notebook, automatically clean unwanted metadata to remove unnecessary changes in pull requests and reduce the chance of git merge conflicts.\nAutomatically trust notebooks in the repo so that you can view widgets from collaborators’ commits. For this reason, you should not install hooks into a repo you don’t trust.\n\n\n\n\n\n\n\nTip\n\n\n\nnbdev’s git hooks work on any git repo, even if it doesn’t use the broader nbdev system.\n\n\n\n\nBuild your library\nYou should now create your package from your notebook by running:\nnbdev_export\nThis will create Python modules for your notebooks. These modules will make up the contents of your Python package.\n\n\nInstall your package\nYou might have noticed that nbdev_new created a Python package in your repo. In our case, it was automatically named nbdev_hello_world by using our repo name nbdev-hello-world and replacing - with _ to make it a valid Python package.\nThe next step is to install your package by entering this into your terminal:\npip install -e '.[dev]'\nThis is the recommended way to make a Python package importable from anywhere in your current environment:\n\n-e – short for “editable”, lets you immediately use changes made to your package without having to reinstall, which is convenient for development.\n. – refers to the current directory.\n[dev] – includes “development” requirements: other packages that your notebooks use solely for documentation or testing.\n\n\n\nPreview your docs\nnbdev is an interactive programming environment that values fast feedback loops. The nbdev_preview command helps achieve this by using Quarto to render your docs on your computer and keep them updated as your edit your notebooks.\nStart the preview by entering this into your terminal:\nnbdev_preview\nIt may say Preparing to preview for a few seconds while it gets started, and will eventually display something like:\nWatching files for changes\nBrowse at http://localhost:3000/\nClick the link to open the preview in a new browser tab. It should look exactly like your online docs.\n\n\n\n\n\n\nTip\n\n\n\nWe often find it useful to keep a preview window open on the side while we’re editing our notebooks in Jupyter.\n\n\n\n\nEdit 00_core.ipynb\nNow, open the nbs/00_core.ipynb file (generated by running nbdev_new earlier) in Jupyter. You don’t have to start your notebook names with a number, but we find it helpful to show the order that your project should be read in – even though it could have been created in a different order.\n\nAdd your own frontmatter\nYou’ll see something that looks a bit like this:\n\ncore\n\nFill in a module description here\n\n#| default_exp core\n\nLet’s explain what these special cells means:\n\nThe first is a markdown cell with nbdev’s markdown frontmatter syntax that defines notebook metadata used by Quarto, our documentation engine (see the frontmatter reference page for more). It contains:\n\nH1 header (“core”) – defining the page title\nQuote (“Fill in a module description here”) – defining the page description\n\nThe second is a code cell with a directive default_exp which decides which module this notebook will export to (see the Directives explanation for more). Currently, it exports to the core module.\n\nNext, rename the notebook, replace the title and description, and change the default export module for your own project.\nOnce you’re done, save the notebook. The live preview started in the previous section should update with your latest changes.\nRerun all cells in your notebook to ensure that they work, and to export the updated modules.\n\n\n\n\n\n\nTip\n\n\n\nWe find the “restart kernel and run all cells” Jupyter command (the ⏩ button) so invaluable that we bind it to a keyboard shortcut. A common criticism of notebooks is that out-of-order execution leads to irreproducible notebooks. In our experience, making “restart and rerun” a habit solves this problem.\n\n\nRunning the notebook exports Python modules because of the last cell which contains:\n#| hide\nimport nbdev; nbdev.nbdev_export()\nWhat does this mean?\n\n#| hide is a directive (like #| default_exp) which excludes a cell from both your exported module and docs\nnbdev_export is the command used to export your notebooks to Python modules.\n\nWe recommend including a cell like this at the bottom of all of the notebooks you want to export.\n\n\n\n\n\n\nWarning\n\n\n\nRemember to delete any unused modules that aren’t exported by a notebook or otherwise needed by your package. This is likely to happen if you change the default export of a notebook – nbdev doesn’t remove the old module. This is intended, since nbdev is designed to work with hybrid packages that use .py modules (with no corresponding notebook) as well as those exported from notebooks.\n\n\n\n\nAdd your own function\nAdd a new code cell below the #| default_exp cell with a function. For example:\n#| export\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\nNotice how it includes #| export at the top – this is a directive (like #| default_exp) that tells nbdev to include the cell in your exported module and in your documentation.\nThe documentation should look like this:\n\n\n\nsay_hello\n\n say_hello (to)\n\nSay hello to somebody\n\n\n\n\nAdd your own examples, tests, and docs\nOne of the superpowers of notebook-driven development is that you can very easily add examples, tests, and documentation right below your code.\nInclude regular code cells, and they’ll appear (with output) in your docs, for example:\n\nsay_hello(\"Isaac\")\n\n'Hello Isaac!'\n\n\nThis is a test too! When you run nbdev_test it will execute this cell (and all other test cells) and fail if they raise any exceptions.\nFor tests, it’s preferred to use more explicit asserts:\n\nassert say_hello(\"Hamel\") == \"Hello Hamel!\"\n\n…or functions from fastcore.test, which behave like assert but also display the actual and expected values if they differ:\n\nfrom fastcore.test import *\n\n\ntest_eq(say_hello(\"Hamel\"), \"Hello Hamel!\")\n\nAnother superpower of notebook-driven development is that your examples can include plots, images, and even JavaScript widgets. For example, here’s an SVG circle:\n\nfrom IPython.display import display,SVG\n\n\ndisplay(SVG('&lt;svg height=\"100\" xmlns=\"http://www.w3.org/2000/svg\"&gt;&lt;circle cx=\"50\" cy=\"50\" r=\"40\"/&gt;&lt;/svg&gt;'))\n\n\n\n\n\n\n\n\n\n\n\nPrepare your changes\nBefore commiting your changes to GitHub we recommend running nbdev_prepare in the terminal, which bundles the following commands:\n\nnbdev_export: Builds the .py modules from Jupyter notebooks\nnbdev_test: Tests your notebooks\nnbdev_clean: Cleans your notebooks to get rid of extreanous output for git\nnbdev_readme: Updates your repo’s README.md file from your index notebook.\n\n\n\nEdit index.ipynb\nNow you’re ready to personalize your documentation home page and README.md file; these are both generated automatically from index.ipynb. Open Jupyter, then click on nbs/index.ipynb to open it.\nWe recommend including a longer description about what your package does, how to install it, and how to use it (with a few examples which import and use your package). Remember, examples can be code cells with real outputs rather than plain markdown text – they’ll double as tests too!\n\n\nPush to Github\nYou can now commit and push your changes to GitHub. As we mentioned before, always remember to run nbdev_prepare before you commit to ensure your modules are exported and your tests pass. You can use git status to check which files have been generated or changed. Then:\ngit add .\ngit commit -m 'Add `say_hello`; update index' # Update this text with your own message\ngit push\nThis will kick-off your GitHub Actions. Wait a minute or two for those to complete, then check your updated repo and documentation.\n\n\nRecap\nCongratulations, you’ve used all of the basics needed to build delightful projects with nbdev! Here’s a recap of the steps you took:\n\nInstalled hooks for git-friendly notebooks with nbdev_install_hooks\nInstalled your package with pip install -e '.[dev]'\nPreviewed your docs with nbdev_preview\nAdded your own frontmatter, function, tests, and docs to nbs/00_core.ipynb\nPrepared your changes with nbdev_prepare\nUpdated nbs/index.ipynb with your own information\nPushed to GitHub.\n\nRead on to learn about more advanced nbdev functionality. Also see our explanations for deep-dives on specific topics, as well as our other tutorials.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "API Walkthrough"
    ]
  },
  {
    "objectID": "tutorials/api_walkthrough.html#advanced-functionality",
    "href": "tutorials/api_walkthrough.html#advanced-functionality",
    "title": "API Walkthrough",
    "section": "Advanced functionality",
    "text": "Advanced functionality\n\nAdd a class\nCreate a class in 00_core.ipynb as follows:\n#| export\nclass HelloSayer:\n    \"Say hello to `to` using `say_hello`\"\n    def __init__(self, to): self.to = to\n        \n    def say(self):\n        \"Do the saying\"\n        return say_hello(self.to)\nThis will automatically appear in the docs like this:\n\n\n\nHelloSayer\n\n HelloSayer (to)\n\nSay hello to to using say_hello\n\nDocument with show_doc\nHowever, methods aren’t automatically documented. To add method docs, use show_doc:\nshow_doc(HelloSayer.say)\n\n\n\n\nHelloSayer.say\n\n HelloSayer.say ()\n\nDo the saying\nAnd add some examples and/or tests:\n\no = HelloSayer(\"Alexis\")\no.say()\n\n'Hello Alexis!'\n\n\n\n\nAdd links with backticks\nNotice above there is a link from our new class documentation to our function. That’s because we used backticks in the docstring:\n    \"Say hello to `to` using `say_hello`\"\nThese are automatically converted to hyperlinks wherever possible. For instance, here are hyperlinks to HelloSayer and say_hello created using backticks.\n\n\nSet up autoreload\nSince you’ll be often updating your modules from one notebook, and using them in another, it’s helpful if your notebook automatically reads in the new modules as soon as the Python file changes. To make this happen, just add these lines to the top of your notebook:\n%load_ext autoreload\n%autoreload 2\n\n\nSet up prerequisites\nIf your module requires other modules as dependencies, you can add those prerequisites to your settings.ini in the requirements section. The requirements should be separated by a space and if the module requires at least or at most a specific version of the requirement this may be specified here, too.\nFor example if your module requires the fastcore module of at least version 1.0.5, the torchvision module of at most version 0.7 and any version of matplotlib, then the prerequisites would look like this:\nrequirements = fastcore&gt;=1.0.5 torchvision&lt;0.7 matplotlib\nIn addition to requirements you can specify dependencies with other keywords that have different scopes. Below is a list of all possible dependency keywords:\n\nrequirements: Passed to both pip and conda setup\npip_requirements: Passed to pip setup only\nconda_requirements: Passed to conda setup only\ndev_requirements: Passed to pip setup as a development requirement\n\nFor more information about the format of dependencies, see the pypi and conda docs on creating specifications in setup.py and meta.yaml, respectively.\n\n\nSet up console scripts\nBehind the scenes, nbdev uses that standard package setuptools for handling installation of modules. One very useful feature of setuptools is that it can automatically create cross-platform console scripts. nbdev surfaces this functionality; to use it, use the same format as setuptools, with whitespace between each script definition (if you have more than one).\nconsole_scripts = nbdev_export=nbdev.cli:nbdev_export\n\n\nUpload to pypi\nIf you want people to be able to install your project by just typing pip install your-project then you need to upload it to pypi. The good news is, we’ve already created a fully pypi compliant installer for your project! So all you need to do is register at pypi (click “Register” on pypi) if you haven’t previously done so, and then create a file called ~/.pypirc with your login details. It should have these contents:\n[pypi]\nusername = your_pypi_username\npassword = your_pypi_password\nAnother thing you will need is twine, so you should run once\npip install twine\nTo upload your project to pypi, just type nbdev_pypi in your project root directory. Once it’s complete, a link to your project on pypi is displayed.\n\n\nUpload to conda\nSimilar to pip install support, we have provided an anaconda compliant installer to upload your project to anaconda. Once uploaded, your package can be installed by typing conda install -c your_anaconda_username your-project.\nYou need to register at anaconda (fill out the form to Sign Up) which will create a username and password. You will then need to install the following packages\npip install anaconda-client conda-build conda-verify\nBefore running the anaconda uploader, you need to login to conda using the CLI command (you will be prompted to enter your username and password)\nanaconda login\nTo upload to anaconda, just type nbdev_conda in your project root directory.\n\n\nUpload to pypi and conda\nThe command nbdev_release_both from the root of your nbdev repo will upload your project to both conda and pypi.\n\n\nInstall collapsible headings and toc2\nThere are two jupyter notebook extensions that I highly recommend when working with projects like this. They are:\n\nCollapsible headings: This lets you fold and unfold each section in your notebook, based on its markdown headings. You can also hit left to go to the start of a section, and right to go to the end\nTOC2: This adds a table of contents to your notebooks, which you can navigate either with the Navigate menu item it adds to your notebooks, or the TOC sidebar it adds. These can be modified and/or hidden using its settings.\n\n\n\nMath equation support\nnbdev supports equations (using Quarto). You can include math in your notebook’s documentation using the following methods.\nUsing $$, e.g.:\n$$\\sum_{i=1}^{k+1}i$$\nWhich is rendered as:\n\n\\[\\sum_{i=1}^{k+1}i\\]\n\nUsing $, e.g.:\nThis version is displayed inline: $\\sum_{i=1}^{k+1}i$ . You can include text before and after.\nWhich is rendered as:\n\nThis version is displayed inline: \\(\\sum_{i=1}^{k+1}i\\) . You can include text before and after.\n\nFor more information, see the Quarto Docs\n\n\nLook at nbdev “source” for more ideas\nDon’t forget that nbdev itself is written in nbdev! It’s a good place to look to see how fast.ai uses it in practice, and get a few tips. You’ll find the nbdev notebooks here in the nbs folder on Github.\n\n\nQuarto Features\nnbdev supports most Quarto features. We encourage you to read the Quarto documentation to discover all the features available to you. For example, this is how you can incorporate mermaid charts:\n\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\n\nHere is another example of using Graphviz:\n\n\n\n\n\n\n\nG\n\n\n\nrun\n\nrun\n\n\n\nintr\n\nintr\n\n\n\nrun--intr\n\n\n\n\nkernel\n\nkernel\n\n\n\nrun--kernel\n\n\n\n\nrunbl\n\nrunbl\n\n\n\nintr--runbl\n\n\n\n\nrunbl--run\n\n\n\n\nzombie\n\nzombie\n\n\n\nkernel--zombie\n\n\n\n\nsleep\n\nsleep\n\n\n\nkernel--sleep\n\n\n\n\nrunmem\n\nrunmem\n\n\n\nkernel--runmem\n\n\n\n\nsleep--runmem\n\n\n\n\nswap\n\nswap\n\n\n\nsleep--swap\n\n\n\n\nrunswap\n\nrunswap\n\n\n\nswap--runswap\n\n\n\n\nrunswap--runmem\n\n\n\n\nnew\n\nnew\n\n\n\nrunswap--new\n\n\n\n\nnew--runmem\n\n\n\n\n\n\n\n\n\nIt is worth taking a look at the documentation for figures, callouts, markdown, widgets, layouts, conditional content and quarto extensions to name a few useful things we have encountered.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "API Walkthrough"
    ]
  },
  {
    "objectID": "api/mavlink.camera.html",
    "href": "api/mavlink.camera.html",
    "title": "Mavlink Camera",
    "section": "",
    "text": "Implementation of these commands:\n\nMAV_CMD_REQUEST_CAMERA_CAPTURE_STATUS = 527 MAV_CMD_REQUEST_CAMERA_INFORMATION = 523 MAV_CMD_REQUEST_CAMERA_SETTINGS = 524 MAV_CMD_REQUEST_STORAGE_INFORMATION = 525 MAV_CMD_STORAGE_FORMAT = 526 MAV_CMD_SET_CAMERA_ZOOM = 531 MAV_CMD_SET_CAMERA_FOCUS = 532 MAV_CMD_IMAGE_START_CAPTURE = 2000 MAV_CMD_IMAGE_STOP_CAPTURE = 2001\nMAV_CMD_REQUEST_VIDEO_STREAM_INFORMATION = 2504 MAV_CMD_REQUEST_VIDEO_STREAM_STATUS = 2505 MAV_CMD_VIDEO_START_CAPTURE = 2500 MAV_CMD_VIDEO_STOP_CAPTURE = 2501 MAV_CMD_SET_CAMERA_MODE = 530\nNote The simulated camera is implemented in PX4 gazebo_camera_manager_plugin.cpp.\n\n\n\nExported source\n# from pymavlink.dialects.v20 import ardupilotmega as mav\n# from pymavlink.dialects.v20.ardupilotmega import MAVLink\n\n\nNAN = float(\"nan\")\n\n\"\"\"\nMAV_CMD_REQUEST_CAMERA_CAPTURE_STATUS = 527 # https://mavlink.io/en/messages/common.html#MAV_CMD_REQUEST_CAMERA_CAPTURE_STATUS\nMAV_CMD_REQUEST_CAMERA_INFORMATION = 521 # https://mavlink.io/en/messages/common.html#MAV_CMD_REQUEST_CAMERA_INFORMATION\nMAV_CMD_REQUEST_CAMERA_SETTINGS = 522 # https://mavlink.io/en/messages/common.html#MAV_CMD_REQUEST_CAMERA_SETTINGS\nMAV_CMD_REQUEST_STORAGE_INFORMATION = 525 # https://mavlink.io/en/messages/common.html#MAV_CMD_REQUEST_STORAGE_INFORMATION\nMAV_CMD_STORAGE_FORMAT = 526 # https://mavlink.io/en/messages/common.html#MAV_CMD_STORAGE_FORMAT\nMAV_CMD_SET_CAMERA_ZOOM = 531 # https://mavlink.io/en/messages/common.html#MAV_CMD_SET_CAMERA_ZOOM\nMAV_CMD_SET_CAMERA_FOCUS = 532 # https://mavlink.io/en/messages/common.html#MAV_CMD_SET_CAMERA_FOCUS\nMAV_CMD_IMAGE_START_CAPTURE = 2000  # https://mavlink.io/en/messages/common.html#MAV_CMD_IMAGE_START_CAPTURE\nMAV_CMD_IMAGE_STOP_CAPTURE = 2001  # https://mavlink.io/en/messages/common.html#MAV_CMD_IMAGE_STOP_CAPTURE\nMAV_CMD_REQUEST_VIDEO_STREAM_INFORMATION = 2504 # https://mavlink.io/en/messages/common.html#MAV_CMD_REQUEST_VIDEO_STREAM_INFORMATION\nMAV_CMD_REQUEST_VIDEO_STREAM_STATUS = 2505 # https://mavlink.io/en/messages/common.html#MAV_CMD_REQUEST_VIDEO_STREAM_STATUS\nMAV_CMD_VIDEO_START_CAPTURE = 2500 # https://mavlink.io/en/messages/common.html#MAV_CMD_VIDEO_START_CAPTURE\nMAV_CMD_VIDEO_STOP_CAPTURE = 2501 # https://mavlink.io/en/messages/common.html#MAV_CMD_VIDEO_STOP_CAPTURE\nMAV_CMD_SET_CAMERA_MODE = 530 # https://mavlink.io/en/messages/common.html#MAV_CMD_SET_CAMERA_MODE\n\n\"\"\"\nCAMERA_INFORMATION = mavlink.MAVLINK_MSG_ID_CAMERA_INFORMATION # https://mavlink.io/en/messages/common.html#CAMERA_INFORMATION\nCAMERA_SETTINGS = mavlink.MAVLINK_MSG_ID_CAMERA_SETTINGS # https://mavlink.io/en/messages/common.html#CAMERA_SETTINGS\nSTORAGE_INFORMATION = mavlink.MAVLINK_MSG_ID_STORAGE_INFORMATION # https://mavlink.io/en/messages/common.html#STORAGE_INFORMATION\nCAMERA_CAPTURE_STATUS = mavlink.MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS # https://mavlink.io/en/messages/common.html#CAMERA_CAPTURE_STATUS\nCAMERA_IMAGE_CAPTURED = mavlink.MAVLINK_MSG_ID_CAMERA_IMAGE_CAPTURED # https://mavlink.io/en/messages/common.html#CAMERA_IMAGE_CAPTURED\n\n\n\n\nCamera Server\n\nThe server is on the companion computer and is used to receive commands from the camera on the ground station PC.\n\n\n\n\nCameraServer\n\n CameraServer (source_component=100, mav_type=30, camera=None,\n               loglevel=20)\n\nCreate a mavlink Camera server Component, camera argument will normally be a gstreamer pipeline\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsource_component\nint\n100\nused for component indication\n\n\nmav_type\nint\n30\nused for heartbeat MAV_TYPE indication\n\n\ncamera\nNoneType\nNone\ncamera (or FakeCamera for testing)\n\n\nloglevel\nint\n20\nlogging level\n\n\n\n\n# run a server that can receive commands from a client\nfrom mavcom.logging import LogLevels\n\n# start a mavlink server that can receive commands from a client\nwith MAVCom(\"udpout:localhost:14445\", source_system=222, loglevel=LogLevels.DEBUG) as UAV_server:\n    # add the camera server components to the server\n    UAV_server.add_component(CameraServer(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=mavlink.MAV_COMP_ID_CAMERA, camera=None))\n    UAV_server.add_component(CameraServer(mavlink.MAV_COMP_ID_CAMERA2))\n    UAV_server.add_component(CameraServer(mavlink.MAV_COMP_ID_CAMERA3))\n    \n    time.sleep(1)\n\nINFO   | mavcom.MAVCom      | 40.097 |  mavcom.py:379 | Thread-63 (listen) | MAVLink Mav2: True, source_system: 222\nWARNIN | mavcom.CameraServe | 40.099 | camera_server.py:110 | MainThread         | Component has no camera object\nINFO   | mavcom.CameraServe | 40.100 | component.py:135 | MainThread         | Component Started self.source_component = 100, self.mav_type = 30, self.source_system = 222\nWARNIN | mavcom.CameraServe | 40.102 | camera_server.py:110 | MainThread         | Component has no camera object\nINFO   | mavcom.CameraServe | 40.103 | component.py:135 | MainThread         | Component Started self.source_component = 101, self.mav_type = 30, self.source_system = 222\nWARNIN | mavcom.CameraServe | 40.104 | camera_server.py:110 | MainThread         | Component has no camera object\nINFO   | mavcom.CameraServe | 40.105 | component.py:135 | MainThread         | Component Started self.source_component = 102, self.mav_type = 30, self.source_system = 222\nINFO   | mavcom.CameraServe | 42.101 | component.py:401 | MainThread         | CameraServer closed\nINFO   | mavcom.CameraServe | 42.104 | component.py:401 | MainThread         | CameraServer closed\nINFO   | mavcom.CameraServe | 42.106 | component.py:401 | MainThread         | CameraServer closed\nINFO   | mavcom.MAVCom      | 42.106 |  mavcom.py:428 | MainThread         | MAVCom  closed\n\n\nUAV                             \nUAV                             \nUAV                             \n\n\n\nCameraServer().list_commands()\n\nSupported Commands: https://mavlink.io/en/messages/common.html#mav_commands\n Cmd = MAV_CMD_REQUEST_MESSAGE: 512 \n Cmd = MAV_CMD_STORAGE_FORMAT: 526 \n Cmd = MAV_CMD_SET_CAMERA_ZOOM: 531 \n Cmd = MAV_CMD_IMAGE_START_CAPTURE: 2000 \n Cmd = MAV_CMD_IMAGE_STOP_CAPTURE: 2001 \n Cmd = MAV_CMD_VIDEO_START_CAPTURE: 2500 \n Cmd = MAV_CMD_VIDEO_STOP_CAPTURE: 2501 \n Cmd = MAV_CMD_SET_CAMERA_MODE: 530 \n Cmd = MAV_CMD_VIDEO_START_STREAMING: 2502 \n Cmd = MAV_CMD_VIDEO_STOP_STREAMING: 2503 \nSupported Message Requests:  https://mavlink.io/en/messages/common.html#messages\n\nMAVLINK_MSG_ID_CAMERA_INFORMATION:  259\nMAVLINK_MSG_ID_CAMERA_SETTINGS:  260\nMAVLINK_MSG_ID_STORAGE_INFORMATION:  261\nMAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS:  262\nMAVLINK_MSG_ID_CAMERA_IMAGE_CAPTURED:  263\nMAVLINK_MSG_ID_VIDEO_STREAM_INFORMATION:  269\nMAVLINK_MSG_ID_VIDEO_STREAM_STATUS:  270\n\n\n\ndoc_class(CameraServer)\n\n\n\nCameraServer.close\n\n CameraServer.close ()\n\nClose the connection to the camera\n\n\n\nComponent.count_message\n\n Component.count_message (msg)\n\nCount a message by adding it to the message_cnts dictionary. indexed by system and message type\n\n\n\nCameraServer.list_commands\n\n CameraServer.list_commands ()\n\nList the commands supported by the camera server https://mavlink.io/en/messages/common.html https://mavlink.io/en/messages/common.html#MAV_CMD_REQUEST_CAMERA_INFORMATION https://mavlink.io/en/messages/common.html#MAV_CMD_REQUEST_CAMERA_SETTINGS https://mavlink.io/en/messages/common.html#MAV_CMD_REQUEST_STORAGE_INFORMATION https://mavlink.io/en/messages/common.html#MAV_CMD_STORAGE_FORMAT https://mavlink.io/en/messages/common.html#MAV_CMD_SET_CAMERA_ZOOM etc\n\n\n\nCameraServer.on_mav_connection\n\n CameraServer.on_mav_connection ()\n\nStart the mavlink connection\n\n\n\nCameraServer.on_message\n\n CameraServer.on_message\n                          (msg:pymavlink.dialects.v20.ardupilotmega.MAVLin\n                          k_command_long_message)\n\nCallback for a command received from the client This will respond to the mavlink camera and storage focused commands:\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nmsg\nMAVLink_command_long_message\n: mavlink Message\n\n\nReturns\nbool\nreturn True to indicate that the message has been handled\n\n\n\n\n\n\nComponent.send_ack\n\n Component.send_ack (msg, ack_result:object=0)\n\nSend an ACK message to indicate a command was received.\n\n\n\nComponent.send_command\n\n Component.send_command (target_system:int, target_component:int,\n                         command_id:int, params:list, timeout=0.5)\n\nNote: async function\n\n\n\nComponent.send_ping\n\n Component.send_ping (target_system:int, target_component:int,\n                      ping_num:int=None)\n\nSend self.max_pings * ping messages to test if the server is alive.\n\n\n\nComponent.set_log\n\n Component.set_log (loglevel)\n\n\n\n\nComponent.set_mav_connection\n\n Component.set_mav_connection (mav_com:MAVCom)\n\nSet the mav_connection for the component\n\n\n\nComponent.set_source_compenent\n\n Component.set_source_compenent ()\n\nSet the source component for the master.mav\n\n\n\nComponent.set_target\n\n Component.set_target (target_system, target_component)\n\nSet the target system and component for the gimbal\n\n\n\nComponent.wait_ack\n\n Component.wait_ack (target_system, target_component, command_id=None,\n                     timeout=0.1)\n\nWait for an ack from target_system and target_component.\nNote: async function\n\n\n\nComponent.wait_heartbeat\n\n Component.wait_heartbeat (remote_mav_type=None, target_system=None,\n                           target_component=None, timeout:int=1)\n\nWait for a heartbeat from target_system and target_component.\nNote: async function\n\n\n\n\n\nCamera Client\n\nThe client is on the ground station PC and is used to send commands to the camera on the companion computer.\n\n\n\n\nCameraClient\n\n CameraClient (source_component:int, mav_type:int,\n               loglevel:mavcom.logging.LogLevels|int=20)\n\nCreate a client component to send commands to a companion computer or GCS that will control a camera via a CameraServer instance\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsource_component\nint\n\nused for component indication\n\n\nmav_type\nint\n\nused for heartbeat MAV_TYPE indication\n\n\nloglevel\nmavcom.logging.LogLevels | int\n20\nlogging level\n\n\n\n\nExample: CameraClient\n\n# run a client that can send commands to a server\nwith MAVCom(\"udpin:localhost:14445\", source_system=111, loglevel=LogLevels.CRITICAL) as client: \n    # add the camera client component to the client\n    gcs:CameraClient = client.add_component( CameraClient(mav_type=mavutil.mavlink.MAV_TYPE_GCS, source_component=11, loglevel=LogLevels.DEBUG) )\n\nDEBUG  | mavcom.CameraClien | 42.274 | component.py:131 | MainThread         | set_mav_connection CameraClient component.py:131 self.mav_com = &lt;MAVCom&gt;\nDEBUG  | mavcom.CameraClien | 42.275 | component.py:175 | Thread-73 (_thread | Starting heartbeat type: 6 to all Systems and Components\nDEBUG  | mavcom.CameraClien | 42.276 | component.py:139 | MainThread         | Called from Component.start_mav_connection(), override to add startup behaviour\nINFO   | mavcom.CameraClien | 42.276 | component.py:135 | MainThread         | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\nINFO   | mavcom.CameraClien | 43.277 | component.py:401 | MainThread         | CameraClient closed\n\n\n\ndoc_class(CameraClient)\n\n\n\nComponent.close\n\n Component.close ()\n\n\n\n\nComponent.count_message\n\n Component.count_message (msg)\n\nCount a message by adding it to the message_cnts dictionary. indexed by system and message type\n\n\n\nCameraClient.image_start_capture\n\n CameraClient.image_start_capture (target_system=None,\n                                   target_component=None, interval=0,\n                                   count=1)\n\nStart image capture sequence.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntarget_system\nNoneType\nNone\n\n\n\ntarget_component\nNoneType\nNone\n\n\n\ninterval\nint\n0\nImage capture interval\n\n\ncount\nint\n1\nNumber of images to capture (0 for unlimited)\n\n\n\n\n\n\nCameraClient.image_stop_capture\n\n CameraClient.image_stop_capture (target_system=None,\n                                  target_component=None)\n\nStop image capture sequence\n\n\n\nCameraClient.message_callback_cond\n\n CameraClient.message_callback_cond (msg_id, target_system,\n                                     target_component, timeout=1)\n\nRegister a callback for a message received from the server Returns the message\nNote: async function\n\n\n\nCameraClient.on_mav_connection\n\n CameraClient.on_mav_connection ()\n\n\n\n\nCameraClient.on_message\n\n CameraClient.on_message\n                          (msg:pymavlink.dialects.v20.ardupilotmega.MAVLin\n                          k_message)\n\nCallback for a command received from the server\n\n\n\nCameraClient.request_message\n\n CameraClient.request_message (msg_id, params=None, target_system=None,\n                               target_component=None)\n\nRequest a message from the camera\nNote: async function\n\n\n\nComponent.send_ack\n\n Component.send_ack (msg, ack_result:object=0)\n\nSend an ACK message to indicate a command was received.\n\n\n\nComponent.send_command\n\n Component.send_command (target_system:int, target_component:int,\n                         command_id:int, params:list, timeout=0.5)\n\nNote: async function\n\n\n\nCameraClient.send_message\n\n CameraClient.send_message (msg)\n\nSend a message to the camera\n\n\n\nComponent.send_ping\n\n Component.send_ping (target_system:int, target_component:int,\n                      ping_num:int=None)\n\nSend self.max_pings * ping messages to test if the server is alive.\n\n\n\nCameraClient.set_camera_mode\n\n CameraClient.set_camera_mode (target_system=None, target_component=None,\n                               mode_id=0)\n\nSet the camera mode\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntarget_system\nNoneType\nNone\n\n\n\ntarget_component\nNoneType\nNone\n\n\n\nmode_id\nint\n0\nhttps://mavlink.io/en/messages/common.html#CAMERA_MODE\n\n\n\n\n\n\nCameraClient.set_camera_zoom\n\n CameraClient.set_camera_zoom (target_system=None, target_component=None,\n                               zoom_type=0, zoom_value=1)\n\nSet the camera zoom\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntarget_system\nNoneType\nNone\n\n\n\ntarget_component\nNoneType\nNone\n\n\n\nzoom_type\nint\n0\n\n\n\nzoom_value\nint\n1\n0 to 100 zoom value\n\n\n\n\n\n\nComponent.set_log\n\n Component.set_log (loglevel)\n\n\n\n\nComponent.set_mav_connection\n\n Component.set_mav_connection (mav_com:MAVCom)\n\nSet the mav_connection for the component\n\n\n\nCameraClient.set_message_callback_cond\n\n CameraClient.set_message_callback_cond (msg_id, target_system,\n                                         target_component)\n\nRegister a callback condition for a message received from the server\n\n\n\nComponent.set_source_compenent\n\n Component.set_source_compenent ()\n\nSet the source component for the master.mav\n\n\n\nComponent.set_target\n\n Component.set_target (target_system, target_component)\n\nSet the target system and component for the gimbal\n\n\n\nCameraClient.storage_format\n\n CameraClient.storage_format (target_system=None, target_component=None)\n\nFormat storage (for cases where camera has storage)\n\n\n\nCameraClient.video_start_capture\n\n CameraClient.video_start_capture (target_system=None,\n                                   target_component=None,\n                                   video_stream_id=0, frequency=1)\n\nStart video capture\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntarget_system\nNoneType\nNone\n\n\n\ntarget_component\nNoneType\nNone\n\n\n\nvideo_stream_id\nint\n0\nVideo stream id (0 for all streams)\n\n\nfrequency\nint\n1\nFrequency CAMERA_CAPTURE_STATUS messages should be sent while recording (0 for no messages, otherwise frequency in Hz)\n\n\n\n\n\n\nCameraClient.video_start_streaming\n\n CameraClient.video_start_streaming (target_system=None,\n                                     target_component=None,\n                                     video_stream_id=0)\n\nStart video streaming\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntarget_system\nNoneType\nNone\n\n\n\ntarget_component\nNoneType\nNone\n\n\n\nvideo_stream_id\nint\n0\nVideo Stream ID (0 for all streams)\n\n\n\n\n\n\nCameraClient.video_stop_capture\n\n CameraClient.video_stop_capture (target_system=None,\n                                  target_component=None,\n                                  video_stream_id=0)\n\nStop video capture\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntarget_system\nNoneType\nNone\n\n\n\ntarget_component\nNoneType\nNone\n\n\n\nvideo_stream_id\nint\n0\nVideo stream id (0 for all streams)\n\n\n\n\n\n\nCameraClient.video_stop_streaming\n\n CameraClient.video_stop_streaming (target_system=None,\n                                    target_component=None,\n                                    video_stream_id=0)\n\nStop the video stream\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntarget_system\nNoneType\nNone\n\n\n\ntarget_component\nNoneType\nNone\n\n\n\nvideo_stream_id\nint\n0\nVideo Stream ID (0 for all streams)\n\n\n\n\n\n\nComponent.wait_ack\n\n Component.wait_ack (target_system, target_component, command_id=None,\n                     timeout=0.1)\n\nWait for an ack from target_system and target_component.\nNote: async function\n\n\n\nComponent.wait_heartbeat\n\n Component.wait_heartbeat (remote_mav_type=None, target_system=None,\n                           target_component=None, timeout:int=1)\n\nWait for a heartbeat from target_system and target_component.\nNote: async function\n\n\n\nCameraClient.wait_message_callback\n\n CameraClient.wait_message_callback (cond, timeout=1)\n\nWait for the callback for a message received from the server\nNote: async function\n\n\n\n\n\n\nExample: Test locally using UDP ports\n\non the same machine using UDP ports 14445 with server_system_ID=111, client_system_ID=222 CameraClient is set to udpin:localhost:14445 and CameraServer is set to udpout:localhost:14445 udpin is so that the client can receive UDP from the mavproxy server at localhost:14445 CameraClient uses async/await to send commands to the CameraServer\n\n\nimport asyncio\nasync def main():\n    MAV_TYPE_GCS = mavutil.mavlink.MAV_TYPE_GCS\n    MAV_TYPE_CAMERA = mavutil.mavlink.MAV_TYPE_CAMERA\n    \n    con1, con2 = \"udpin:localhost:14445\", \"udpout:localhost:14445\"\n    # con1, con2 = \"/dev/ttyACM0\", \"/dev/ttyUSB0\"\n    with MAVCom(con1, source_system=111) as client:\n        with MAVCom(con2, source_system=222) as server:\n            gcs:CameraClient = client.add_component(\n                CameraClient(mav_type=MAV_TYPE_GCS, source_component=11))\n            # server.add_component(CameraServer(mav_type=MAV_TYPE_CAMERA, source_component=22, camera=cam_fake1, debug=False))\n            server.add_component(CameraServer(mav_type=MAV_TYPE_CAMERA, source_component=22, camera=None))\n    \n            ret = await gcs.wait_heartbeat(remote_mav_type=mavlink.MAV_TYPE_CAMERA)\n            print(f\"Heartbeat received {ret = }\")\n    \n            msg = await gcs.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_INFORMATION, target_system=222, target_component=22)\n\n            print( f\"MAVLINK_MSG_ID_CAMERA_INFORMATION {msg}\")\n            \n            # msg = await cam.request_storage_information()\n            # print (msg)\n            \n            time.sleep(1)\n            \nawait main()\n\nINFO   | mavcom.MAVCom      | 43.433 |  mavcom.py:379 | Thread-75 (listen) | MAVLink Mav2: True, source_system: 111\nINFO   | mavcom.MAVCom      | 43.534 |  mavcom.py:379 | Thread-76 (listen) | MAVLink Mav2: True, source_system: 222\nINFO   | mavcom.CameraClien | 43.536 | component.py:135 | MainThread         | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\nWARNIN | mavcom.CameraServe | 43.537 | camera_server.py:110 | MainThread         | Component has no camera object\nINFO   | mavcom.CameraServe | 43.538 | component.py:135 | MainThread         | Component Started self.source_component = 22, self.mav_type = 30, self.source_system = 222\nINFO   | mavcom.CameraServe | 45.539 | component.py:401 | MainThread         | CameraServer closed\nINFO   | mavcom.MAVCom      | 45.540 |  mavcom.py:428 | MainThread         | MAVCom  closed\nINFO   | mavcom.CameraClien | 46.539 | component.py:401 | MainThread         | CameraClient closed\nINFO   | mavcom.MAVCom      | 46.540 |  mavcom.py:428 | MainThread         | MAVCom  closed\n\n\nUAV                             \nHeartbeat received ret = (222, 22)\nMAVLINK_MSG_ID_CAMERA_INFORMATION CAMERA_INFORMATION {time_boot_ms : 2248962, vendor_name : UAV, model_name : FakeCamera, firmware_version : 1, focal_length : 2.799999952316284, sensor_size_h : 3.200000047683716, sensor_size_v : 2.4000000953674316, resolution_h : 640, resolution_v : 480, lens_id : 0, flags : 0, cam_definition_version : 1, cam_definition_uri : , gimbal_device_id : 0}\n\n\n\nStarting a client and server\n\non the same machine using UDP ports 14445 with server_system_ID=111, client_system_ID=222\n\n\n\nExported source\nfrom mavcom.mavlink.mavcom import MAVCom\nfrom mavcom.mavlink.component import Component, mavutil\nimport time\n\ndef on_message(message):\n    print(f\"on_message: {message}\")\n    return True # Return True to indicate that command was ok and send ack\n\nclass Cam1(Component):\n    def __init__(self, source_component, mav_type, debug=False):\n        super().__init__(source_component=source_component, mav_type=mav_type)\n        self._set_message_callback(on_message)\n\n\nclass Cam2(Component):\n    def __init__(self, source_component, mav_type, debug=False):\n        super().__init__(source_component=source_component, mav_type=mav_type)\n        self._set_message_callback(on_message)\n\n\nclass Cli(Component):\n    def __init__(self, source_component, mav_type, debug=False):\n        super().__init__(source_component=source_component, mav_type=mav_type)\n        self._set_message_callback(on_message)\n\n\n\n\nExported source\nasync def test_client_server(con1=\"udpin:localhost:14445\", con2=\"udpout:localhost:14445\"):\n    with MAVCom(con1, source_system=111) as client:\n        with MAVCom(con2, source_system=222) as server:\n\n            client.add_component(Cli(mav_type=mavlink.MAV_TYPE_GCS, source_component=11))\n            server.add_component(Cam1(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=22))\n            server.add_component(Cam1(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=23))\n\n            for key, comp in client.component.items():\n                # result = await comp.wait_heartbeat(target_system=222, target_component=22)\n                result = await comp.wait_heartbeat(remote_mav_type=mavlink.MAV_TYPE_CAMERA, target_system=222, target_component=22)\n                print(f\"Component {comp}, Heartbeat: {result = }\")\n\n            Num_Iters = 3\n            for i in range(Num_Iters):\n                await client.component[11]._test_command(222, 22, 1)\n\n                await client.component[11]._test_command(222, 23, 1)\n\n            await client.component[11]._test_command(222, 24, 1)\n\n    print(f\"{server.source_system = };  {server.message_cnts = }\")\n    print(f\"{client.source_system = };  {client.message_cnts = }\")\n    print()\n    print(f\"{client.source_system = } \\n{client.summary()} \\n\")\n    print(f\"{server.source_system = } \\n{server.summary()} \\n\")\n    \n    assert client.component[11].num_cmds_sent == Num_Iters * 2 + 1\n    print(f\"{server.component[22].message_cnts[111]['COMMAND_LONG'] = }\")\n    assert server.component[22].message_cnts[111]['COMMAND_LONG'] == Num_Iters\n    assert client.component[11].num_acks_rcvd == Num_Iters * 2\n    assert client.component[11].num_acks_drop == 1\n    assert server.component[22].num_cmds_rcvd == Num_Iters\n    assert server.component[23].num_cmds_rcvd == Num_Iters\n\ntry:     \n    import asyncio \n    # notebook does not run asyncio tasks\n    asyncio.run(test_client_server(con1=\"udpin:localhost:14445\", con2=\"udpout:localhost:14445\"))\nexcept: \n    pass\n\n\nWARNIN | py.warnings     | 46.577 | warnings.py:109 | MainThread         | /tmp/ipykernel_9420/569135065.py:41: RuntimeWarning: coroutine 'test_client_server' was never awaited\n  pass\n\n\n\n\nawait test_client_server()\n\nINFO   | mavcom.MAVCom      | 46.687 |  mavcom.py:379 | Thread-81 (listen) | MAVLink Mav2: True, source_system: 111\nINFO   | mavcom.MAVCom      | 46.788 |  mavcom.py:379 | Thread-82 (listen) | MAVLink Mav2: True, source_system: 222\nINFO   | mavcom.Cli         | 46.790 | component.py:135 | MainThread         | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\nINFO   | mavcom.Cam1        | 46.792 | component.py:135 | MainThread         | Component Started self.source_component = 22, self.mav_type = 30, self.source_system = 222\nINFO   | mavcom.Cam1        | 46.794 | component.py:135 | MainThread         | Component Started self.source_component = 23, self.mav_type = 30, self.source_system = 222\nERROR  | mavcom.MAVCom      | 47.399 |  mavcom.py:402 | Thread-82 (listen) |  Component 24 does not exist? ; Exception: 24\nWARNIN | mavcom.Cli         | 47.900 | component.py:374 | MainThread         | **No ACK: 222/24 MAV_CMD_DO_DIGICAM_CONTROL:203\nINFO   | mavcom.Cam1        | 48.794 | component.py:401 | MainThread         | Cam1 closed\nINFO   | mavcom.Cam1        | 49.797 | component.py:401 | MainThread         | Cam1 closed\nINFO   | mavcom.MAVCom      | 49.797 |  mavcom.py:428 | MainThread         | MAVCom  closed\nINFO   | mavcom.Cli         | 51.796 | component.py:401 | MainThread         | Cli closed\nINFO   | mavcom.MAVCom      | 51.797 |  mavcom.py:428 | MainThread         | MAVCom  closed\n\n\nComponent Cli, Heartbeat: result = (222, 22)\non_message: COMMAND_LONG {target_system : 222, target_component : 22, command : 203, confirmation : 0, param1 : 1.0, param2 : 1.0, param3 : 0.0, param4 : 0.0, param5 : 0.0, param6 : 0.0, param7 : 0.0}\non_message: COMMAND_LONG {target_system : 222, target_component : 23, command : 203, confirmation : 0, param1 : 1.0, param2 : 1.0, param3 : 0.0, param4 : 0.0, param5 : 0.0, param6 : 0.0, param7 : 0.0}\non_message: COMMAND_LONG {target_system : 222, target_component : 22, command : 203, confirmation : 0, param1 : 1.0, param2 : 1.0, param3 : 0.0, param4 : 0.0, param5 : 0.0, param6 : 0.0, param7 : 0.0}\non_message: COMMAND_LONG {target_system : 222, target_component : 23, command : 203, confirmation : 0, param1 : 1.0, param2 : 1.0, param3 : 0.0, param4 : 0.0, param5 : 0.0, param6 : 0.0, param7 : 0.0}\non_message: COMMAND_LONG {target_system : 222, target_component : 22, command : 203, confirmation : 0, param1 : 1.0, param2 : 1.0, param3 : 0.0, param4 : 0.0, param5 : 0.0, param6 : 0.0, param7 : 0.0}\non_message: COMMAND_LONG {target_system : 222, target_component : 23, command : 203, confirmation : 0, param1 : 1.0, param2 : 1.0, param3 : 0.0, param4 : 0.0, param5 : 0.0, param6 : 0.0, param7 : 0.0}\nserver.source_system = 222;  server.message_cnts = {111: {'COMMAND_LONG': 7, 'HEARTBEAT': 1}}\nclient.source_system = 111;  client.message_cnts = {222: {'HEARTBEAT': 5, 'COMMAND_ACK': 6}}\n\nclient.source_system = 111 \n - comp.source_component = 11\n - comp.num_msgs_rcvd = 11\n - comp.num_cmds_sent = 7\n - comp.num_cmds_rcvd = 0\n - comp.num_acks_rcvd = 6\n - comp.num_acks_sent = 0\n - comp.num_acks_drop = 1\n - comp.message_cnts = {222: {'HEARTBEAT': 5, 'COMMAND_ACK': 6}} \n\nserver.source_system = 222 \n - comp.source_component = 22\n - comp.num_msgs_rcvd = 4\n - comp.num_cmds_sent = 0\n - comp.num_cmds_rcvd = 3\n - comp.num_acks_rcvd = 0\n - comp.num_acks_sent = 3\n - comp.num_acks_drop = 0\n - comp.message_cnts = {111: {'COMMAND_LONG': 3, 'HEARTBEAT': 1}}\n - comp.source_component = 23\n - comp.num_msgs_rcvd = 4\n - comp.num_cmds_sent = 0\n - comp.num_cmds_rcvd = 3\n - comp.num_acks_rcvd = 0\n - comp.num_acks_sent = 3\n - comp.num_acks_drop = 0\n - comp.message_cnts = {111: {'COMMAND_LONG': 3, 'HEARTBEAT': 1}} \n\nserver.component[22].message_cnts[111]['COMMAND_LONG'] = 3\n\n\n\n# assert False, \"Stop here\"\n\n\n\nTest with Serial ports\nTest using a Pixhawk connected via telemetry 2 and USB serial ports. CamClient is set to udpin:localhost:14445 and CamServer is set to udpout:localhost:14435 udpin is so that the client can receive UDP from the mavproxy server at localhost:14445 mavproxy.py –master=/dev/ttyACM1 –baudrate 57600 –out udpout:localhost:14445 mavproxy.py –master=/dev/ttyACM3 –baudrate 57600 –out udpout:localhost:14435\n\n# Test sending a command and receiving an ack from client to server\nwith MAVCom(\"/dev/ttyACM0\", source_system=111) as client:\n    with MAVCom(\"/dev/ttyUSB0\", source_system=222) as server:\n        client.add_component(Cli(client, mav_type=MAV_TYPE_GCS))\n        server.add_component(Cam1(server, mav_type=MAV_TYPE_CAMERA))\n        server.add_component(Cam1(server, mav_type=MAV_TYPE_CAMERA))\n        \n        for key, comp in client.component.items():\n            if comp.wait_heartbeat(target_system=222, target_component=22, timeout=0.1):\n                print (\"*** Received heartbeat **** \" )\n        NUM_TO_SEND = 2\n        for i in range(NUM_TO_SEND):\n            client.component[11]._test_command(222, 22, 1)\n            client.component[11]._test_command(222, 23, 1)\n            \n        client.component[11]._test_command(222, 24, 1)\n\n    print(f\"{server.source_system = };  {server.message_cnts = }\")\n    print(f\"{client.source_system = };  {client.message_cnts = }\")\n    print()\n    print(f\"{client.source_system = } \\n{client.summary()} \\n\")\n    print(f\"{server.source_system = } \\n{server.summary()} \\n\")\n\n    assert client.component[11].num_cmds_sent == NUM_TO_SEND * 2 + 1\n    assert client.component[11].num_acks_rcvd == NUM_TO_SEND * 2\n    assert client.component[11].num_acks_drop == 1\n    assert server.component[22].num_cmds_rcvd == NUM_TO_SEND\n    assert server.component[23].num_cmds_rcvd == NUM_TO_SEND\n\nSerialException: [Errno 2] could not open port /dev/ttyACM0: [Errno 2] No such file or directory: '/dev/ttyACM0'\n\n\n\nFor debugging help see http://localhost:3000/tutorials/mavlink_doc&debug.html and http://localhost:3000/tutorials/mavlink_doc&debug.html#debugging",
    "crumbs": [
      "Get Started",
      "API",
      "Mavlink Camera"
    ]
  },
  {
    "objectID": "api/template.html",
    "href": "api/template.html",
    "title": "Gstreamer raw transmit",
    "section": "",
    "text": "All of nbdev’s configuration is done through a file called settings.ini which lives in the root of your repo. It’s in ConfigParser format. For example, here’s the first few lines of nbdev’s settings.ini file\n\ntest_eq(1,2)\n\nAssertionError: ==:\n1\n2",
    "crumbs": [
      "Get Started",
      "API",
      "Gstreamer raw transmit"
    ]
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "API",
    "section": "",
    "text": "This section contains API details for each of projects python submodules. This reference documentation is mainly useful for people looking to customise or build on top of the API, or wanting detailed information about how the API works.\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nGstreamer raw transmit\n\n\nGstreamer video capture with on/off valve\n\n\n\n\nMavlink MavCom\n\n\nMavlink base class for Client and server.\n\n\n\n\nMavlink Camera\n\n\nMavlink Camera Component for sending commands to a camera on a companion computer or GCS\n\n\n\n\nMavlink Component\n\n\nMavlink base class for Client and server.\n\n\n\n\nMavlink ViewSheen Gimbal Component\n\n\nMavlink ViewSheen Camera Component for sending commands to a viewsheen gimbal on a companion computer or GCS\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Get Started",
      "API"
    ]
  },
  {
    "objectID": "contributing/docs.html",
    "href": "contributing/docs.html",
    "title": "Docs Website",
    "section": "",
    "text": "There are two mediums in which you can author documentation in nbdev:\n\nJupyter Notebooks\nQuarto Markdown (.qmd)\n\nFor most cases, you will use Jupyter Notebooks. However, you may choose to author a document in Quarto Markdown if there is no code on that particular page. When in doubt, we recommend using notebooks as they are more versatile.\nIn the case of notebooks, nbdev pre-processes them to add, remove or change the content before passing it to Quarto. In some cases, nbdev even executes certain cells in order to render the documentation properly. The mechanics of this are discussed in the Notebook Processor section below.\nFor markdown files, Quarto renders these directly.\n\n\n\nNbdev does special pre-processing on notebooks based on the following:\n\nDirectives: Directives are special comments that allow you to perform operations on cells. For example, the comment #|hide allows you to hide cell inputs and outputs. You can read more about directives on this page. Directives that are unique to nbdev and not supported by Quarto are removed from the notebook before being passed to Quarto.\nFront Matter: Front matter allows you to specify document-level options so you don’t have to repeat them on each cell. (Similarly, _quarto.yml allows you to specify project-level options.) You can read more about Quarto front-matter here.\n\nThe directives and front-matter are used by a Processing Pipeline to transform notebooks. Many of these pre-processing steps are defined in nbdev.processors, which are then run by nbdev.process.NBProcessor. Some of these pre-processing steps involve running code (with execnb) in order to dynamically render API documentation. This process is explained in the How show_doc works section below.\nWhen generating your docs site, the intermediate output of these pre-processed notebooks and other quarto project files are saved into a directory named _proc/ at the root of your repo. You can inspect the _proc/ directory in order to debug or understand how notebooks are pre-processed.\n\n\n\nQuarto is the mechanism nbdev uses to generate web pages from notebooks. It is useful to visit the Quarto docs and understand how it works. nbdev automatically generates the Quarto configuration files _quarto.yml and sidebar.yml for you.\nYou can override any settings in _quarto.yml by defining a custom.yml file. This is explained further in the Customizing Quarto section. We explain how to customize your sidebar in the Customizing The Sidebar section.\n\n\n\nQuarto has a built-in static site generator that will generate HTML, Javascript and CSS files. These files will be placed in the doc_path directory as specified in your project’s settings.ini file, which is _docs/ by default.",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Docs Website"
    ]
  },
  {
    "objectID": "contributing/docs.html#concepts",
    "href": "contributing/docs.html#concepts",
    "title": "Docs Website",
    "section": "",
    "text": "There are two mediums in which you can author documentation in nbdev:\n\nJupyter Notebooks\nQuarto Markdown (.qmd)\n\nFor most cases, you will use Jupyter Notebooks. However, you may choose to author a document in Quarto Markdown if there is no code on that particular page. When in doubt, we recommend using notebooks as they are more versatile.\nIn the case of notebooks, nbdev pre-processes them to add, remove or change the content before passing it to Quarto. In some cases, nbdev even executes certain cells in order to render the documentation properly. The mechanics of this are discussed in the Notebook Processor section below.\nFor markdown files, Quarto renders these directly.\n\n\n\nNbdev does special pre-processing on notebooks based on the following:\n\nDirectives: Directives are special comments that allow you to perform operations on cells. For example, the comment #|hide allows you to hide cell inputs and outputs. You can read more about directives on this page. Directives that are unique to nbdev and not supported by Quarto are removed from the notebook before being passed to Quarto.\nFront Matter: Front matter allows you to specify document-level options so you don’t have to repeat them on each cell. (Similarly, _quarto.yml allows you to specify project-level options.) You can read more about Quarto front-matter here.\n\nThe directives and front-matter are used by a Processing Pipeline to transform notebooks. Many of these pre-processing steps are defined in nbdev.processors, which are then run by nbdev.process.NBProcessor. Some of these pre-processing steps involve running code (with execnb) in order to dynamically render API documentation. This process is explained in the How show_doc works section below.\nWhen generating your docs site, the intermediate output of these pre-processed notebooks and other quarto project files are saved into a directory named _proc/ at the root of your repo. You can inspect the _proc/ directory in order to debug or understand how notebooks are pre-processed.\n\n\n\nQuarto is the mechanism nbdev uses to generate web pages from notebooks. It is useful to visit the Quarto docs and understand how it works. nbdev automatically generates the Quarto configuration files _quarto.yml and sidebar.yml for you.\nYou can override any settings in _quarto.yml by defining a custom.yml file. This is explained further in the Customizing Quarto section. We explain how to customize your sidebar in the Customizing The Sidebar section.\n\n\n\nQuarto has a built-in static site generator that will generate HTML, Javascript and CSS files. These files will be placed in the doc_path directory as specified in your project’s settings.ini file, which is _docs/ by default.",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Docs Website"
    ]
  },
  {
    "objectID": "contributing/docs.html#overview",
    "href": "contributing/docs.html#overview",
    "title": "Docs Website",
    "section": "Overview",
    "text": "Overview\nBelow is a diagram on how these concepts fit together.\n\n\n\n\n\nflowchart TB\n  %%styles\n  style JN fill:#FFA500\n  style FP fill:#cfe5ed\n  style SF fill:#dff1dd,stroke-dasharray: 5 5;\n  style QMD fill:#7286bb,color:#fff;\n  classDef files fill:#ede8ce ;\n  classDef code fill:#5695c7,color:#fff;\n  classDef container fill:#f9f9f6;\n  \n   %% list of nodes\n  FP(&lt;strong&gt;Processing Pipeline&lt;/strong&gt;\\ntransforms notebook based\\non directives and front-matter)\n  E(execnb)\n  SD(\"show_doc\")\n  SS(&lt;strong&gt;Static Site&lt;/strong&gt;\\nHTML, CSS and Javascript)\n  CF(\"Intermediate Output is stored in the &lt;code&gt;_procs/&lt;/code&gt; directory\\n\\n&lt;i&gt;(This is a full copy of your Quarto project)&lt;/i&gt;\")\n  class SD,E code;\n  \n  subgraph SF[\"&lt;strong&gt;Source Files&lt;/strong&gt;\"]\n      JN([Jupyter\\nNotebook])\n      QMD([\"Quarto\\nMarkdown\\n(.qmd)\"])\n  end\n  \n  \n  %% connections to things inside Notebook Processor (NBP)\n  JN -- json --&gt; FP\n  E -. \"cell execution\" .- SD\n  \n  subgraph NBP [\"&nbsp;&lt;strong&gt;Notebook Processor\\n&lt;/strong&gt;&nbsp;\"]\n      SD -.- |\"render API docs\"|FP\n  end\n  \n  FP -- modified json with only\\nQuarto directives remaining --&gt; CF\n  \n  subgraph Quarto [\"&nbsp;&lt;strong&gt;Quarto&lt;/strong&gt;\\n&nbsp;&lt;br&gt;\"]\n      direction LR\n      F[[_quarto.yml]] .-&gt; G[[custom.yml]] & H[[sidebar.yml]]\n      class F,G,H files;\n  end\n  \n  QMD --\"rendered\\ndirectly by Quarto\\n(no pre-processing required)\"--&gt; CF\n  CF --&gt; Quarto\n  Quarto --&gt; SS\n  \n  class NBP,CF,Quarto container;",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Docs Website"
    ]
  },
  {
    "objectID": "contributing/docs.html#customizing-quarto",
    "href": "contributing/docs.html#customizing-quarto",
    "title": "Docs Website",
    "section": "Customizing Quarto",
    "text": "Customizing Quarto\nYou can create a custom.yml file in the same location as your _quarto.yml file to override any values in _quarto.yml. For example, assume your _quarto.yml file looks contains this:\n\nwebsite:\n  title: \"nbdev\"\n  site-url: \"https://nbdev.fast.ai/\"\n  description: \"Create delightful software with Jupyter Notebooks\"\n  twitter-card: true\n  open-graph: true\n  repo-branch: master\n  repo-url: \"https://github.com/fastai/nbdev\"\n  repo-actions: [issue]\n  navbar:\n    background: primary\n    search: true\n    right:\n      - icon: github\n        href: \"https://github.com/fastai/nbdev\"\n  sidebar:\n    style: \"floating\"\n\nLet’s assume you want to customize your sidebar navigation options such that instead of “floating” for sidebar.style, you wanted your navbar to be “docked”. Additionally, lets assume you want a different background color using the sidebar.background field which is not in the configuration above.\nTo accomplish these tasks, you would create a custom.yml in the same location as _quarto.yml with these contents:\n\nwebsite:\n  sidebar:\n      style: \"docked\"\n      background: \"dark\"\n\n\n\n\n\n\n\nNote\n\n\n\nYou can also set custom_quarto_yml = True in settings.ini if you wish to edit _quarto.yml directly instead of overriding settings in custom.yml.\n\n\n\nCustomizing The Sidebar\nBy default nbdev automatically generates sidebar.yml, which specifies the tree structure of your sidebar. nbdev infers the tree structure by inspecting the directory structure containing your source files. You can see an example of this by inspecting the folder structure of the notebooks directory in nbdev and the corresponding left-hand sidebar on this website. Leading numbers in filenames and directories are ignored when naming elements of the sidebar (which you can see examples of in this project’s notebooks directory).\nTo customize the sidebar, you must set custom_sidebar = true in settings.ini. This will prevent nbdev from regenerating this file every time the docs are re-built. This way, you an edit this file directly instead of overriding the sidebar with custom.yml.",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Docs Website"
    ]
  },
  {
    "objectID": "contributing/docs.html#how-show_doc-works",
    "href": "contributing/docs.html#how-show_doc-works",
    "title": "Docs Website",
    "section": "How show_doc works",
    "text": "How show_doc works\nWhen your documention website is built, all functions and classes you export to source code will be automatically documented with show_doc. This function outputs a summary of the symbol, showing its signature, docstring, and parameters. For instance, if you have this function:\n\ndef say_gday(\n    greeting:str=\"G'day\",  # Greeting to use\n    strine:bool=True,      # Use incomprehensible Aussie accent?\n    dropbears:bool=False): # Also warn about drop-bears?\n    \"Says g'day, the classic Aussie greeting\"\n    ...\n\nThis is how it’s rendered in the documentation, by automatically generating a temporary cell containing:\n\nshow_doc(say_gday)\n\n\nsay_gday\n\n say_gday (greeting:str=\"G'day\", strine:bool=True, dropbears:bool=False)\n\nSays g’day, the classic Aussie greeting\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ngreeting\nstr\nG’day\nGreeting to use\n\n\nstrine\nbool\nTrue\nUse incomprehensible Aussie accent?\n\n\ndropbears\nbool\nFalse\nAlso warn about drop-bears?\n\n\n\n\n\nBecause this is done automatically any time you build your docs (including automatically by continuous integration), your documentation will always contain current information about your code.\nYou can also document code that’s not created in a notebook, by using show_doc with imported code. For instance, if we wanted to document release_conda, we can import it and call show_doc(release_conda):\n\nfrom nbdev.release import release_conda\nshow_doc(release_conda)\n\nsource\n\nrelease_conda\n\n release_conda (path:str='conda', do_build:&lt;function bool_arg&gt;=True,\n                build_args:str='', skip_upload:&lt;function\n                store_true&gt;=False, mambabuild:&lt;function store_true&gt;=False,\n                upload_user:str=None)\n\nCreate a meta.yaml file ready to be built into a package, and optionally build and upload it\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nconda\nPath where package will be created\n\n\ndo_build\nbool_arg\nTrue\nRun conda build step\n\n\nbuild_args\nstr\n\nAdditional args (as str) to send to conda build\n\n\nskip_upload\nstore_true\nFalse\nSkip anaconda upload step\n\n\nmambabuild\nstore_true\nFalse\nUse mambabuild (requires boa)\n\n\nupload_user\nstr\nNone\nOptional user to upload package to\n\n\n\n\n\n\nAutomatic Cell Execution\nWhen your documentation is built, all your manually added show_doc cells are run automatically. nbdev also executes all cells containing an import statement, and all exported cells – that way we can be sure that the symbol used in your show_doc cell is available.\nWe don’t, however, execute any other cells. That’s because you wouldn’t want to wait for your entire notebook to run just to build your docs; for instance, your docs might demonstrate training a model which takes hours to complete!\nThis leads to an important rule when authoring nbdev notebooks:\n\n\n\n\n\n\nWarning\n\n\n\nDo not mix import statements (or calls to show_doc) with other code in a single cell. If you do, all the code in that cell will be executed every time you build your docs, which might lead to errors (since not all previous cells will have been executed.\nInstead, put your imports in separate cells, and calls to show_doc should contain only that one line of code – the show_doc call.\n\n\nNote that nbdev automatically hides the actual show_doc(...) line of code. So your users only see the output.\n\nForcing Cells To Execute\nSometimes you may want to execute additional cells beyond what is automatically executed by nbdev. For instance, on our Getting Started page we show a list of all nbdev commands, automatically generated with nbdev_help. We want this page to always have the most up to date list of commands and docs, so we want it to always execute when the docs are rendered. To do that, add the following directive to the top of a cell:\n#| exec_doc\nAlternatively, you can get nbdev to automatically execute all cells when rendering your docs, by adding the following to your notebook frontmatter:\n---\nexec_all: true\n---\n\n\nSkipping Execution\nLikewise, you can instruct nbdev to not execute any cells when rendering your docs with the following front matter:\n---\nskip_showdoc: true\n---\nOr ignore execution for a specific cell with this directive:\n#|eval: false\n\n\n\nWhy use show_doc?\nMany Python developers use sphinx autodoc to automatically document a whole module all at once. Whilst this can work reasonably well, we think there are huge benefits for both developers and users in using nbdev’s approach instead\nThe premise of nbdev’s approach is that your documentation is important enough to be worth you taking the time to think carefully though each thing you want to show your users, what examples you’re going to provide, maybe adding some images to explain more complex ideas, and so forth. Jupyter provides a terrific environment for creating just these kinds of documents. For instance, with Jupyter you can:\n\nPaste images directly from your clipboard into a cell\nInsert code and have it executed and the results displayed to users\nCreate a hierarchy of headings to help structure your page\n…and much more.\n\nWith show_doc, you can insert automatically-updated API details for your library anywhere in a page. That means that you get to decide exactly how your page should look, and what information is provided where. You don’t have to limit yourself to the limits of ASCII art for diagrams, and can include full end-to-end code walk-through of the processes your users will be following.",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Docs Website"
    ]
  },
  {
    "objectID": "contributing/docs.html#previewing-your-site-locally",
    "href": "contributing/docs.html#previewing-your-site-locally",
    "title": "Docs Website",
    "section": "Previewing Your Site Locally",
    "text": "Previewing Your Site Locally\nYou can preview your docs anytime by running nbdev_preview. While in preview mode, you can make updates to notebooks and it will be reflected (after a small delay) in your browser.",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Docs Website"
    ]
  },
  {
    "objectID": "contributing/docs.html#deploying-docs-with-github-actions",
    "href": "contributing/docs.html#deploying-docs-with-github-actions",
    "title": "Docs Website",
    "section": "Deploying Docs With GitHub Actions",
    "text": "Deploying Docs With GitHub Actions\nIf your nbdev project lives in GitHub, we include automation that deploys your documentation site for you on GitHub Pages.\nnbdev comes bundled with a workflow file that enables this automation. This workflow is automatically triggered whenever you change any of the content in your repo. The following GitHub Actions workflows will run to generate a docs site (in this order):\n\nDeploy to GitHub Pages: This workflow builds the docs with nbdev. This is defined in deploy.yaml and references fastai/workflows/quarto-ghp.\npages build and deployment: This is an internal built-in workflow that GitHub provides whenever GitHub pages are enabled.\n\nShould anything go wrong in your page build, you can always look at the logs of these workflows. Like other workflows, these can be found in the Actions tab of your repo:\n\n\n\n\n\nTo read more about GitHub Actions, see their docs.",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Docs Website"
    ]
  },
  {
    "objectID": "contributing/docs.html#deploying-your-docs-on-other-platforms",
    "href": "contributing/docs.html#deploying-your-docs-on-other-platforms",
    "title": "Docs Website",
    "section": "Deploying Your Docs On Other Platforms",
    "text": "Deploying Your Docs On Other Platforms\nYou can generate all of the static assets for your site (html, css, etc) by running the command nbdev_docs. After running this command, all of the files for your documentation site will be located in the _docs/ directory (the location is configurable by doc_path in settings.ini) at the root of your repository. This directory is not checked into git and is ignored by .gitignore, but you can use these files to deploy to any hosting platform you want.\nYou can also use the quarto publish command to render your docs on a wide variety of other platforms, which is discussed in the Quarto docs here. After running the command nbdev_docs, the quarto publish command must be run from the root of the _proc/ directory, which is located at the root of your repo. The built-in help of quarto publish provides a good overview of the various targets available:\n\n\n\n\n\n\nCall nbdev_proc_nbs and publish from the _proc/ directory\n\n\n\nTo use quarto publish with nbdev, you must run the nbdev_proc_nbs command to pre-process your notebooks before publishing your docs. As a reminder, nbdev_proc_nbs creates the directory _proc/ at the root of your project that Quarto uses to render your site.\nFor example, to publish a site to Netlify you can run the following command from the root of your repo:\nnbdev_proc_nbs && cd _proc && quarto publish netlify\n\n\n\n!quarto publish -h\n\n\n  Usage:   quarto publish [provider] [path]\n  Version: 1.1.75                          \n                                           \n\n  Description:\n\n    Publish a document or project. Available providers include:\n                                                               \n     - Quarto Pub (quarto-pub)                                 \n     - GitHub Pages (gh-pages)                                 \n     - RStudio Connect (connect)                               \n                                                               \n     - Netlify (netlify)                                       \n    Accounts are configured interactively during publishing.   \n    Manage/remove accounts with: quarto publish accounts       \n\n  Options:\n\n    -h, --help              - Show this help.                                     \n    --id          &lt;id&gt;      - Identifier of content to publish                    \n    --server      &lt;server&gt;  - Server to publish to                                \n    --token       &lt;token&gt;   - Access token for publising provider                 \n    --no-render             - Do not render before publishing.                    \n    --no-prompt             - Do not prompt to confirm publishing destination     \n    --no-browser            - Do not open a browser to the site after publishing  \n    --log         &lt;level&gt;   - Path to log file                                    \n    --log-level   &lt;level&gt;   - Log level (info, warning, error, critical)          \n    --log-format  &lt;format&gt;  - Log format (plain, json-stream)                     \n    --quiet                 - Suppress console output.                            \n\n  Commands:\n\n    help  [command]  - Show this help or the help of a sub-command.\n\n  Examples:\n\n    Publish project (prompt for provider):  quarto publish                                                  \n    Publish document (prompt for provider): quarto publish document.qmd                                     \n    Publish project to Netlify:             quarto publish netlify                                          \n    Publish with explicit target:           quarto publish netlify --id DA36416-F950-4647-815C-01A24233E294 \n    Publish project to GitHub Pages:        quarto publish gh-pages                                         \n    Publish project to RStudio Connect:     quarto publish connect                                          \n    Publish with explicit credentials:      quarto publish connect --server example.com --token 01A24233E294\n    Publish without confirmation prompt:    quarto publish --no-prompt                                      \n    Publish without rendering:              quarto publish --no-render                                      \n    Publish without opening browser:        quarto publish --no-browser                                     \n    Manage/remove publishing accounts:      quarto publish accounts",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Docs Website"
    ]
  },
  {
    "objectID": "contributing/doc_walkthrough.html",
    "href": "contributing/doc_walkthrough.html",
    "title": "Documentation Walkthrough",
    "section": "",
    "text": "The written tutorial below shows you how to create a Python package from scratch using nbdev.\nAlternatively, you can watch this video tutorial where Jeremy Howard and Hamel Husain guide you through a similar process step by step:",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Documentation Walkthrough"
    ]
  },
  {
    "objectID": "contributing/doc_walkthrough.html#installation",
    "href": "contributing/doc_walkthrough.html#installation",
    "title": "Documentation Walkthrough",
    "section": "Installation",
    "text": "Installation\nYou’ll need the following software to complete the tutorial, read on for specific installation instructions:\n\nPython\nA Python package manager: we recommend conda or pip\nJupyter Notebook\nnbdev\nQuarto\n\nIf you haven’t worked with Python before, we recommend getting started with the Anaconda Individual Edition and using the conda package manager.\nNote that you will only need to follow the steps in the installation section once per environment. If you create a new repo, you won’t need to redo these.\n\nInstall JupyterLab\nLaunch a terminal and install JupyterLab by entering:\nconda install -c conda-forge -y jupyterlab\n…or\npip install jupyterlab\n…if you’re using the pip package manager.\nYou can now launch Jupyter by entering:\njupyter lab\nThis should open JupyterLab in a new browser tab:\n\n\n\n\n\n\n\nInstall nbdev\nThe next step is to install nbdev itself. JupyterLab comes with its own terminal, so we’ll use that moving forward.\nIn the Launcher, scroll down to the “Other” section, then click “Terminal”. If the Launcher isn’t opened, you can open it by clicking “File” → “New Launcher”.\nA new tab should open with a blank terminal – it might not look exactly the same, depending on how your shell is configured:\n\n\n\n\n\nFor Mac and Linux, enter:\nconda install -c fastai -y nbdev\n…or for Mac, Linux and Windows:\npip install nbdev\n…if you’re using pip.\n\n\nInstall Quarto\nnbdev provides a command to install the latest version of Quarto. In the terminal, enter:\nnbdev_install_quarto\nYour password may be requested at this point. Since nbdev is open source, you can read the source code of this command to verify that it isn’t doing anything malicious. Or, if you prefer, you may instead follow Quarto’s official installation instructions.\n\n\nInstall Quarto JupyterLab extension\nQuarto provides its own JupyterLab extension that allows it to render Quarto markdown content.\nFor example, here is their notebook demonstrating some of its features:\n\nInstall the extension by entering:\npip install jupyterlab-quarto\nNote that the jupyterlab-quarto package is not currently available via conda.\n\nYou’re all setup and ready to go! Installing these tools may take some time, but you’ll only need to do it once. Next, we’ll setup an nbdev repo for your specific project.",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Documentation Walkthrough"
    ]
  },
  {
    "objectID": "contributing/doc_walkthrough.html#first-steps",
    "href": "contributing/doc_walkthrough.html#first-steps",
    "title": "Documentation Walkthrough",
    "section": "First steps",
    "text": "First steps\nBy the end of this section you’ll have your own nbdev repo with tests, continuous integration, streamlined PyPI & conda packaging, and a documentation website.\n\nCreate an empty GitHub repo\nCreate an empty GitHub repo using the convenient link github.com/new. If you get stuck, you might find GitHub’s Create a repo page helpful.\nRemember to add a description, since nbdev will use that later. Don’t add a README file, .gitignore, or license just yet.\nIf you’re using the web interface, it should look something like this (with your own repository name and descrpition) before you click “Create Repository”:\n\n\n\n\n\nYou should then be redirected to your new repo:\n\n\n\n\n\n\n\n\n\n\n\nTry GitHub’s powerful CLI\n\n\n\n\n\nGitHub’s web interface is a great way to get started. As you grow more experienced, you might want to explore the GitHub CLI (command line interface). We often prefer to use command line tools for repetitive tasks where we’re likely to make mistakes. Having those tasks written as small scripts in your terminal means that you can repeat them with little effort.\n\n\n\n\n\nInitialise your repo with nbdev\nNow clone your repo from the Jupyter terminal you started earlier (or create a new terminal following those instructions if needed). If you get stuck here, you might find GitHub’s Cloning a repository page helpful.\nSince we created a repo named nbev-hello-world with the fastai user, we can clone it as follows:\ngit clone https://github.com/fastai/nbdev-hello-world.git\nThen cd (change directory) to our repo:\ncd nbdev-hello-world\nYou may have seen this message while cloning:\nYou appear to have cloned an empty repository.\n…since the repo is completely empty. Let’s add some files!\nnbdev provides the nbdev_new command to initialise an empty git repository. It’ll infer information about your project from git and GitHub, and ask you to input anything remaining. It will create files in your repo that:\n\nStreamline publishing Python packages to PyPI and conda.\nConfigure Quarto for publication-grade technical documentation.\nSetup GitHub actions to test notebooks and build and deploy Quarto docs to GitHub pages.\n\nInitialise your nbdev repo by entering:\nnbdev_new\nIt may ask you to enter information that it couldn’t infer from git or GitHub.\n\n\n\n\n\n\nNote\n\n\n\nnbdev_new assumes that your package name is the same as your repo name (with - replaced by _). Use the --lib_name option if that isn’t the case.\n\n\nDouble-check your settings.ini file to ensure that it has all of the correct information. Then commit and push your additions to GitHub:\ngit add .\ngit commit -m'Initial commit'\ngit push\n\n\nEnable GitHub Pages\nnbdev hosts your docs on GitHub Pages—an excellent (and free!) way to host websites.\n\n\n\n\n\n\nNote\n\n\n\nnbdev uses GitHub Pages by default because its easily accessible. However, you can use any host you like. See these docs for more information.\n\n\nYou need to enable GitHub Pages for your repo by clicking on the “Settings” tab near the top-right of your repo page, then “Pages” on the left, then setting the “Branch” to “gh-pages”, and finally clicking “Save”.\nIt should look similar to this after you click “Save”:\n\n\n\n\n\nNow it’s time to see all of the goodies nbdev gives you!\n\n\nCheck out your workflows\nOpen GitHub Actions by clicking the “Actions” tab near the top of your repo page. You should see two workflow runs:\n\n\n\n\n\nIf you opened this page shortly after pushing your initial commit, the runs may not have a green check (✅) because they’re still “In progress” or “Queued”. That’s no problem, they shouldn’t take much more than a minute to complete.\nIf you see a red cross (❌), that means something failed. Click on the cross, then click “Details”, and you’ll be able to see what failed. If you can’t figure out what’s wrong, search the forum in case someone else resolved the same issue, otherwise create a new post describing your issue in as much detail as you can, and we’ll try our best to help you. Remember that including a link to an actual repo and/or GitHub Action is the best way for us to quickly identify what’s wrong.\nWhat do these workflows do?\n\nCI – The CI (continuous integration) workflow streamlines your developer workflow, particularly with multiple collaborators. Every time you push to GitHub, it ensures that:\n\nYour notebooks and libraries are in sync\nYour notebooks are cleaned of unwanted metadata (which pollute pull requests and git histories and lead to merge conflicts)\nYour notebook tests all pass\n\nDeploy to GitHub Pages – Builds your docs with Quarto and deploys it to GitHub Pages.\n\nWe provide these basic workflows out-of-the-box, however, you can edit their corresponding YAML files in the .github/workflows/ folder to your liking.\n\n\nCheck out your docs\nWhen you enable GitHub Pages you should see a new workflow run: “pages build and deployment”. As the name suggests, this workflow deploys your website contents to GitHub Pages.\n\n\n\n\n\nWait for the workflow run to complete, then open your website. By default it should be available at: https://{user}.github.io/{repo}. For example, you can view fastai’s nbdev-hello-world docs at https://fastai.github.io/nbdev-hello-world.\n\n\n\n\n\n\n\nRecap\nYou now have a base nbdev repo with continuous integration and hosted documentation! Here’s a recap of the steps you took:\n\nCreated a GitHub repo (with GitHub Pages enabled)\nInitialised your repo with nbdev_new\nPushed to GitHub.",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Documentation Walkthrough"
    ]
  },
  {
    "objectID": "contributing/doc_walkthrough.html#make-your-first-edit",
    "href": "contributing/doc_walkthrough.html#make-your-first-edit",
    "title": "Documentation Walkthrough",
    "section": "Make your first edit",
    "text": "Make your first edit\nIn this section, you’ll make your first edit to the repo you created in First steps.\n\nInstall hooks for git-friendly notebooks\nStep one when working with Jupyter notebooks in a new repo is to install nbdev’s hooks (you can think of “hooks” as plugins or extensions to an application).\nInstall them by entering this command in your terminal:\nnbdev_install_hooks\n\n\n\n\n\n\nNote\n\n\n\nThe clean hook currently only supports Jupyter Notebook and JupyterLab. If you’re using VSCode, you can try the experimental nbdev VSCode extension. Otherwise, you might also want to try nbdev’s pre-commit hooks.\n\n\nSee Git-friendly Jupyter for more about how nbdev hooks work and how to customise them. Here’s a short summary:\n\nFix broken notebooks due to git merge conflicts so that they can be opened and resolved directly in Jupyter.\nEach time you save a Jupyter notebook, automatically clean unwanted metadata to remove unnecessary changes in pull requests and reduce the chance of git merge conflicts.\nAutomatically trust notebooks in the repo so that you can view widgets from collaborators’ commits. For this reason, you should not install hooks into a repo you don’t trust.\n\n\n\n\n\n\n\nTip\n\n\n\nnbdev’s git hooks work on any git repo, even if it doesn’t use the broader nbdev system.\n\n\n\n\nBuild your library\nYou should now create your package from your notebook by running:\nnbdev_export\nThis will create Python modules for your notebooks. These modules will make up the contents of your Python package.\n\n\nInstall your package\nYou might have noticed that nbdev_new created a Python package in your repo. In our case, it was automatically named nbdev_hello_world by using our repo name nbdev-hello-world and replacing - with _ to make it a valid Python package.\nThe next step is to install your package by entering this into your terminal:\npip install -e '.[dev]'\nThis is the recommended way to make a Python package importable from anywhere in your current environment:\n\n-e – short for “editable”, lets you immediately use changes made to your package without having to reinstall, which is convenient for development.\n. – refers to the current directory.\n[dev] – includes “development” requirements: other packages that your notebooks use solely for documentation or testing.\n\n\n\nPreview your docs\nnbdev is an interactive programming environment that values fast feedback loops. The nbdev_preview command helps achieve this by using Quarto to render your docs on your computer and keep them updated as your edit your notebooks.\nStart the preview by entering this into your terminal:\nnbdev_preview\nIt may say Preparing to preview for a few seconds while it gets started, and will eventually display something like:\nWatching files for changes\nBrowse at http://localhost:3000/\nClick the link to open the preview in a new browser tab. It should look exactly like your online docs.\n\n\n\n\n\n\nTip\n\n\n\nWe often find it useful to keep a preview window open on the side while we’re editing our notebooks in Jupyter.\n\n\n\n\nEdit 00_core.ipynb\nNow, open the nbs/00_core.ipynb file (generated by running nbdev_new earlier) in Jupyter. You don’t have to start your notebook names with a number, but we find it helpful to show the order that your project should be read in – even though it could have been created in a different order.\n\nAdd your own frontmatter\nYou’ll see something that looks a bit like this:\n\ncore\n\nFill in a module description here\n\n#| default_exp core\n\nLet’s explain what these special cells means:\n\nThe first is a markdown cell with nbdev’s markdown frontmatter syntax that defines notebook metadata used by Quarto, our documentation engine (see the frontmatter reference page for more). It contains:\n\nH1 header (“core”) – defining the page title\nQuote (“Fill in a module description here”) – defining the page description\n\nThe second is a code cell with a directive default_exp which decides which module this notebook will export to (see the Directives explanation for more). Currently, it exports to the core module.\n\nNext, rename the notebook, replace the title and description, and change the default export module for your own project.\nOnce you’re done, save the notebook. The live preview started in the previous section should update with your latest changes.\nRerun all cells in your notebook to ensure that they work, and to export the updated modules.\n\n\n\n\n\n\nTip\n\n\n\nWe find the “restart kernel and run all cells” Jupyter command (the ⏩ button) so invaluable that we bind it to a keyboard shortcut. A common criticism of notebooks is that out-of-order execution leads to irreproducible notebooks. In our experience, making “restart and rerun” a habit solves this problem.\n\n\nRunning the notebook exports Python modules because of the last cell which contains:\n#| hide\nimport nbdev; nbdev.nbdev_export()\nWhat does this mean?\n\n#| hide is a directive (like #| default_exp) which excludes a cell from both your exported module and docs\nnbdev_export is the command used to export your notebooks to Python modules.\n\nWe recommend including a cell like this at the bottom of all of the notebooks you want to export.\n\n\n\n\n\n\nWarning\n\n\n\nRemember to delete any unused modules that aren’t exported by a notebook or otherwise needed by your package. This is likely to happen if you change the default export of a notebook – nbdev doesn’t remove the old module. This is intended, since nbdev is designed to work with hybrid packages that use .py modules (with no corresponding notebook) as well as those exported from notebooks.\n\n\n\n\nAdd your own function\nAdd a new code cell below the #| default_exp cell with a function. For example:\n#| export\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\nNotice how it includes #| export at the top – this is a directive (like #| default_exp) that tells nbdev to include the cell in your exported module and in your documentation.\nThe documentation should look like this:\n\n\n\nsay_hello\n\n say_hello (to)\n\nSay hello to somebody\n\n\n\n\nAdd your own examples, tests, and docs\nOne of the superpowers of notebook-driven development is that you can very easily add examples, tests, and documentation right below your code.\nInclude regular code cells, and they’ll appear (with output) in your docs, for example:\n\nsay_hello(\"Isaac\")\n\n'Hello Isaac!'\n\n\nThis is a test too! When you run nbdev_test it will execute this cell (and all other test cells) and fail if they raise any exceptions.\nFor tests, it’s preferred to use more explicit asserts:\n\nassert say_hello(\"Hamel\") == \"Hello Hamel!\"\n\n…or functions from fastcore.test, which behave like assert but also display the actual and expected values if they differ:\n\nfrom fastcore.test import *\n\n\ntest_eq(say_hello(\"Hamel\"), \"Hello Hamel!\")\n\nAnother superpower of notebook-driven development is that your examples can include plots, images, and even JavaScript widgets. For example, here’s an SVG circle:\n\nfrom IPython.display import display,SVG\n\n\ndisplay(SVG('&lt;svg height=\"100\" xmlns=\"http://www.w3.org/2000/svg\"&gt;&lt;circle cx=\"50\" cy=\"50\" r=\"40\"/&gt;&lt;/svg&gt;'))\n\n\n\n\n\n\n\n\n\n\n\nPrepare your changes\nBefore commiting your changes to GitHub we recommend running nbdev_prepare in the terminal, which bundles the following commands:\n\nnbdev_export: Builds the .py modules from Jupyter notebooks\nnbdev_test: Tests your notebooks\nnbdev_clean: Cleans your notebooks to get rid of extreanous output for git\nnbdev_readme: Updates your repo’s README.md file from your index notebook.\n\n\n\nEdit index.ipynb\nNow you’re ready to personalize your documentation home page and README.md file; these are both generated automatically from index.ipynb. Open Jupyter, then click on nbs/index.ipynb to open it.\nWe recommend including a longer description about what your package does, how to install it, and how to use it (with a few examples which import and use your package). Remember, examples can be code cells with real outputs rather than plain markdown text – they’ll double as tests too!\n\n\nPush to Github\nYou can now commit and push your changes to GitHub. As we mentioned before, always remember to run nbdev_prepare before you commit to ensure your modules are exported and your tests pass. You can use git status to check which files have been generated or changed. Then:\ngit add .\ngit commit -m 'Add `say_hello`; update index' # Update this text with your own message\ngit push\nThis will kick-off your GitHub Actions. Wait a minute or two for those to complete, then check your updated repo and documentation.\n\n\nRecap\nCongratulations, you’ve used all of the basics needed to build delightful projects with nbdev! Here’s a recap of the steps you took:\n\nInstalled hooks for git-friendly notebooks with nbdev_install_hooks\nInstalled your package with pip install -e '.[dev]'\nPreviewed your docs with nbdev_preview\nAdded your own frontmatter, function, tests, and docs to nbs/00_core.ipynb\nPrepared your changes with nbdev_prepare\nUpdated nbs/index.ipynb with your own information\nPushed to GitHub.\n\nRead on to learn about more advanced nbdev functionality. Also see our explanations for deep-dives on specific topics, as well as our other tutorials.",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Documentation Walkthrough"
    ]
  },
  {
    "objectID": "contributing/doc_walkthrough.html#advanced-functionality",
    "href": "contributing/doc_walkthrough.html#advanced-functionality",
    "title": "Documentation Walkthrough",
    "section": "Advanced functionality",
    "text": "Advanced functionality\n\nAdd a class\nCreate a class in 00_core.ipynb as follows:\n#| export\nclass HelloSayer:\n    \"Say hello to `to` using `say_hello`\"\n    def __init__(self, to): self.to = to\n        \n    def say(self):\n        \"Do the saying\"\n        return say_hello(self.to)\nThis will automatically appear in the docs like this:\n\n\n\nHelloSayer\n\n HelloSayer (to)\n\nSay hello to to using say_hello\n\nDocument with show_doc\nHowever, methods aren’t automatically documented. To add method docs, use show_doc:\nshow_doc(HelloSayer.say)\n\n\n\n\nHelloSayer.say\n\n HelloSayer.say ()\n\nDo the saying\nAnd add some examples and/or tests:\n\no = HelloSayer(\"Alexis\")\no.say()\n\n'Hello Alexis!'\n\n\n\n\nAdd links with backticks\nNotice above there is a link from our new class documentation to our function. That’s because we used backticks in the docstring:\n    \"Say hello to `to` using `say_hello`\"\nThese are automatically converted to hyperlinks wherever possible. For instance, here are hyperlinks to HelloSayer and say_hello created using backticks.\n\n\nSet up autoreload\nSince you’ll be often updating your modules from one notebook, and using them in another, it’s helpful if your notebook automatically reads in the new modules as soon as the Python file changes. To make this happen, just add these lines to the top of your notebook:\n%load_ext autoreload\n%autoreload 2\n\n\nSet up prerequisites\nIf your module requires other modules as dependencies, you can add those prerequisites to your settings.ini in the requirements section. The requirements should be separated by a space and if the module requires at least or at most a specific version of the requirement this may be specified here, too.\nFor example if your module requires the fastcore module of at least version 1.0.5, the torchvision module of at most version 0.7 and any version of matplotlib, then the prerequisites would look like this:\nrequirements = fastcore&gt;=1.0.5 torchvision&lt;0.7 matplotlib\nIn addition to requirements you can specify dependencies with other keywords that have different scopes. Below is a list of all possible dependency keywords:\n\nrequirements: Passed to both pip and conda setup\npip_requirements: Passed to pip setup only\nconda_requirements: Passed to conda setup only\ndev_requirements: Passed to pip setup as a development requirement\n\nFor more information about the format of dependencies, see the pypi and conda docs on creating specifications in setup.py and meta.yaml, respectively.\n\n\nSet up console scripts\nBehind the scenes, nbdev uses that standard package setuptools for handling installation of modules. One very useful feature of setuptools is that it can automatically create cross-platform console scripts. nbdev surfaces this functionality; to use it, use the same format as setuptools, with whitespace between each script definition (if you have more than one).\nconsole_scripts = nbdev_export=nbdev.cli:nbdev_export\n\n\nUpload to pypi\nIf you want people to be able to install your project by just typing pip install your-project then you need to upload it to pypi. The good news is, we’ve already created a fully pypi compliant installer for your project! So all you need to do is register at pypi (click “Register” on pypi) if you haven’t previously done so, and then create a file called ~/.pypirc with your login details. It should have these contents:\n[pypi]\nusername = your_pypi_username\npassword = your_pypi_password\nAnother thing you will need is twine, so you should run once\npip install twine\nTo upload your project to pypi, just type nbdev_pypi in your project root directory. Once it’s complete, a link to your project on pypi is displayed.\n\n\nUpload to conda\nSimilar to pip install support, we have provided an anaconda compliant installer to upload your project to anaconda. Once uploaded, your package can be installed by typing conda install -c your_anaconda_username your-project.\nYou need to register at anaconda (fill out the form to Sign Up) which will create a username and password. You will then need to install the following packages\npip install anaconda-client conda-build conda-verify\nBefore running the anaconda uploader, you need to login to conda using the CLI command (you will be prompted to enter your username and password)\nanaconda login\nTo upload to anaconda, just type nbdev_conda in your project root directory.\n\n\nUpload to pypi and conda\nThe command nbdev_release_both from the root of your nbdev repo will upload your project to both conda and pypi.\n\n\nInstall collapsible headings and toc2\nThere are two jupyter notebook extensions that I highly recommend when working with projects like this. They are:\n\nCollapsible headings: This lets you fold and unfold each section in your notebook, based on its markdown headings. You can also hit left to go to the start of a section, and right to go to the end\nTOC2: This adds a table of contents to your notebooks, which you can navigate either with the Navigate menu item it adds to your notebooks, or the TOC sidebar it adds. These can be modified and/or hidden using its settings.\n\n\n\nMath equation support\nnbdev supports equations (using Quarto). You can include math in your notebook’s documentation using the following methods.\nUsing $$, e.g.:\n$$\\sum_{i=1}^{k+1}i$$\nWhich is rendered as:\n\n\\[\\sum_{i=1}^{k+1}i\\]\n\nUsing $, e.g.:\nThis version is displayed inline: $\\sum_{i=1}^{k+1}i$ . You can include text before and after.\nWhich is rendered as:\n\nThis version is displayed inline: \\(\\sum_{i=1}^{k+1}i\\) . You can include text before and after.\n\nFor more information, see the Quarto Docs\n\n\nLook at nbdev “source” for more ideas\nDon’t forget that nbdev itself is written in nbdev! It’s a good place to look to see how fast.ai uses it in practice, and get a few tips. You’ll find the nbdev notebooks here in the nbs folder on Github.\n\n\nQuarto Features\nnbdev supports most Quarto features. We encourage you to read the Quarto documentation to discover all the features available to you. For example, this is how you can incorporate mermaid charts:\n\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\n\nHere is another example of using Graphviz:\n\n\n\n\n\n\n\nG\n\n\n\nrun\n\nrun\n\n\n\nintr\n\nintr\n\n\n\nrun--intr\n\n\n\n\nkernel\n\nkernel\n\n\n\nrun--kernel\n\n\n\n\nrunbl\n\nrunbl\n\n\n\nintr--runbl\n\n\n\n\nrunbl--run\n\n\n\n\nzombie\n\nzombie\n\n\n\nkernel--zombie\n\n\n\n\nsleep\n\nsleep\n\n\n\nkernel--sleep\n\n\n\n\nrunmem\n\nrunmem\n\n\n\nkernel--runmem\n\n\n\n\nsleep--runmem\n\n\n\n\nswap\n\nswap\n\n\n\nsleep--swap\n\n\n\n\nrunswap\n\nrunswap\n\n\n\nswap--runswap\n\n\n\n\nrunswap--runmem\n\n\n\n\nnew\n\nnew\n\n\n\nrunswap--new\n\n\n\n\nnew--runmem\n\n\n\n\n\n\n\n\n\nIt is worth taking a look at the documentation for figures, callouts, markdown, widgets, layouts, conditional content and quarto extensions to name a few useful things we have encountered.",
    "crumbs": [
      "Get Started",
      "Contributing",
      "Documentation Walkthrough"
    ]
  },
  {
    "objectID": "contributing/index.html",
    "href": "contributing/index.html",
    "title": "How to contribute & Document",
    "section": "",
    "text": "These explanations provide background information on how nbdev is designed and how it works. They are designed to help people who want to more deeply understand the nbdev system.\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nDocumentation Walkthrough\n\n\nA step-by-step guide to using nbdev\n\n\n\n\nDirectives\n\n\nA cheat sheet of directives available in nbdev.\n\n\n\n\nDocs Website\n\n\nHow nbdev renders a documentation website for your project.\n\n\n\n\nConfiguration\n\n\nThe nbdev configuration file\n\n\n\n\nWhy nbdev\n\n\nWhy we develop software with nbdev\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Get Started",
      "Contributing"
    ]
  },
  {
    "objectID": "getting_started.html",
    "href": "getting_started.html",
    "title": "Getting Started",
    "section": "",
    "text": "UAV software is a collection of Jupyter Notebooks that are used to develop and test UAV software. The notebooks are organized into a library, and the library is used to create a documentation website and a Python package that can be installed with pip or conda (see nbdev template for an example)\n\nDocumentation is automatically generated using nbdev & Quarto and hosted on GitHub Pages. Docs support LaTeX, are searchable, and are automatically hyperlinked (including out-of-the-box support for many packages via nbdev-index)\nPublish packages to PyPI and conda as well as tools to simplify package releases. Python best practices are automatically followed, for example, only exported objects are included in __all__\nTwo-way sync between notebooks and plaintext source code allowing you to use your IDE for code navigation or quick edits\nTests written as ordinary notebook cells are run in parallel with a single command\nContinuous integration out-of-the-box with GitHub Actions that run your tests and rebuild your docs\nGit-friendly notebooks with Jupyter/Git hooks that clean unwanted metadata and render merge conflicts in a human-readable format\n… and much more!",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "getting_started.html#install",
    "href": "getting_started.html#install",
    "title": "Getting Started",
    "section": "Install",
    "text": "Install\n\nPython 3.10 venv for Ubuntu 21.04, Ubuntu 20.04 LTS https://www.python.org/downloads/\n\nsudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt update\nsudo apt install python3.10\nNote For Ubuntu 18.04\nDeadsnakes/ppa is not hold distribution for Ubuntu 18.04 LTS, so you need to install it manually. Download Python 3.10.0 from https://github.com/conda-forge/miniforge - Linux x86_64 (amd64) For Jetson Nano use Python 3.8.xx - Linux aarch64 (arm64)\nGive the script execution permission and run it to install into ~/miniforge3\nchmod +x Miniforge3-Linux-x86_64.sh\n./Miniforge3-Linux-x86_64.sh\nfollow the prompts to install\n\nDownload UAV from github and create a virtual environment\n\nmkdir repos\ncd repos\ngit clone https://github.com/johnnewto/mavcom.git\ncd UAV\n~/miniforge3/bin/python -m venv 'venv'\nsource ./venv/bin/activate\npip install --upgrade pip\npip install -e .\n\nInstall gstreamer\n\nsudo apt-get install libcairo2 libcairo2-dev libgirepository1.0-dev\nsudo apt-get install libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libgstreamer-plugins-bad1.0-dev gstreamer1.0-plugins-base gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly gstreamer1.0-libav gstreamer1.0-tools gstreamer1.0-x gstreamer1.0-alsa gstreamer1.0-gl gstreamer1.0-gtk3 gstreamer1.0-qt5 gstreamer1.0-pulseaudio\n\nInstall gstreamer-python package into the python venv\n\npip install git+https://github.com/johnnewto/gstreamer-python.git\nNote For Ubuntu 18.04\nif you get glib install error such as\nRequested 'glib-2.0 &gt;= 2.64.0' but version of GLib is 2.56.4\nthen run this first\npip install PyGObject==3.42.0\nRunning a example program\ncd examples\npython run_camera_asyncio_gui.py",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "getting_started.html#faq",
    "href": "getting_started.html#faq",
    "title": "Getting Started",
    "section": "FAQ",
    "text": "FAQ\nTesting in a virtual Machine\nhttps://www.makeuseof.com/how-to-install-qemu-ubuntu-set-up-virtual-machine/\nsudo apt install qemu-kvm\nsudo apt install virt-manager\n\nCopyright\nCopyright © 2019 onward maui63.ai, Inc. Licensed under the Apache License, Version 2.0 (the “License”); you may not use this project’s files except in compliance with the License. A copy of the License is provided in the LICENSE file in this repository.",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  }
]